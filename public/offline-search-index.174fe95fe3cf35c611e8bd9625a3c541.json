[{"body":"Introducir usuario en el grupo docker\nsudo usermod -a -G docker [nombre_usuario] Refrescar grupo sin tener que reiniciar\nnewgrp docker Buscar un contenedor para descargar\ndocker search [nombre_contenedor] Instalar una imagen\ndocker pull [nombre_imagen] Listar imágenes instaladas\ndocker images Ver imágenes ejecutándose\ndocker ps Iniciar una imagen\ndocker run [nombre_imagen] Para acceder al contenedor, además de crearlo, se puede hacer de dos maneras. Una es haciendo referencia al IMAGE ID y otra al repositorio (REPOSITORY) y la etiqueta (TAG).\ndocker run -i -t b72889fa879c /bin/bash docker run -i -t ubuntu:14.04 /bin/bash El usuario también puede ponerle una etiqueta personalizada que haga referencia a una imagen instalada en su sistema.\ndocker tag b72889fa879c oldlts:latest Para crear el contenedor y ponerlo en marcha hay que seguir el mismo paso de antes, pero cambiando la referencia por la etiqueta creada por el usuario.\ndocker run -i -t oldlts:latest /bin/bash Para iniciar un contenedor en modo demonio\ndocker run -d [identificador_imagen] Como ya hemos comentado, cada vez que ejecutamos el comando run estamos creando un contenedor nuevo, por lo que lo recomendable es ejecutarlo tan solo una vez. Luego podemos listar los contenedores disponibles a través del siguiente comando.\ndocker ps -a Hay dos maneras de poner en marcha el contenedor a través del mismo comando, pudiéndose utilizar su identificador (CONTAINER ID) o su nombre (NAMES).\ndocker start ef7e107e0aae docker start lonely_wing Si se quiere acceder (attach, que se podría traducir por adjuntar o unir) al contenedor se puede recurrir a una de estas dos opciones.\ndocker attach ef7e107e0aae docker attach lonely_wing Salir del terminal de docker sin apagarlo Control + P \u0026 Control + Q Para detener un contenedor\ndocker stop ef7e107e0aae docker stop lonely_wing Para borrar un contenedor\ndocker rm ef7e107e0aae docker rm lonely_wing Parar todos los contenedores\ndocker stop $(docker ps -a -q) Terminal de un contenedor arrancado\ndocker exec -ti f38197856de0 /bin/bash Eliminar todos los contenedores\ndocker rm $(docker ps -a -q) Eliminar todas las imágenes\ndocker rmi $(docker images -q) Realizar commit de una imagen\ndocker commit -a \"[información creador]\" -m \"[versión del programa]\" [identificador_container] [nombre_repositorio:nombre_TAG] Obtener la ruta del registro de un contenedor\ndocker inspect --format='{{.LogPath}}' $ID_CONTENEDOR ","categories":"","description":"\"Guía de comandos generales de docker\" \n","excerpt":"\"Guía de comandos generales de docker\" \n","ref":"/docs/contenedores/docker/comandos_generales/","tags":["docker","contenedores"],"title":"Comandos docker"},{"body":"","categories":"","description":"Sección que agrupa los conocimientos sobre tecnologías de contenedores como docker, kubernetes... etc.\n","excerpt":"Sección que agrupa los conocimientos sobre tecnologías de contenedores …","ref":"/docs/contenedores/","tags":"","title":"Contenedores"},{"body":"Docker es un proyecto de código abierto que automatiza el despliegue de aplicaciones dentro de contenedores de software. Comenzó como un proyecto interno dentro de dotCloud, empresa enfocada a una plataforma como un servicio PaaS (Platform as a Service). Fué iniciado por Solomon Hykes con contribuciones de otros ingenieros de la compañia.\nDocker fué liberado como código abierto en 2013. El 13 de marzo de 2014, con el lanzamiento de la versión 0.9 se dejó de utilizar LXC como entorno de ejecución por defecto y lo reemplazó con su propia biblioteca, libcontainer, escrito en Go. Para 2015 el proyecto ya tenía más 20.000 estrellas en GitHub y más de 900 colaboradores.\nPero… ¿Cómo funciona? Docker se basa en la ejecución de procesos aislados entre sí y empaquetados en “contenedores” con todas las dependencias necesarias para funcionar.\nEsto es posible gracias a dos funcionalidades del kernel de linux que se llaman “namespaces” y “cgroups”.\nEl soporte de los namescaces o espacios de nombres aísla la vista que tiene una aplicación de su entorno operativo,​ incluyendo árboles de proceso, red, ID de usuario y sistemas de archivos montados. Por otra parte, los cgroups del kernel proporcionan aislamiento de recursos, incluyendo la CPU, la memoria, el bloque de E/S y de la red.\nComo resumen, se lanza un proceso aislado con todas las dependencias necesarias para que funcione.\nArquitectura de Docker Hemos hablado de procesos y contenedores, pero esto es solo una pequeña pieza de todos los objetos que conforman Docker a día de hoy.\n","categories":"","description":"Primera entrada del curso de docker hablando sobre sus fundamentos.","excerpt":"Primera entrada del curso de docker hablando sobre sus fundamentos.","ref":"/docs/contenedores/docker/fundamentos/","tags":["docker","contenedores"],"title":"Fundamentos"},{"body":"TODO\n","categories":"","description":"","excerpt":"TODO\n","ref":"/docs/contenedores/kubernetes/fundamentos/","tags":["kubernetes","devops"],"title":"Fundamentos"},{"body":"En la parte de reconocimiento o fingerprinting, se busca obtener información de los objetivos, para ello se utilizan herramientas como nmap, que nos permite obtener información de los puertos abiertos, servicios, versiones, etc.\nLa mayoría de sistemas operativos enfocados en pentesting tienen instalado nmap, por lo que no es necesario instalarlo. Por si no estuvieras utilizando kalilinux, parrot, blackarch… etc, podrías instalarlo de la siguiente manera.\nInstalación En sistemas basados en Debian, podrías instalarlo de la siguiente manera.\nsudo apt install nmap En el caso de sistemas basados en Arch, podrías instalarlo de la siguiente manera.\nsudo pacman -S nmap Para sistemas con paquetes rpm, podrías instalarlo de la siguiente manera.\nsudo dnf install nmap Y por último, para sistemas con paquetería yum, podrías instalarlo de la siguiente manera.\nsudo yum install nmap Descubrimiento de hosts Los primero que haremos será descubrir los hosts que están en la red, para ello utilizaremos el comando nmap, con el parámetro -sn, que nos permite realizar un escaneo ping, para descubrir los hosts que están en la red.\nnmap -sn \u003crango de ips\u003e Los ragos en de IPs en nmap, se pueden definir de la siguiente manera.\nnmap -sn 192.168.1.0-254 # Rango de IPs específico nmap -sn 192.168.0-32.0-254 # Múltiples rangos específicos nmap -sn 192.168.1.0/24 # Rango de IPs con máscara de red RECUERDA: Un escaneo ping utiliza el protocolo ICMP, el cual es bloqueado por muchos cortafuegos, por lo que no siempre funcionará. Como alternativa, podrías utilizar el comando arp-scan, que utiliza el protocolo ARP, el cual no es bloqueado por los cortafuegos.\narp-scan -l # Escaneo de hosts en la red Tipos de escaneos Nmap tiene múltiples opciones para realizar escaneos de puertos usando diferentes técnicas y combinaciones de flags en los paquetes TCP y UDP. En esta sección, se explicarán los escaneos más comunes.\nSyn Scan (Escaneo TCP SYN) El escaneo TCP SYN es el más común y el más rápido. Este escaneo envía paquetes TCP SYN a los puertos especificados y espera una respuesta. Si el puerto está abierto, el objetivo responde con un paquete TCP SYN/ACK. Si el puerto está cerrado, el objetivo responde con un paquete TCP RST. Si el puerto está filtrado, el objetivo no responde.\nnmap -sS \u003cip\u003e Connect Scan (Escaneo TCP Connect) El escaneo TCP Connect es similar al escaneo TCP SYN, pero en lugar de enviar paquetes TCP SYN, envía paquetes TCP SYN/ACK. Si el puerto está abierto, el objetivo responde con un paquete TCP ACK. Si el puerto está cerrado, el objetivo responde con un paquete TCP RST. Si el puerto está filtrado, el objetivo no responde.\nnmap -sT \u003cip\u003e Ack Scan (Escaneo TCP ACK) El escaneo TCP ACK es similar al escaneo TCP SYN, pero en lugar de enviar paquetes TCP SYN, envía paquetes TCP ACK. Si el puerto está abierto, el objetivo responde con un paquete TCP RST. Si el puerto está cerrado, el objetivo responde con un paquete TCP RST. Si el puerto está filtrado, el objetivo no responde.\nnmap -sA \u003cip\u003e Window Scan (Escaneo TCP Window) El escaneo TCP Window es similar al escaneo TCP SYN, pero en lugar de enviar paquetes TCP SYN, envía paquetes TCP SYN/ACK con el flag de ventana en 0. Si el puerto está abierto, el objetivo responde con un paquete TCP RST. Si el puerto está cerrado, el objetivo responde con un paquete TCP RST. Si el puerto está filtrado, el objetivo no responde.\nnmap -sW \u003cip\u003e Null Scan (Escaneo TCP Null) El escaneo TCP Null es similar al escaneo TCP SYN, pero en lugar de enviar paquetes TCP SYN, envía paquetes TCP con todos los flags en 0. Si el puerto está abierto, el objetivo responde con un paquete TCP RST. Si el puerto está cerrado, el objetivo responde con un paquete TCP RST. Si el puerto está filtrado, el objetivo no responde.\nnmap -sN \u003cip\u003e Fin Scan (Escaneo TCP Fin) El escaneo TCP Fin es similar al escaneo TCP SYN, pero en lugar de enviar paquetes TCP SYN, envía paquetes TCP FIN. Si el puerto está abierto, el objetivo responde con un paquete TCP RST. Si el puerto está cerrado, el objetivo responde con un paquete TCP RST. Si el puerto está filtrado, el objetivo no responde.\nnmap -sF \u003cip\u003e Xmas Scan (Escaneo TCP Xmas) El escaneo TCP Xmas es similar al escaneo TCP SYN, pero en lugar de enviar paquetes TCP SYN, envía paquetes TCP con los flags de urgente, push y fin en 1. Si el puerto está abierto, el objetivo responde con un paquete TCP RST. Si el puerto está cerrado, el objetivo responde con un paquete TCP RST. Si el puerto está filtrado, el objetivo no responde.\nnmap -sX \u003cip\u003e Idle Scan (Escaneo TCP Idle) El escaneo TCP Idle es similar al escaneo TCP SYN, pero en lugar de enviar paquetes TCP SYN, envía paquetes TCP con el flag de urgente en 1. Si el puerto está abierto, el objetivo responde con un paquete TCP RST. Si el puerto está cerrado, el objetivo responde con un paquete TCP RST. Si el puerto está filtrado, el objetivo no responde.\nnmap -sI \u003cip\u003e UDP Scan (Escaneo UDP) El escaneo UDP es similar al escaneo TCP SYN, pero en lugar de enviar paquetes TCP SYN, envía paquetes UDP. Si el puerto está abierto, el objetivo responde con un paquete UDP. Si el puerto está cerrado, el objetivo no responde. Si el puerto está filtrado, el objetivo no responde.\nnmap -sU \u003cip\u003e Escaneo de puertos Nmap tiene múltiples opciones para realizar escaneos como ya hemos visto. Si no especificamos nada, por defecto, nmap realiza un escaneo de puertos TCP SYN.\nEl escaneo básico que podríamos hacer es el siguiente:\nnmap \u003cip\u003e Si quisiéramos realizar un escaneo de puertos UDP, podríamos hacerlo de la siguiente forma:\nnmap -sU \u003cip\u003e Filtrado de puertos Podemos filtrar los puertos que queremos escanear de la siguiente forma:\nnmap -p 1-100 \u003cip\u003e También podríamos especificar puertos individuales:\nnmap -p 1,2,3,4,5 \u003cip\u003e O una combinación de ambos:\nnmap -p 1-100,200,300,400 \u003cip\u003e Banner Grabbing o obtención de banners Nmap se conecta a un puerto y obtiene la información que nos devuelve. Esta información se conoce como banner. Podemos obtener esta información de la siguiente forma:\nnmap -sV \u003cip\u003e Escaneo de puertos con scripts Nmap tiene una gran cantidad de scripts que podemos utilizar para realizar escaneos más avanzados. Podemos ver la lista de scripts disponibles con el siguiente comando:\nnmap --script-help Para ejecutar un script en concreto, podemos hacerlo de la siguiente forma:\nnmap --script=\u003cscript\u003e \u003cip\u003e Algunos scripts tienen argumentos que podemos pasarle. Para ver los argumentos de un script, podemos hacerlo de la siguiente forma:\nnmap --script-help=\u003cscript\u003e Cuando tenemos claro como funciona un script, podemos ejecutarlo de la siguiente forma:\nnmap --script=\u003cscript\u003e --script-args=\u003cargumentos\u003e \u003cip\u003e Por último, nmap tiene una opción para ejecutar automáticamente los scripts recomendados a cada puerto automáticamente (Es muy lento y poco efectivo si la máquina tiene muchos puertos abiertos). Podemos hacerlo de la siguiente forma:\nnmap -sC \u003cip\u003e Combinaciones comunes Estos serían algunos ejemplos de escaneos más comunes que podríamos realizar:\nnmap -v -p- \u003cip\u003e # Escaneo de todos los puertos de una máquina Cuando sabemos todos los puertos abiertos de una máquina, podemos realizar un escaneo de servicios para obtener información más detallada de cada uno de ellos. Es importante no volver a escanear todos los puertos y centrarnos solo en los abiertos para ahorrar tiempo y recursos. Podemos hacerlo de la siguiente forma:\nnmap -v -sV -p \u003cpuertos abiertos\u003e \u003cip\u003e # Escaneo de servicios de los puertos abiertos de una máquina ","categories":"","description":"Explicación y enumeración de información genérica con la herramienta nmap","excerpt":"Explicación y enumeración de información genérica con la herramienta …","ref":"/docs/pentesting/reconocimiento/nmap/","tags":["pentesting","reconocimiento"],"title":"General - Nmap"},{"body":"Estos comandos nos permiten guardar y cargar imágenes de docker. Aunque lo común es que las imágenes se descarguen de un repositorio, en ocasiones puede ser útil guardarlas en un fichero y cargarlas en otro equipo mediante ficheros tar.\nGuardar una imagen docker save -o \u003cnombre_imagen\u003e.tar \u003cnombre_imagen\u003e Cargar una imagen docker load -i \u003cnombre_imagen\u003e.tar También puedes ver un vídeo de youtube sobre este tema:\n","categories":"","description":"\"Guía de comandos generales de docker\" \n","excerpt":"\"Guía de comandos generales de docker\" \n","ref":"/docs/contenedores/docker/cargar_guardar/","tags":["docker","contenedores"],"title":"Save y Load"},{"body":"Git es un sistema muy estricto y metódico diseñado para garantizar la integridad de nuestro código a lo largo de infinidad de versiones y cambios generados por múltiples programadores.\nEs normal y frecuente en estos procesos equivocarnos, como por ejemplo, escribir el mensaje que no era en un commit, olvidarse de añadir algún archivo en un commit o añadir el que no querías… etc.\nPor suerte, para todos ellos hay solución y veremos diferentes comandos que git ofrece para arreglar errores.\nVamos a ir viendo las diferentes opciones agrupadas por comandos:\nAmmend - Enmendar el commit más reciente Esta opción trabaja en conjunto con el comando commit y es una manera práctica de modificar el commit más reciente. Te permite combinar los cambios prepados con el commit anterior en en lugar de crear uno nuevo.\nSin embargo, este comando no se limita a alterar el cambio más reciente, sino que lo reemplaza por completo. Importante tenerlo en cuenta sobre todo en repositorios públicos cuyos commits puedan ser dependencias de otras ramas o herramientas.\nUso básico Supón que acabas de terminar un commit y quieres modificar su mensaje porque has puesto lo que no debías. Podrías ejecutar esto:\ngit commit --amend Tras ejecutarlo se nos mostrará el editor de texto seleccionado en git para editar el menaje del último commit. En esta entrada puedes ver como cambiar el editor de texto que git usará para estas labores.\nAñadir archivo al último commit Podría pasar también, que te hubieras dejado de añadir un archivo al último commit. Es cierto que podrías crear un nuevo commit pero queda más limpio si corriges el anterior. Para ello añadiríamos el o los archivos que nos hubieramos dejado en el anterior commit usando el comando “add”:\ngit add \u003cfichero\u003e Y luego, volveríamos a repetir el “ammend”:\ngit commit --amend Esto nos permitiría añadir el archivo los archivos omitidos en el commit anterior y corregir el mensaje si fuera necesario.\nReset - Revertir cambios de un commit Que pasaría si hacemos lo contrario que en punto anterior, en vez de añadir un archivo, lo queremos eliminar. Muchas veces por error incluimos en el repositorio un archivo que no queríamos dado que contienen secretos o información importante.\nBorrar del stage area Si solo lo hemos mandado al “stage” area, podríamos quitarlo de ahí con el siguiente comando:\ngit reset \u003cfichero a eliminar\u003e Revertir un commit En caso de haberlo añadido al “stage area” y haber hecho un commit, podríamos revertir el cambio con el siguiente comando:\ngit reset --soft HEAD~1 #Revertir el último commit git reset \u003carchivo a eliminar\u003e #Resturar el archivo del commiteado por error rm \u003carchivo a eliminar\u003e #Eliminar el archivo del repositorio git commit #Hacer el commit Esto revertirá el último commit, eliminará el archivo y añadira un nuevo commit en su lugar.\nVolver a un estado anterior tras muchos cambios Podría pasar, ya en el peor de los casos, que hubieramos hecho muchos cambios mal y quisieramos volver a un estado anterior. Primero podríamos consultar el historial de commits con el comando “log” o “reflog” y ver la referencia del commit al que queremos volver:\ngit log git reflog Con la referencia del commit al que queremos volver, podemos revertir el commit con el siguiente comando:\ngit reset HEAD@{Referencia} Volver al último commit rápidamente Para volver al último commit sin tener que consultar el historial, podemos usar el comando “reset” con el parámetro “–hard”:\ngit reset --hard HEAD Branch - Errores en ramas En este apartado veremos los errores más comunes que pueden ocurrir en las ramas.\nNombre de rama equivocado Es frecuente que con las prisas escribamos el nombre de una rama con un nombre equivocado. Aquí la solución es simple, dentro del comando branch esta el parámetro “-m” que nos permite cambiar el nombre de la rama:\ngit branch -m nombre-rama-equivocada nombre-rama-correcta Commit a la rama principal Podríamos hacer sin querer un commit en la rama principal, por ejemplo, main cuando nuestro sistema de organización es hacer ramas distintas para cada característica nueva que se desarrolla o trabajar primero en develop y luego integrar los cambios en main.\nEn varios pasos podríamos crear una rama con todos los cambios que acabamos de generar y luego, en el siguiente paso, resetear la rama principal al commit anterior:\ngit branch nombre-rama-nueva-con-los-cambios #Creamos una rama con los cambios git reset HEAD~ --hard #Reseteamos la rama principal al commit anterior git checkout nombre-rama-nueva-con-los-cambios #Cambiamos a la rama nueva En el último paso, nos cambiaríamos a la rama nueva para seguir trabajando con los cambios habiendo dejado limpia la rama principal.\nEliminar secretos tanto en local como en remoto En este apartado veremos como eliminar los secretos de un repositorio local o remoto. Es muy frecuente sin querer introducir tokens o contraseñas en un repositorio. Aunque los borremos posteriormente, estos, se mantendrán en el historial de git.\nPodemos borrar un archivo de toda la historia con el siguiente comando:\ngit filter-branch --force --index-filter \\ \"git rm --cached --ignore-unmatch ARCHIVO-SENSIBLE\" \\ --prune-empty --tag-name-filter cat -- --all git push --force --verbose --dry-run git push --force ","categories":"","description":"En git es muy común equivocarse y, dada su funcionamiento, puede ser tedioso corregir ciertos descuidos. En este artículo trataremos los errores más comunes","excerpt":"En git es muy común equivocarse y, dada su funcionamiento, puede ser …","ref":"/docs/programacion/git/solucionar_errores/","tags":["git","errores","restaurar"],"title":"Solucionar errores"},{"body":"","categories":"","description":"Sección dedicada a la parte de pentesting","excerpt":"Sección dedicada a la parte de pentesting","ref":"/docs/pentesting/","tags":"","title":"Pentesting"},{"body":"","categories":"","description":"Seccion dedicada al reconocimiento activo de información contra un sistema. \n","excerpt":"Seccion dedicada al reconocimiento activo de información contra un …","ref":"/docs/pentesting/privilegios/","tags":["privilegios","pentesting"],"title":"Escalada privilegios"},{"body":"","categories":"","description":"Seccion dedicada al reconocimiento activo de información contra un sistema. \n","excerpt":"Seccion dedicada al reconocimiento activo de información contra un …","ref":"/docs/pentesting/reconocimiento/","tags":["pentesting"],"title":"Reconocimiento"},{"body":"Elegir el editor de commit por defecto Dependiendo del sistema operativo en el que nos encontremos Git utilizara un editor u otro para los mensajes de commit en el terminal. En algunos por defecto es nano, en otros vim, gedit… etc. Con el siguiente comando puedes elegir el que más se adapte a tus gustos y necesidades.\nEn mi caso, prefiero Vim y usaría el siguiente comando:\ngit config --global core.editor \"vim\" También serviría para Neovim usando:\ngit config --global core.editor \"nvim\" Si quisieras usar nano sería tan fácil como usar el siguiente:\ngit config --global core.editor \"nano\" Configurar identidad Si es la primera vez que utilizamos git en un sistema, al hacer un commit, es obligatorio que este quere registrado con el nombre y email de un usuario. Se puede configurar con los siguientes comandos:\ngit config --global user.name \"John Doe\" git config --global user.email \"johndoe@example.com\" ","categories":"","description":"Configuraciones básicas y esenciales\n","excerpt":"Configuraciones básicas y esenciales\n","ref":"/docs/programacion/git/configurar_editor_commits/","tags":["git","configuracion"],"title":"Configuración"},{"body":"Introducción Los contenedores nos han permitido la facilidad y comodidad de empaquetar nuestras aplicaciones y servicios, y también nos permiten asegurar que se ejecuten de forma segura. Sin embargo, las imágenes se contruyen con muchos componentes de terceros sobre los que no tenemos visibilidad. Para esta labor tenemos diferentes herramientas que nos ayudan a analizar la seguridad de nuestros contenedores.\nHerramientas Snyk - Docker Desktop Es sin duda una de las más desconocidas debido a su reciente implementación en la plataforma de Docker pero, dada su integración nativa y que no es necesario realizar instalaciones adicionales, es una herramienta más que adecuada.\nTiene unas limitaciones de uso mensual pero podemos iniciar sesión con una cuenta gratuita para ampliarlo. Snyk.\nPodemos utilizar esta herramienta simplemente escribiendo:\ndocker scan \u003cimagen\u003e Otra forma de utilizarla, es con el parámetro “–dependency-tree”, el cuál muestra todo el árbol de dependencias de la images.\ndocker scan --dependency-tree \u003cimagen\u003e ├─ ca-certificates @ 20200601~deb10u1 │ └─ openssl @ 1.1.1d-0+deb10u3 │ └─ openssl/libssl1.1 @ 1.1.1d-0+deb10u3 ├─ curl @ 7.64.0-4+deb10u1 │ └─ curl/libcurl4 @ 7.64.0-4+deb10u1 │ ├─ e2fsprogs/libcom-err2 @ 1.44.5-1+deb10u3 │ ├─ krb5/libgssapi-krb5-2 @ 1.17-3 │ │ ├─ e2fsprogs/libcom-err2 @ 1.44.5-1+deb10u3 │ │ ├─ krb5/libk5crypto3 @ 1.17-3 │ │ │ └─ krb5/libkrb5support0 @ 1.17-3 │ │ ├─ krb5/libkrb5-3 @ 1.17-3 │ │ │ ├─ e2fsprogs/libcom-err2 @ 1.44.5-1+deb10u3 │ │ │ ├─ krb5/libk5crypto3 @ 1.17-3 │ │ │ ├─ krb5/libkrb5support0 @ 1.17-3 │ │ │ └─ openssl/libssl1.1 @ 1.1.1d-0+deb10u3 │ │ └─ krb5/libkrb5support0 @ 1.17-3 │ ├─ libidn2/libidn2-0 @ 2.0.5-1+deb10u1 │ │ └─ libunistring/libunistring2 @ 0.9.10-1 │ ├─ krb5/libk5crypto3 @ 1.17-3 │ ├─ krb5/libkrb5-3 @ 1.17-3 │ ├─ openldap/libldap-2.4-2 @ 2.4.47+dfsg-3+deb10u2 │ │ ├─ gnutls28/libgnutls30 @ 3.6.7-4+deb10u4 │ │ │ ├─ nettle/libhogweed4 @ 3.4.1-1 │ │ │ │ └─ nettle/libnettle6 @ 3.4.1-1 │ │ │ ├─ libidn2/libidn2-0 @ 2.0.5-1+deb10u1 │ │ │ ├─ nettle/libnettle6 @ 3.4.1-1 │ │ │ ├─ p11-kit/libp11-kit0 @ 0.23.15-2 │ │ │ │ └─ libffi/libffi6 @ 3.2.1-9 │ │ │ ├─ libtasn1-6 @ 4.13-3 │ │ │ └─ libunistring/libunistring2 @ 0.9.10-1 │ │ ├─ cyrus-sasl2/libsasl2-2 @ 2.1.27+dfsg-1+deb10u1 │ │ │ └─ cyrus-sasl2/libsasl2-modules-db @ 2.1.27+dfsg-1+deb10u1 │ │ │ └─ db5.3/libdb5.3 @ 5.3.28+dfsg1-0.5 │ │ └─ openldap/libldap-common @ 2.4.47+dfsg-3+deb10u2 │ ├─ nghttp2/libnghttp2-14 @ 1.36.0-2+deb10u1 │ ├─ libpsl/libpsl5 @ 0.20.2-2 │ │ ├─ libidn2/libidn2-0 @ 2.0.5-1+deb10u1 │ │ └─ libunistring/libunistring2 @ 0.9.10-1 │ ├─ rtmpdump/librtmp1 @ 2.4+20151223.gitfa8646d.1-2 │ │ ├─ gnutls28/libgnutls30 @ 3.6.7-4+deb10u4 │ │ ├─ nettle/libhogweed4 @ 3.4.1-1 │ │ └─ nettle/libnettle6 @ 3.4.1-1 │ ├─ libssh2/libssh2-1 @ 1.8.0-2.1 │ │ └─ libgcrypt20 @ 1.8.4-5 │ └─ openssl/libssl1.1 @ 1.1.1d-0+deb10u3 ├─ gnupg2/dirmngr @ 2.2.12-1+deb10u1 ","categories":"","description":"Herramientas que nos permiten analizar la seguridad en nuestros contenedores.","excerpt":"Herramientas que nos permiten analizar la seguridad en nuestros …","ref":"/docs/contenedores/docker/analizar_contenedores/","tags":["docker","seguridad","vulnerabilidades"],"title":"Escáneres de vulnerabilidades"},{"body":"Introducción Los contenedores son procesos aislados que, por defecto, ¿se podrían considerar como seguros?. Su enfoque nos dice que sí pero existen muchos casos en los que, principalmente por malas configuraciones, podrían ser vulnerables.\nAislados pero no herméticos - Posibles malas configuraciones Tecnologías de contenedores como Docker, LXC, LXD, etc.. permiten a los usuarios lanzar un proceso aislado pero, existen multiples funcionalidades, que podrían comprometer la aplicación en mayor o menor medida:\nMontaje de volúmenes Esta funcionalidad permite montar un volumen en un contenedor. Un volumen puede ser una carpeta o archivo en el sistema de archivos del host o un filesystem aislado que cree docker junto con el contenedor. Los volúmenes se suelen utilizar para dar persistencia a los datos de un contenedor y así evitar cuando se para o se vuelve a desplegar un contenedor los datos ser pierdan.\nCuando montamos como volumen parte del host en un contenedor tenemos que tener en cuenta el usuario que ejecuta el engine de docker y el grupo de permisos y, por otra parte, el usuario que ejecuta el contenedor. Si montamos ficheros del hosts sensibles y los montamos en cualquier contenedor que ejecute el usuario root, este usuario sería capaz de acceder a los ficheros. Es importante que los contenedores no utilicen volúmenes sensibles, montar ficheros o directorios muy específicos y que los contenedores no utilicen el usuario root.\nTambién se podría cambiar el usuario que ejecuta el engine de docker pero acarreo muchos problemas de funcionamiento a día de hoy y no lo recomiendo. Lo ideal es crear un usuario en el host y asignarle la propiedad de los archivos que queremos montar en el contenedor y, a su vez, ejecutar el contenedor con dicho usuario.\nSi por ejemplo ejecutamos un contenedor montado un directorio del host (en este caso /etc) y ejecutamos el contenedor como root, este podrá leerlo y modificarlo sin problemas.\ndocker run -it -v /etc:/host busybox sh cat /host/shadow # Comando dentro del contenedor root:*:18970:0:99999:7::: ... systemd-timesync:*:18970:0:99999:7::: systemd-network:*:18970:0:99999:7::: systemd-resolve:*:18970:0:99999:7::: strike:\u003cCENSORED\u003e:18986:0:99999:7::: ... En mi linux tengo un usuario strike que no tiene permiso de root. Vamos a ejecutar este contenedor con este usuario para entender que docker arrastra los permisos de archivos del host a los contenedores.\nPrimero hago un cat /etc/passwd para obtener el uid de mi usuario strike:\ncat /etc/passwd root:x:0:0:root:/root:/bin/bash daemon:x:1:1:daemon:/usr/sbin:/usr/sbin/nologin ... strike:x:1000:1000:,,,:/home/strike:/usr/bin/zsh ... Sabiendo que el uid de mi usuario strike es 1000, vamos a ejecutar el contenedor con este usuario (especificamos el usuario con el parámetro -u \u003cuid\u003e):\ndocker run -it -u 1000 -v /etc/:/host busybox sh cat /host/shadow # Comando dentro del contenedor\u003e $ docker run -it -u 1000 -v /etc/:/host busybox cat: cant open host/shadow: Permission denied / $ Es importante entender esto para no comprometer la seguridad de los archivos del host. Por eso hay que evitar utilizar el usuario root en los contenedores y, por otra parte, evitar montar ficheros sensibles.\nEjecución de contenedores en modo privilegiado Este modo de ejecución permite a un contenedor acceder a ciertos recursos que, por defecto, estan restringidos. Este modo se activa con la opción --privileged en el comando run de un contenedor.\nEsto permitiría acceder al hardware del host y los recursos de red. Podría montar dispositivos como USB, interfaces de red.. etc.\nDicho esto, la forma más sencilla de escalar privilegios es montando el disco del host y buscando secretos u otros accesos:\n# Dentro del contenedor privilegiado suponiendo que el disco del hosts se llama /dev/sda mkdir -p /mnt/hola mount /dev/sda1 /mnt/hola Hay más formas pero he documentado la más sencilla e interesante. En esta referencia podéis encontrar más formas: Documentación de Hacktricks\nEscalado a través del grupo de docker Imaginaros ahora que hemos accedido a un hosts del que no somos root pero tiene docker instalado y nuestro usuario tiene permisos para ejecutar docker. Podríamos ejecutar un contenedor en modo privilegiado para acceder a los recursos del host y conseguir escalar.\ndocker run -it -v /:/host/ debian chroot /host/ bash Host vulnerable Aunque no es muy frecuente, aparecen vulnerabilidades en las tecnologías, ya sea en docker, el kernel de linux, etc. que puede permitir que un host sea vulnerado.\nComo siempre, la recomendación es tener actualizado el kernel de linux a la última versión estable, así como también el engine de docker o la tecnología de contenedores que estés utilizando.\nSecretos o variables de entorno El objetivo de crear una imagen de contenedor es paquetizar tu software para que esté listo para arrancar al instante, eso sí, siempre requiere una configuración en la mayoría de los casos. Si es una base de datos, necesitará definir usuarios y contraseñas, si es una página web, necesitará definir una configuración de servidor, etc.\nMeter esos secretos en la imagen sería un fallo de seguridad y además rompería la versatilidad de coger una imagen que pueda funcionar en diferentes casos. Para configurar un contenedor, lo más común, es añadir variables de entono a la imagen en tiempo de ejecución.\nPor ejemplo, para configurar un servidor de base de datos de mariadb y que funcione en un contenedor tenemos que definir al menos la contraseña del usuario root:\ndocker run --name some-mariadb -e MARIADB_ROOT_PASSWORD=contraseña -d mariadb:latest Muchas aplicaciones no gestionan esto correctamente, es decir, no limpian las variables de entorno que datos sensibles una vez que cargan los secretos en memoria.\nPor eso, uno de los primeros pasos de un pentester es consultar el environment del contenedor:\n# Simplemente entrando al terminal del contenedor y ejecutando el comando env dentro del contenedor \u003e $ docker exec -it some-mariadb /bin/bash root@5f3f1ce5b7e1: env HOSTNAME=5f3f1ce5b7e1 PWD=/ HOME=/root MARIADB_VERSION=1:10.7.3+maria~focal GOSU_VERSION=1.14 TERM=xterm MARIADB_MAJOR=10.7 SHLVL=1 MARIADB_ROOT_PASSWORD=contraseña PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin _=/usr/bin/env Podríamos ver que el credencial sigue ahí una vez arrancado el contenedor.\nTambién podríamos ver las variables de entorno desde fuera con el siguiente comando:\ndocker container inspect --format '{{.Config.Env}}' \u003cnombre contenedor\u003e Montaje del socket Cuando utilizamos diferentes comandos de docker, como por ejemplo docker run, lo que hace el cliente de docker es comunicarse con el engine mediante un socket.\nEn algunos escenarios en los que se necesita ejecutar comandos de docker dentro de un contenedor, por ejemplo, un orquestador de servicios montado sobre docker que necesite levantar otros contenedores a su vez.\nEjemplo de una herramienta Jenkins que orquesta el despliegue de contenedores. A su vez, esta herramienta también está dentro de un contenedor y tiene el socket de docker montado. Por último, tanto el contenedor del front como el del jenkins están expuestos a internet.\nSi este orquestador es vulnerado por un atacante, teniendo acceso al socket del docker engine (que recordemos que se ejecuta con el usuario root), podría montar el sistema de archivos del host con permisos de root fácilmente.\nPor ejemplo, para docker:\ndocker run -it -v /:/host/ debian:11 chroot /host/ bash Pivotar a otros contenedores de la red. Docker por defecto crea una red donde ejecuta todos estos contenedores. Si no especificamos nada, todos los contenedores se ejecutan en la misma red. Esto puede permitir que se comprometa las seguridad de otros contenedores de la red.\nSupongamos el escenario anterior del jenkins con el socket de docker montado. Imaginaros que este caso pudiésemos vulnerar el back de la aplicación. Este no tendría acceso directamente al socket de docker pero podríamos intentar pivotar a otros contenedores de la red.\nPara solventar esto, en el momento de la creación de un contenedor, podemos especificar una red diferente. Por ejemplo, para aislar la aplicación web completamente del jenkins:\n# Primero creamos la red docker network create \u003cnombre de la red\u003e # Creamos el front y el back de la aplicación y los añadimos a la nueva red docker run -d --name front --network \u003cnombre de la red\u003e \u003cimagen del front\u003e docker run -d --name back --network \u003cnombre de la red\u003e \u003cimagen del back\u003e Así evitaríamos que aunque una aplicación sea vulnerada no afecte al resto de contenedor y servicios que estén desplegados en el mismo host.\nHerramientas Deepce Esta herramienta permite enumerar y escalar privilegios en contenedores. Está escrita puramente en sh sin ninguna dependencia pero, para aprovechar todas las funcionalidades, usa herramientas como curl, nmap, nslookup y dig si estan disponibles.\nEste es su repositorio de github: https://github.com/stealthcopter/deepce\nLa descarga de la aplicación se puede hacer:\n# Con wget wget https://github.com/stealthcopter/deepce/raw/main/deepce.sh # Con curl curl -sL https://github.com/stealthcopter/deepce/raw/main/deepce.sh -o deepce.sh Una vez descargado, le asignamos permisos de ejecución y lo ejecutamos:\nchmod +x deepce.sh ./deepce.sh ","categories":"","description":"","excerpt":"Introducción Los contenedores son procesos aislados que, por defecto, …","ref":"/docs/pentesting/privilegios/contenedores/","tags":["pentesting","contenedores"],"title":"Contenedores"},{"body":"Git tiene un sistema de funcionamiento muy estricto para evitar conflictos y ayudarnos a mantener nuestro bien versionado. Para ello, solo a un proceso realziar cambios a la vez para mantener la integridad de la información.\nCuando realizamos cualquier tarea en git, un commit, push, pull… este genera un archivo llamado “index.lock” y lo guarda dentro de la carpeta “.git” en la raiz del repositorio.\nEste archivo bloquea el repositorio ante cualquier otro acceso o proceso simult�neo que quiera realizar cambios. En algunos casos, poco frecuentes, puede pasar que una acción o tarea nunca termine ( por fallo del SO u otros) y el repositorio se quede bloqueado.\nSi tenemos claro lo que estamos haciendo, podríamos borrar simplemente este archivo con el comando:\nrm .git/index.lock Así de simple conseguiríamos quitar el bloqueo de git pero atención que no tengamos otro proceso ejecutando alguna tarea sobre git o podríamos corromper datos del repositorio.\n","categories":"","description":"Error index lock \n","excerpt":"Error index lock \n","ref":"/docs/programacion/git/index_lock/","tags":["git","errores"],"title":"Index lock"},{"body":"La instalación de Kubernetes en un cluster de nodos puede ser un proceso complejo. En esta guía agruparé distintos tutoriales de instalación con distintos motores de contenedores y distintos sistemas operativos.\nUbuntu Server 22.04 con Containerd Nodo maestro Instalar requisitos previos: apt install curl apt-transport-https vim git wget gnupg2 \\ software-properties-common apt-transport-https ca-certificates uidmap -y Desactivar swap: swapoff -a sed -i '/swap/s/^\\(.*\\)$/#\\1/g' /etc/fstab # Auto comenta la línea de swap en fstab Cargar módulos necesarios: modprobe overlay modprobe br_netfilter sudo tee /etc/modules-load.d/k8s.conf \u003c\u003cEOF overlay br_netfilter EOF Configurar módulos: cat \u003c\u003c EOF | tee /etc/sysctl.d/kubernetes.conf net.bridge.bridge-nf-call-ip6tables = 1 net.bridge.bridge-nf-call-iptables = 1 net.ipv4.ip_forward = 1 EOF sysctl --system # Aplica la configuración Añadir al fichero `/etc/hosts’ la IP y el nombre de la máquina (ATENCIÓN: Pon la IP del nodo master si esta configurando un worker). Con esto podremos configurar el cluster con el nombre de la máquina en vez de la IP. echo \"\u003cIP\u003e \u003cNOMBRE\u003e\" \u003e\u003e /etc/hosts Instalar containerd: curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add - add-apt-repository \"deb [arch=amd64] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable\" apt update \u0026\u0026 apt install containerd.io -y Configurar containerd: mkdir -p /etc/containerd containerd config default | sudo tee /etc/containerd/config.toml Dentro del fichero /etc/containerd/config.toml hay que cambiar la línea SystemdCgroup = false por SystemdCgroup = true.\nIniciar containerd: systemctl enable containerd systemctl restart containerd Instalar kubeadm, kubelet y kubectl: # Agrergar repositorio de Kubernetes echo \"deb https://apt.kubernetes.io/ kubernetes-xenial main\" | tee -a /etc/apt/sources.list.d/kubernetes.list # Instalar clave pública de Kubernetes curl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add # Instalar paquetes apt update \u0026\u0026 apt install -y kubelet kubeadm kubectl # Especificar versión de Kubernetes, por ejemplo: #apt install -y kubelet=1.24.1-00 kubeadm=1.24.1-00 kubectl=1.24.1-00 # Bloquear actualizaciones automáticas apt-mark hold kubelet kubeadm kubectl # Iniciar kubelet systemctl enable kubelet Iniciar cluster master: kubeadm init --pod-network-cidr=\u003crango de IPs para pods\u003e --control-plane-endpoint=\u003cNombre añañadido en /etc/hosts\u003e:6443 Configurar kubectl: mkdir -p $HOME/.kube cp -i /etc/kubernetes/admin.conf $HOME/.kube/config chown $(id -u):$(id -g) $HOME/.kube/config Instalar red de pods: Esta paso es importante, tendremos que editar el archivo de configuración de la red de pods para que funcione correctamente. En este caso usaremos Calico, pero puedes usar cualquier otra red de pods que quieras. Debemos especificar en la instrucción CALICO_IPV4POOL_CIDR el rango de IPs que hemos especificado en el paso 9. wget https://docs.projectcalico.org/manifests/calico.yaml # Editar el archivo de configuración de Calico descomentando las líneas. Quedando así: - name: CALICO_IPV4POOL_CIDR value: \"rango de IPs para pods\" Por ejemplo:\n# The default IPv4 pool to create on startup if none exists. Pod IPs will be # chosen from this range. Changing this value after installation will have # no effect. This should fall within `--cluster-cidr`. - name: CALICO_IPV4POOL_CIDR value: \"192.168.0.0/16\" # The default IPv4 pool to create on startup if none exists. Pod IPs will be # chosen from this range. Changing this value after installation will have # no effect. This should fall within `--cluster-cidr`. Aplicar red de pods: kubectl apply -f calico.yaml Nodo worker Repeticiones de los pasos 1 a 9 del nodo maestro. Esta vez en el fichero /etc/hosts tenemos que añadir la IP y el nombre del nodo maestro.\nIniciar cluster worker: kubeadm join \u003cNombre del nodo maestro\u003e:6443 --token \u003ctoken\u003e --discovery-token-ca-cert-hash sha256:\u003chash\u003e El token se puede obtener con el comando kubeadm token list lanzado en el nodo maestro. Si hubiera expirado, se puede generar uno nuevo con kubeadm token create.\nEl hash se puede obtener con el siguiente comando de openssl. Lo lanzamos en el nodo maestro:\nopenssl x509 -pubkey -in /etc/kubernetes/pki/ca.crt | openssl rsa -pubin -outform der 2\u003e/dev/null | openssl dgst -sha256 -hex | sed 's/^.* //' ","categories":"","description":"","excerpt":"La instalación de Kubernetes en un cluster de nodos puede ser un …","ref":"/docs/contenedores/kubernetes/instalacion/","tags":["kubernetes","devops"],"title":"Instalación"},{"body":"","categories":"","description":"Sección dedicada a la parte de programación.\n","excerpt":"Sección dedicada a la parte de programación.\n","ref":"/docs/programacion/","tags":"","title":"Programación"},{"body":"Utilidades de red Existen varias herramientas que nos ayudan a trabajar con redes:\n# Ping - comprueba la conexión con un hosts y si está acttivo ping -c 4 google.com # Con el -c 4 el número de veces que se ejecuta el ping # Traceroute - identifica la ruta que se ha recorrido para llegar a un host traceroute google.com # Netstat - muestra los puertos abiertos en el sistema netstat -l # ARP - muestran la tabla ARP del sistema que actúa como una cache. arp -a # Muestra la relación entre direcciones IP y direcciones MAC Configuración de una red - Comando IP Con el comando ip podemos alterar la configuración de una interfaz de red. Para ello hay múltiples opciones de este comando que debemos conocer previamente:\nListar las interfaces de red, información y estado:\nip addr # O su versión corta ip a Ver la configuración de una interfaz de red:\nip addr show ens33 # O su versión corta ip a s ens33 Habilitar o deshabilitar una interfaz de red:\n#Habilitar ip link set ens33 up #Deshabilitar ip link set ens33 down El estado de una interfaz de red lo podríamos ver tras el state de la configuración de la interfaz marcado como UP o DOWN.:\nip a s ens33 ens33: \u003cBROADCAST,MULTICAST,UP,LOWER_UP\u003e mtu 1500 qdisc mq state UP group default qlen 1000 link/ether 00:15:5d:cc:35:ff brd ff:ff:ff:ff:ff:ff inet 172.17.71.94/20 brd 172.17.79.255 scope global eth0 valid_lft forever preferred_lft forever inet6 fe80::215:5dff:fecc:35ff/64 scope link valid_lft forever preferred_lft forever Asignar una dirección IP a una interfaz de red Para asignar una dirección IP a una interfaz de red debemos usar el comando ip addr add:\nip addr add \u003cIP\u003e/\u003cMASCARA\u003e dev \u003cINTERFACE\u003e #Por ejemplo: ip addr add 192.168.1.56/255.255.255.0 dev ens33 #o ip addr add 192.168.1.56/24 dev ens33 También podríamos añadir la dirección de broadcast:\nip addr add \u003cIP\u003e/\u003cMASCARA\u003e broadcast \u003cBROADCAST\u003e dev \u003cINTERFACE\u003e # O su versión corta ip a a \u003cIP\u003e/\u003cMASC Comprobando la puerta de enlace Para comprobar si una interfaz de red tiene una puerta de enlace activa podemos usar el comando ip route show:\nip route show También podemos obtener la información de enrutamiento a una IP particular usando:\nip route get \u003cIP\u003e Configuración de una red - NetworkManager Antes de comenzar, vamos a parar el servicio ’network-manager’ para que no interfiera con nuestra configuración. Este servicio es el encargado de gestionar las redes. Esto lo podemos hacer con el comando:\nsystemctl stop network-manager Para configurar una red en Ubuntu Server tendremos que crear un fichero llamado 01-netcfg.yaml en la carpeta /etc/netplan. El fichero especifica por cada red si queremos utilizar DHCP, dirección IP manual (en caso de no usar DHCP), gateays y servidores DNS nameservers. Ejemplo (obviar las líneas que comienzan por # ya que son comentarios para explicar el fichero):\nnetwork: version: 2 renderer: NetworkManager # Se especifiaca cada una de las redes que queremos configurar ethernets: # Ejemplo de red con DHCP que recibirá la dirección IP automáticamente ens33: dhcp4: yes dhcp6: yes nameservers: addresses: [8.8.8.8, 8.8.4.4] # Ejemplo de una red con IP manual ens38: dhcp4: no dhcp6: no addresses: [192.168.1.120/24] # Se especifica la puerta de enlace. IP del router. gateway4: 192.168.1.1 nameservers: addresses: [8.8.8.8, 8.8.4.4] Una vez terminado de editar el fichero, tenemos que aplicar los cambios con el comando:\nnetplan apply Finalmente, volveríamos a arrancar el servicio ’network-manager’ para que los cambios surjan efecto:\nsystemctl start network-manager ","categories":"","description":"","excerpt":"Utilidades de red Existen varias herramientas que nos ayudan a …","ref":"/docs/unix/redes/","tags":["linux","redes"],"title":"Redes"},{"body":"Introducción SNMP o Simple Network Mangement Protocol es un protocolo usado para monitorizar los dispositivos de una red ( por ejemplo, routers, switches, impresoras, IoTs…). Las versiones 1,2 y 2c son bastante inseguras y transmiten la información en texto plano. Estos problemas se solucionaron con la versión 3. En cualquiera de los casos teniendo credenciales se puede lsitar información muy valiosa de un sistema.\nEnumeración Nmap tiene varios scripts para enumerar información sobre este protocolo.\nLo primero que tendremos que identificar es el protocolo y puerto. Por defecto, opera en el 161 UDP. Con NMAP podríamos lanzar un barrido a todos los puertos UDP con el siguiente comando:\nnmap -v -p- -sU \u003cObjetivo\u003e Una vez identificado el protocolo y puerto, especificamos a nmap el puesto concreto sobre el que operar:\nnmap -p161 -sU \u003cObjetivo\u003e Ahora toca utilizar los scripts de nmap. Podríamos dejarlo en modo automático con el parámetro -sC pero no es el método más eficaz dado que muchos de estos script requieren parámetros.\n","categories":"","description":"Explicación y enumeración de información sobre el protocolo SNMP","excerpt":"Explicación y enumeración de información sobre el protocolo SNMP","ref":"/docs/pentesting/reconocimiento/snmp/","tags":["pentesting","fingerprinting","reconocimiento"],"title":"SNMP"},{"body":"","categories":"","description":"Aquí se agrupa todo lo que tenga que ver con sistemas unix y utilidades de línea de comandos.","excerpt":"Aquí se agrupa todo lo que tenga que ver con sistemas unix y …","ref":"/docs/unix/","tags":"","title":"Unix"},{"body":"","categories":"","description":"Una de las técnologías de contenedores más populares del momento","excerpt":"Una de las técnologías de contenedores más populares del momento","ref":"/docs/contenedores/docker/","tags":"","title":"Docker"},{"body":"Bash nos ofrece una serie de utilidades para buscar información en ficheros de texto. En este apartado vamos a ver algunas de ellas.\nFind El comando find nos permite buscar ficheros en un directorio y sus subdirectorios. Para realizar una búsqueda simple, podemos hacerlo de la siguiente forma:\nfind / -name fichero En este caso, la búsqueda se realiza en el directorio raíz del sistema. El parámetro -name indica el nombre del fichero que queremos buscar. Si queremos buscar un fichero que contenga una cadena de caracteres, podemos usar el parámetro -iname:\nfind / -iname fichero Para buscar directorios, podemos usar el parámetro -type d:\nfind / -type d -iname directorio Si queremos buscar ficheros que contengan una cadena de caracteres, podemos usar el parámetro -exec grep:\nfind / -type f -iname fichero -exec grep \"cadena\" {} \\; Locate La utilidad locate nos permite buscar ficheros en el sistema. Para ello, utiliza una base de datos que se actualiza periódicamente. Para buscar un fichero, podemos hacerlo de la siguiente forma:\nlocate fichero Para que la base de datos se actualice, podemos usar el comando updatedb:\nupdatedb Esta utilidad es más rápida que find, pero no siempre encuentra los ficheros que buscamos ya que se basa en una base de datos que no siempre está actualizada.\nWhich La utilidad which nos permite buscar la localización de un comando en el sistema. Para buscar un comando, podemos hacerlo de la siguiente forma:\nwhich comando Por ejemplo, imaginemos que queremos saber donde esta instalado el comando ls. Podemos hacerlo de la siguiente forma:\nwhich ls Esto nos devolverá la ruta donde se encuentra el comando ls:\n/usr/bin/ls # Habitualmente, el comando ls se encuentra en esta ruta Grep El comando grep nos permite buscar una cadena de caracteres en un fichero de texto. Para buscar una cadena de caracteres, podemos hacerlo de la siguiente forma:\ngrep \"cadena\" fichero Si queremos buscar una cadena de caracteres en todos los ficheros de un directorio, podemos usar el parámetro -r:\ngrep -r \"cadena\" directorio Si queremos buscar una cadena de caracteres en todos los ficheros de un directorio y sus subdirectorios, podemos usar el parámetro -R:\ngrep -R \"cadena\" directorio Podríamos filtar el flujo de salida de otro comando. Por ejemplo, si queremos buscar una cadena de caracteres en los ficheros de un directorio, podemos hacerlo de la siguiente forma:\nls directorio | grep \"cadena\" ","categories":"","description":"Utilidades de búsqueda de información\n","excerpt":"Utilidades de búsqueda de información\n","ref":"/docs/programacion/bash/herramientas_busqueda/","tags":["git","configuracion"],"title":"Búsqueda"},{"body":"Usar una clave específica por repositorio Puede ocurrir, por ejemplo usando github, que tengamos varias cuentas y no podamos usar la misma clave ssh que tenemos en el sistema para todos los repositorios. Este problema surge a raiz de que github no permite tener la misma clave ssh repetida en diferentes cuentas.\nEn nuestro local podríamos generar otra pareja de claves que tuvieran otro nombre y luego en nuestro repositorio de git, especificar manualmente que clave queremos que use nuestro repositorio.\ngit config --local core.sshCommand \"ssh -i ~/.ssh/id_rsa_personal -F /dev/null\" ","categories":"","description":"Configuracion de múltiples claves o claves ssh específicas por repositorio\n","excerpt":"Configuracion de múltiples claves o claves ssh específicas por …","ref":"/docs/programacion/git/claves_ssh/","tags":["git","configuracion"],"title":"Claves ssh"},{"body":"Acceder a MySQL Sin especificar credenciales:\nmysql # Sin login Con usuario y contraseña (la password la pide por pantalla):\nmysql -u root -p # Con usuario y contraseña Bases de datos Mostrar todas:\nshow databases; Crear base de datos:\ncreate database \u003cbase de datos\u003e; Borrar base de datos:\ndrop database \u003cbase de datos\u003e; Tablas Consultar tablas:\nshow tables; Describir los atributos de una tabla:\nDESCRIBE \u003ctabla\u003e; Crear tabla:\nmysql\u003e CREATE TABLE \u003ctabla\u003e( id CLAVE NOT NULL AUTO_INCREMENT, nombre CHAR(30) NOT NULL, edad INTEGER(30), salario INTEGER(30), PRIMARY KEY (id) ); Insertar datos:\nINSERT INTO \u003ctabla\u003e (nombre, edad, salario) VALUES (\"Pedro\", 24, 21000), (\"Maria\", 26, 24000), (\"Juan\", 28, 25000), (\"Luis\", 35, 28000), (\"Monica\", 42, 30000), (\"Rosa\", 43, 25000), (\"Susana\", 45, 39000); Actualizar datos:\nUPDATE \u003ctabla\u003e SET nombre = \"Pedro\" WHERE id = 1; Obtener datos:\nSELECT * FROM \u003ctabla\u003e; Borrar datos:\nDELETE FROM \u003ctabla\u003e WHERE id = 1; Salir de MySql Para salir del cli interactivo de mysql se puede usar la opción quit o exit.\nexit; ","categories":"","description":"","excerpt":"Acceder a MySQL Sin especificar credenciales:\nmysql # Sin login Con …","ref":"/docs/programacion/sql/comandos_basicos/","tags":["database","mysql"],"title":"Comandos básicos"},{"body":"GNU GRUB es un cargador de arranque múltiple, desarrollado por el proyecto GNU que nos permite elegir qué Sistema Operativo arrancar de los instalados. Se usa principalmente en sistemas operativos GNU/Linux.\nConfigurar el tiempo de espera Una configuración que siempre me gusta ajustar es el tiempo de espera, normalmente unos 5 segundos.\nPara configuraciones con múltiples sistemas operativos esta bien que haya cierto margen para elegir el que queramos pero, al menos en mi caso, usando solo linux no veo necesidad de demorar el tiempo de arranque.\nEsta configuración se puede editar en el fichero:\n/etc/default/grub Cambiando el parámetro “GRUB_TIMEOUT” por el valor que deseemos:\nGRUB_DEFAULT=0 GRUB_TIMEOUT=5 # \u003c-- CAMBIAR POR EL VALOR QUE QUIERAS GRUB_DISTRIBUTOR=`lsb_release -i -s 2\u003e /dev/null || echo Debian` GRUB_CMDLINE_LINUX_DEFAULT=\"quiet\" GRUB_CMDLINE_LINUX=\"\" En mi caso, lo pongo a 0 para agilizar lo máximo posible.\n","categories":"","description":"","excerpt":"GNU GRUB es un cargador de arranque múltiple, desarrollado por el …","ref":"/docs/unix/grub/","tags":["linux","grub"],"title":"Grub"},{"body":"Página oficial: Oh My Posh\nAquí tenéis también el video tutorial: Instalación El módulo de oh my posh se puede instalar desde la documentación de este enlace: Instalación en windows\nMediante winget (el gestor de paquetes nativo de windows) podemos instalarlo con un solo comando:\nwinget install JanDeDobbeleer.OhMyPosh -s winget Una vez instalado, nos queda configurarlo para que arranque cada vez que iniciamos powershell. Para ello, abrimos el fichero profile de powershell:\nnotepad $PROFILE Una vez abierto notepad, añadimos las siguientes líneas y guardamos:\noh-my-posh init pwsh | Invoke-Expression Esto permitirá que se arranque solo cada vez que abramos el terminal de powershell.\nFuentes ( Nerd Fonts ) Podemos instalar fuentes con el comando (Requiere permisos de administrador):\noh-my-posh font install Esto nos abrirá un prompt interactivo para elegir la fuente que queremos que nos instale.\nTambién podríamos instalarlas desde la página de Nerd Fonts\nUna vez instalada la fuente que nos interesa usar, no nos olvidemos de seleccionarla en nuestra aplicación o gestor de terminales favorito.\nEn el caso de windows terminal: Configuración (Control , ) -\u003e Perfiles -\u003e Valores predeterminados -\u003e Apariencia -\u003e Tipo de Fuente\nMódulos de terceros PSReadLine Este módulo nos permitirá activar el autocompletado de comandos en base a nuestro historial de una forma gráfica y cómoda:\nInstalación:\nInstall-Module -Name PSReadLine -AllowPrerelease -Scope CurrentUser -Force -SkipPublisherCheck Además de la instalación tendremos que añadir al nuestro script ubicado $PROFILE, por defecto, ubicado en ~/Documents/PowerShell/Microsoft.PowerShell_profile.ps1:\nSet-PSReadLineOption -PredictionSource History Set-PSReadLineOption -PredictionViewStyle ListView Set-PSReadLineOption -EditMode Windows oh-my-posh init pwsh --config 'https://raw.githubusercontent.com/JanDeDobbeleer/oh-my-posh/main/themes/material.omp.json' | Invoke-Expression Este es el resultado final de mi configuración importando remotamente el tema de oh-my-posh a utilizar.\n","categories":"","description":"","excerpt":"Página oficial: Oh My Posh\nAquí tenéis también el video tutorial: …","ref":"/docs/windows/oh_my_posh/","tags":["powershell"],"title":"Oh my posh"},{"body":"Los pods se son una unidad de ejecución de contenedores, concretamente la unidad más pequeña con la que se puede trabajar en kubernetes. Estos son los comandos básicos para usar un contenedor en Kubernetes.\nCrear un pod Especificaremos el nombre que le queremos asignar a ese pod y la imagen que utilizaremos.\nkubectl run \u003cnom_pod\u003e --image=\u003cimagen\u003e Ver un pod kubectl get pods # Listar todos los pods en el cluster kubectl get pods -o wide # Listar los pods en una tabla más amplia kubectl get pods \u003cnom_pod\u003e # Listar el pod especificado kubectl describe pods \u003cnom_pod\u003e # Describe el pod nginx kubectl -n anchore get pods \u003cnom_pod\u003e -o yaml # Nos devuelve todo el manifiesto del pod Al hacer un describe del pod veríamos la siguiente salida:\nName: nginx Namespace: default Priority: 0 Node: minikube/192.168.49.2 Start Time: Mon, 20 Dec 2021 20:12:08 +0100 Labels: run=nginx Annotations: \u003cnone\u003e Status: Running IP: 172.17.0.3 IPs: IP: 172.17.0.3 Containers: nginx: Container ID: docker://f19cee240b99b737dc71db300dcfe2ad51a1596b35b2861aea274820aa841530 Image: nginx Image ID: docker-pullable://nginx@sha256:9522864dd661dcadfd9958f9e0de192a1fdda2c162a35668ab6ac42b465f0603 Port: \u003cnone\u003e Host Port: \u003cnone\u003e State: Running Started: Mon, 20 Dec 2021 20:12:14 +0100 Ready: True Restart Count: 0 Environment: \u003cnone\u003e Mounts: /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-58m5c (ro) Conditions: Type Status Initialized True Ready True ContainersReady True PodScheduled True Volumes: kube-api-access-58m5c: Type: Projected (a volume that contains injected data from multiple sources) TokenExpirationSeconds: 3607 ConfigMapName: kube-root-ca.crt ConfigMapOptional: \u003cnil\u003e DownwardAPI: true QoS Class: BestEffort Node-Selectors: \u003cnone\u003e Tolerations: node.kubernetes.io/not-ready:NoExecute op=Exists for 300s node.kubernetes.io/unreachable:NoExecute op=Exists for 300s Events: Type Reason Age From Message ---- ------ ---- ---- ------- Normal Scheduled 43s default-scheduler Successfully assigned default/nginx to minikube Normal Pulling 42s kubelet Pulling image \"nginx\" Normal Pulled 37s kubelet Successfully pulled image \"nginx\" in 4.842081346s Normal Created 37s kubelet Created container nginx Normal Started 37s kubelet Started container nginx Destruir un pod kubectl delete pod nginx Problemas de los pods No saben restaurarse ni replicarse a si mismos. Necesitan de alguien que gestione estos procesos. Para esto se utilizan otro tipo de elementos: Replicasets\n","categories":"","description":"","excerpt":"Los pods se son una unidad de ejecución de contenedores, concretamente …","ref":"/docs/contenedores/kubernetes/pods/","tags":["kubernetes","devops"],"title":"Pods"},{"body":"Las variables en python son contenedores para almacenar valores. Estos valores pueden ser de cualquier tipo, como números, cadenas, listas, diccionarios, etc.\nDeclaración de variables Se pueden declarar variables usando el operador de asignación =. Por ejemplo:\nx = 5 y = \"Hello, World!\" Python es un lenguaje de tipado dinámico, lo que significa que no necesitas declarar el tipo de variable. Cuando se crea una variable, se le asigna un tipo de datos. El tipo de datos puede cambiar durante la ejecución del programa.\nNombres de variables Un nombre de variable debe comenzar con una letra o el carácter de subrayado _. No puede comenzar con un número. Un nombre de variable solo puede contener caracteres alfanuméricos y guiones bajos (A-z, 0-9 y _). Los nombres de variables son sensibles a mayúsculas y minúsculas, por lo que myvar y myVar son dos variables diferentes.\nAsignación múltiple Python permite asignar valores a múltiples variables en una sola línea.\nx, y, z = \"Orange\", \"Banana\", \"Cherry\" print(x) print(y) print(z) También puede asignar el mismo valor a múltiples variables en una sola línea.\nx = y = z = \"Orange\" ","categories":"","description":"","excerpt":"Las variables en python son contenedores para almacenar valores. Estos …","ref":"/docs/programacion/python/variables/","tags":["python","programación"],"title":"Variables"},{"body":"","categories":"","description":"Herramientas, utilidades y configuración para el sistema operativo de Microsoft","excerpt":"Herramientas, utilidades y configuración para el sistema operativo de …","ref":"/docs/windows/","tags":"","title":"Windows"},{"body":"El servicio de NFS es un servicio de red que nos permite compartir archivos entre distintos equipos. Este funciona de forma similar a una carpeta compartida en Windows. Esta pensado para funcionar como servidor o cliente. El servidor comparte una carpeta con uno o más clientes y los clientes acceden a los archivos de la carpeta ( montando las carpetas en su sistema de ficheros ).\nEsta guía se parte por un lado en la configuración de un servidor NFS y por otro en la configuración de un cliente NFS.\nServidor Instalación de los requisitos Para funcionar NFS sobre el servidor debemos instalar los siguientes paquetes:\napt install nfs-kernel-server nfs-common Con esto ya podemos para a la configuración.\nPreparando la carpeta a compartir Primero tenemos que crear la carpeta que vamos a compartir (en el caso de que ya la tengas puedes omitir este paso):\nmkdir \u003ccarpeta_compartida\u003e Luego tenemos que asignar un propietario especial a esta carpeta. Este usuario nobody y grupo nogroup se utilizan para que los clientes remotos puedan acceder a los archivos de la carpeta compartida.\nchown nobody:nogroup \u003ccarpeta_compartida\u003e Configurando el servidor Para configurar el servidor NFS, debemos modificar el archivo de configuración /etc/exports. Al final del fichero de configuración debemos añadir la siguiente línea:\n/ruta/carpeta/compartida \u003corigenes permitidos\u003e(\u003copciones\u003e) # Ejemplo, los orígenes son todos los clientes, especificado con *. /home/usuario/carpeta_compartida *(rw,sync,no_subtree_check,no_root_squash) # Podíamos especificar múltiples clientes con distintas opciones por cada uno de ellos /ruta/carpeta/compartida 192.168.1.56(rw,sync) 192.168.1.68(rw,sync) Podemos especificar los origenes permitidos al servidor de las siguientes maneras:\nHost único: podríamos especificar una IP o un nombre de host único como origen y repetir las opciones por cada uno de ellos. Redes de IPs: Podríamos especificar rangos de IPs especificando la IP con máscara de red. Ejemplo, 192.168.1.0/24 permitiría todas las IPs de la red desde 192.168.1.0 hasta 192.168.1.255. Comodines: Podríamos usar * para indicar que todos los clientes están permitidos y tambien se puede combinar con nombres de dominios. Por ejemplo, *.example.com permitiría todos los clientes que tengan con subdominio de example.com. Grupos de red: Se podría definir un grupo de equipos de red especificándolo de la siguiente manera @grupo_de_red. Veamos las diferentes opciones que podemos configurar por cada origen o grupo de orígenes:\nPermisos de lectura: rw para lectura y escritura y ro para solo lectura. Opciones de sincronización: sync para sincronizar los archivos y async para no sincronizar los archivos. Opciones de compartición: no_subtree_check para que no se compruebe el subdirectorio y no_root_squash para que no se comparta el root. Una vez configuradas las carpetas a compartir tendríamos que reiniciar el servicio para que se aplique la nueva configuración.\nsystemctl restart nfs-kernel-server Permitir conexiones remotas en el firewall Para permitir conexiones remotas en el firewall debemos permitir conexiones al puerto 2049 y 111 que utiliza el servicio NFS. Con ufw en ubuntu se puede hacer de la siguiente manera:\n# Permitir orígenes específicos en el firewall ufw allow from \u003corigen\u003e to any port nfs # Permitir todos los orígenes en el firewall ufw allow from any to any port nfs Cliente Instalación de los requisitos Para funcionar NFS como cliente debemos instalar el siguiente paquete:\napt install nfs-common Punto de montaje o carpeta donde montar los archivos remotos Debemos espesificar la carpeta donde vamos a montar los archivos remotos. Esto se puede hacer con el comando mount:\nmount \u003cIP del servidor\u003e:/ruta/carpeta/remota /ruta/carpeta/local Una vez montada la carpeta podemos listar todos los puntos de montaje del servidor con el siguiente comando:\nshowmount -e \u003cIP del servidor\u003e También podríamos listar los montajes locales con el comando:\ndf -h Por último, podríamos desmontar un punto de montaje con el comando:\numount /ruta/carpeta/local Montaje automático en el arranque - Fstab Podemos montar automáticamente la carpeta remota en el arranque añadiendo una línea de configuración en el archivo /etc/fstab:\nLa línea tendría el siguiente formato:\n\u003cIP del servidor\u003e:\u003cruta/carpeta/remota\u003e /ruta/carpeta/local nfs \u003copciones\u003e 0 0 # Por ejemplo: 192.168.1.56:/home/user/compartida /home/cliente/compartida nfs rw,nofail,noatime,nolock,intr,tcp,actimeo=1800 0 0 Ahora podríamos reiniciar el servidor y comprobar que la carpeta se ha montado automáticamente. A veces tarda unos segundos/minutos en realizar el montaje.\n","categories":"","description":"","excerpt":"El servicio de NFS es un servicio de red que nos permite compartir …","ref":"/docs/unix/nfs/","tags":["linux"],"title":"NFS"},{"body":"En lo personal me encanta el terminal y en lo profesional lo veo indispensable para ciertas tareas.\nAdaptarlo a nuestras necesidades y potenciar sus utilidades de caja me parece vital si pasas muchas horas delante de una interfaz de comandos.\nEn esta guía explico como configurar zsh a mis gustos personales, (en este vídeo tenéis todo el proceso más detallado): Instalación de requisitos Con el siguiente comando podéis instalar todos los requisitos necesarios para instalar zsh:\napt install curl zsh Instalación de ohmyzsh Ahora que tenemos instalado zsh podemos instalar el plugin de ohmyzsh:\nsh -c \"$(curl -fsSL https://raw.githubusercontent.com/ohmyzsh/ohmyzsh/master/tools/install.sh)\" e voila!\nOpción 1 - Configuración con antigen (recomendada) Antigen es un plugin de ohmyzsh que nos permite configurar zsh con una interfaz más sencilla, funcionando como gestor de plugins y temas.\nPodemos descargarlo con el siguiente comando:\ncurl -L git.io/antigen \u003e antigen.zsh Es importante que tengamos localizado el archivo antigen.zsh, personalmente lo suelo guardar dentro de la carpeta .oh-my-zsh por limpieza.\nConfiguración de antigen Para configurar antigen debemos añadir el siguiente comando en el fichero .zshrc:\nsource \u003cubicación del archivo antigen.zsh\u003e Instalación de plugin y temas Para configurar un plugin podemos usar el comando ‘antigen bundle’ y para seleccionar un tema se usa el comando ‘antigen theme’.\nPor ejemplo:\n# Definición de plugins antigen bundle git antigen bundle git-prompt # Definición de un tema antigen theme robbyrussell Para finalizar la configuración de antigen debemos añadir el siguiente comando en el fichero .zshrc:\nantigen apply La principal ventaja que nos aporta antigen es que deja un fichero de configuración mucho más limpio y, además, nos instala automaticamente los plugins y temas que hemos defino.\nLas próxima vez que hagamos source .zshrc antigen se encargará de gestionarlo todo.\nAsí quedaría el fichero .zshrc completo:\nsource ~/.oh-my-zsh/antigen.zsh # Load the oh-my-zsh's library. antigen use oh-my-zsh # Bundles from the default repo (robbyrussell's oh-my-zsh). antigen bundle git antigen bundle git-prompt antigen bundle z antigen bundle pip antigen bundle kubectl antigen bundle git-prompt antigen bundle vi-mode antigen bundle docker antigen bundle docker-compose # Syntax highlighting bundle. antigen bundle zsh-users/zsh-syntax-highlighting antigen bundle zsh-users/zsh-autosuggestions # Load the theme. antigen theme bureau # Tell Antigen that you're done. antigen apply Opción 2 - Configuración de ohmyzsh (Sin antigen) Recuerda que todas las configuraciones que hagas en zsh se guardarán en el archivo .zshrc. Aquí podemos editar el tema, los plugins, añadir alias.. etc.\nTema Se puede editar el tema de zsh en el parámentro ZSH_THEME: del fichero .zshrc. Por ejemplo:\nZSH_THEME=\"robbyrussell\" Así se cambia al tema por defecto de ohmyzsh.\nPlugins Para añadir un plugin a zsh, debemos añadirlo en la sección plugins del fichero .zshrc separados por espacios. Por ejemplo:\nplugins=(git sudo docker z ) Recargar cambios Recuerda que cada vez que modifiques el fichero .zshrc tendras que cargar de nuevo la configuración con el comando:\nsource ~/.zshrc Autocompletado y resaltado de color Estas funcionalidades no vienen por defecto pero si podemos intalar los plugins para activarlos posteriormente. Aquí los enlaces a sus repositorios: autocomplete highlight\nLos podríamos instalar respectivamente con los siguientes comandos:\n#Instalar autocompletado git clone https://github.com/zsh-users/zsh-autosuggestions ${ZSH_CUSTOM:-~/.oh-my-zsh/custom}/plugins/zsh-autosuggestions #Instalar resaltado de color git clone https://github.com/zsh-users/zsh-syntax-highlighting.git ${ZSH_CUSTOM:-~/.oh-my-zsh/custom}/plugins/zsh-syntax-highlighting Los podríamos activar añadiéndolos en el parámetro de plugins en el fichero .zshrc:\nplugins=(zsh-syntax-highlighting zsh-autosuggestions) ","categories":"","description":"","excerpt":"En lo personal me encanta el terminal y en lo profesional lo veo …","ref":"/docs/unix/zsh/","tags":["shell","zsh","terminal","productividad"],"title":"Zsh"},{"body":"","categories":"","description":"Lenguaje de comandos por excelencia en sistemas UNIX y utilidades de terminal.\n","excerpt":"Lenguaje de comandos por excelencia en sistemas UNIX y utilidades de …","ref":"/docs/programacion/bash/","tags":"","title":"Bash y utilidades"},{"body":"Cláusulas Las consultas en SQL son una forma de acceder a la base de datos.\nEstas consultas tienen diferentes cláusulas:\nFROM: Selecciona la tabla. WHERE: Selecciona los registros que cumplan con una condición. ORDER BY: Ordena los registros por un atributo. GROUP BY: Agrupa los registros por un atributo. LIMIT: Limita el número de registros a devolver. HAVING: Selecciona los registros que cumplan con una condición. Opera sobre los registros agrupados. La siguiente consulta devolvería todos los registros de la tabla tabla.\nSELECT * FROM tabla; Ejemplo where: La siguiente consulta devolvería el registro con el id 1 de la tabla tabla.\nSELECT * FROM tabla WHERE id = 1; Ejemplo order by: Por defecto, ORDER BY devolvería todos los registros la tabla tabla ordenados por el id de forma ascendente (sin especificar nada), también podría usarte el DESC para ordenarlas de forma ascendent\nSELECT * FROM tabla ORDER BY id DESC; Ejemplo group by: La siguiente consulta devolvería todos los registros agrupados por el campo nombre.\nSELECT * FROM tabla GROUP BY nombre; Ejemplo limit: La siguiente consulta devolvería los primeros 5 registros de la tabla tabla.\nSELECT * FROM tabla LIMIT 5; Ejemplo having:\nSELECT * FROM tabla GROUP BY nombre HAVING COUNT(*) \u003e 1; Operadores Los operadores nos permiten establecer condiciones en las consultar, modificarlas o agruparlos.\nOperadores de comparación Existen diferentes operadores de comparación que nos permiten comparar dos valores.\nOperador Función \u003c Menor que \u003e Mayor que \u003c\u003e Distinto de = Igual a \u003c= Menor o igual que \u003e= Mayor o igual que IN Dentro de (filas de tabla) NOT IN Fuera de (filas de tabla) BETWEEN Entre (valores numéricos) LIKE Contiene (valor de cadena) Algunos ejemplos:\nSELECT * FROM table WHERE precio \u003e 10; /*Selecciona todos los registros con precio mayor a 10*/ SELECT * FROM table WHERE precio \u003c 10; /*Selecciona todos los registros con precio menor a 10*/ SELECT * FROM table WHERE precio \u003c\u003e 10; /*Selecciona todos los registros con precio distinto a 10*/ SELECT * FROM table WHERE precio = 10; /*Selecciona todos los registros con precio igual a 10*/ SELECT * FROM table WHERE precio \u003c= 10; /*Selecciona todos los registros con precio menor o igual a 10*/ SELECT * FROM table WHERE precio \u003e= 10; /*Selecciona todos los registros con precio mayor o igual a 10*/ SELECT * FROM table WHERE precio IN (10, 20, 30); /*Selecciona todos los registros con precio 10, 20 o 30*/ SELECT * FROM table WHERE precio NOT IN (10, 20, 30); /*Selecciona todos los registros con precio distinto a 10, 20 o 30*/ SELECT * FROM table WHERE precio BETWEEN 10 AND 20; /*Selecciona todos los registros con precio entre 10 y 20*/ Comparación de cadenas Concretamente el comando LIKE nos permite buscar dentro de una cadena de texto. Este comando se aplica a los campos de tipo varchar o char. Se apoya en los siguientes operadores:\nOperador Función % Comodín, representa cualquier cadena de 0 o más caracteres _ Representa a un único carácter cualquiera Combinando el LIKE con el % o con el _ podemos buscar por palabras completas o parciales.\nAlgunos ejemplos con %:\nSELECT * FROM tabla WHERE nombre LIKE '%Pedro%'; /*Todas las filas que contengan la palabra Pedro*/ SELECT * FROM tabla WHERE nombre LIKE 'Pedro%'; /*Todas las filas que comiencen por Pedro*/ SELECT * FROM tabla WHERE nombre LIKE '%Pedro'; /*Todas las filas que terminen por Pedro*/ Algunos ejemplos con _:\nOperadores lógicos Nos permiten establecer condiciones en las consultas. También nos permite agrupar varias consultas y condiciones a su vez.\nLos operadores lógicos son:\nOperador Función AND Y OR O NOT No Algunos ejemplos:\nSELECT * FROM tabla WHERE nombre LIKE '%Pedro%' AND precio \u003c 10; SELECT * FROM tabla WHERE nombre LIKE '%Pedro%' OR precio \u003c 10; SELECT * FROM tabla WHERE precio \u003c 10 AND nombre LIKE '%Pedro%'; SELECT * FROM tabla WHERE nombre LIKE '%Pedro%' AND precio \u003c 10 OR precio \u003e 20; SELECT * FROM tabla WHERE nombre LIKE '%Pedro%' AND (precio \u003c 10 OR precio \u003e 20); SELECT * FROM tabla WHERE nombre LIKE '%Pedro%' OR (precio \u003c 10 AND precio \u003e 20); SELECT * FROM tabla WHERE (nombre LIKE '%Pedro%' AND precio \u003c 10) OR precio \u003e 20; Operadores de agrupación Nos permiten agrupar registros por un campo.\nOperador Función COUNT() Cuenta los registros que cumplan con la condición SUM() Suma los valores de un campo MAX() Devuelve el valor máximo de un campo MIN() Devuelve el valor mínimo de un campo AVG() Devuelve la media de un campo Algunos ejemplos:\nSELECT COUNT(*) FROM tabla; SELECT SUM(precio) FROM tabla; SELECT MAX(precio) FROM tabla; SELECT MIN(precio) FROM tabla; SELECT AVG(precio) FROM tabla; Subconsultas A veces, para realizar alguna operación de consulta, necesitamos los datos devueltos por otra consulta.\nUna subconsulta, que no es más que una sentencia SELECT dentro de otra SELECT.\nLas subconsultas son aquellas sentencias SELECT que forman parte de una cláusula WHERE de una sentencia SELECT anterior. Una subconsulta consistirá en incluir una declaración SELECT como parte de una cláusula WHERE.\nUn ejemplo de subconsultas:\nSELECT apellido FROM empleados WHERE oficio = (SELECT oficio FROM empleados WHERE apellido ='gil'); ","categories":"","description":"","excerpt":"Cláusulas Las consultas en SQL son una forma de acceder a la base de …","ref":"/docs/programacion/sql/clausulas_operadores/","tags":["database","mysql"],"title":"Consultas y cláusulas"},{"body":"Toda la documentación de este sitio esta abierta a mejoras y correcciones. En el sidebar derecho tienes todas las opciones para contribuir. Puede ser que parte del contenido lo haya publicado como entrada del Blog y no lo encuentres aquí reflejado.\n","categories":"","description":"","excerpt":"Toda la documentación de este sitio esta abierta a mejoras y …","ref":"/docs/","tags":"","title":"Documentación"},{"body":"","categories":"","description":"Sección dedicada al control de versiones GIT\n","excerpt":"Sección dedicada al control de versiones GIT\n","ref":"/docs/programacion/git/","tags":"","title":"Git"},{"body":"Por debajo de todas las acciones de kubernetes, lo que el motor entiende, son archivos manifiesto que definen el tipo de cada elemento.\nCuando se coge cierta experiencia se dejan de usar comandos para usar manifiestos y poder aplicar varios a la vez, haciendo el proceso menos tedioso.\nObtener el manifiesto de un pod kubectl get pods \u003cnombre pod\u003e -o \u003cformato\u003e Existen varios formatos de salida pero los más comunes son yaml (el usado nativamente por kubernetes), json, name, go-template (para customizaciones)… https://kubernetes.io/docs/reference/kubectl/overview/#custom-columns\nDefinir un pod en un manifiesto Creamos la definición de un pod de prueba que escribirá “Hello world” cada hora:\napiVersion: v1 kind: Pod metadata: name: myapp-pod labels: app: myapp spec: containers: - name: myapp-container image: busybox command: ['sh', '-c', 'echo Hello World!; sleep 3600'] Luego podríamos crear el elemento con el comando:\nkubectl apply -f pods.yaml También podríamos eliminarlo usando el manifiesto con el comando:\nkubectl deletec-f pods.yaml Multiples contenedores en un pod Podemos definir varios contenedores en un pod. En este ejemplo podemos ver el balanceo que hace kubernetes a nivel de red entre los distintos contenedores de un pod.\napiVersion: v1 kind: Pod metadata: name: doscont spec: containers: - name: cont1 image: python:3.6-alpine command: ['sh', '-c', 'echo \"cont1 \u003e index.html\" \u0026\u0026 python -m http.server 8082'] - name: cont2 image: python:3.6-alpine command: ['sh', '-c', 'echo \"cont2 \u003e index.html\" \u0026\u0026 python -m http.server 8083'] Labels Podemos usar etiquetas para filtrar recursos en proyectos de cierto tamaño. Por ejemplo, separando frontend de backend:\napiVersion: v1 kind: Pod metadata: name: podtest2 labels: app: front env: dev spec: containers: - name: cont1 image: nginx:alpine --- apiVersion: v1 kind: Pod metadata: name: podtest3 labels: app: back env: dev spec: containers: - name: cont1 image: nginx:alpine Ahora para filtrar desde el cli podríamos usar el parámetro “-l” para ello de la siguiente manera:\nkubectl get pod -l app=front Podríamos filtrar por cualquier variable que hayamos definido, también “env”:\nkubectl get pod -l env=dev Incluso multiples labels a la vez:\nkubectl get pod -l app=front,env=dev ","categories":"","description":"","excerpt":"Por debajo de todas las acciones de kubernetes, lo que el motor …","ref":"/docs/contenedores/kubernetes/manifest/","tags":["kubernetes","devops"],"title":"Manifiestos y etiquetas"},{"body":"","categories":"","description":"Uno de los lenguajes más versátiles y simples de la actualidad\n","excerpt":"Uno de los lenguajes más versátiles y simples de la actualidad\n","ref":"/docs/programacion/python/","tags":"","title":"Python"},{"body":"Las cadenas de texto o strings en Python se pueden declarar usando comillas simples o dobles.\nx = \"Hello World\" Las cadenas de texto pueden ser de una línea o de varias líneas. Para declarar una cadena de texto de varias líneas, se debe usar tres comillas simples o dobles.\nx = \"\"\"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua.\"\"\" Operaciones con cadenas Podemos utilizar diferentes operadores para realizar operaciones con cadenas de texto.\nPor ejemplo, si queremos concatenar dos cadenas de texto, podemos usar el operador +.\nx = \"Hello\" y = \"World\" z = x + y print(z) # Output: HelloWorld Indexado de una string Las cadenas en python son un conjunto de caracteres. Por lo tanto, cada carácter tiene un índice asociado. El primer carácter tiene el índice 0, el segundo carácter tiene el índice 1, etc.\nPor ejemplo, si queremos acceder al primer carácter de una cadena de texto, podemos usar el índice 0.\nx = \"Hello World\" print(x[0]) # Output: H Si queremos acceder al último carácter de una cadena de texto, podemos usar el índice -1.\nx = \"Hello World\" print(x[-1]) # Output: d Se trataría exactamente igual que una lista. Si queremos acceder a un rango de caracteres, podemos usar el operador :.\nx = \"Hello World\" print(x[2:5]) # Output: llo Inmutabilidad de las cadenas Las cadenas de texto en Python son inmutables. Esto significa que no podemos cambiar los caracteres de una cadena de texto una vez que se ha creado.\nx = \"Hello World\" x[0] = \"J\" # Error Si queremos cambiar un carácter de una cadena de texto, tenemos que crear una nueva cadena de texto.\nx = \"Hello World\" y = \"J\" + x[1:] print(y) # Output: Jello World Métodos de las cadenas Las cadenas de texto en Python tienen muchos métodos que podemos utilizar.\nLower El método lower() devuelve la cadena de texto en minúsculas.\nx = \"Hello World\" print(x.lower()) # Output: hello world Upper El método upper() devuelve la cadena de texto en mayúsculas.\nx = \"Hello World\" print(x.upper()) # Output: HELLO WORLD Capitalize El método capitalize() devuelve la cadena de texto con la primera letra en mayúsculas.\nx = \"hello world\" print(x.capitalize()) # Output: Hello world Len El método len() devuelve la longitud de la cadena de texto.\nx = \"Hello World\" print(len(x)) # Output: 11 Replace El método replace() devuelve una nueva cadena de texto donde se han reemplazado todas las apariciones de una cadena de texto por otra.\nx = \"Hello World\" print(x.replace(\"H\", \"J\")) # Output: Jello World Split El método split() devuelve una lista donde la cadena de texto se ha dividido en subcadenas en cada aparición del carácter especificado.\nx = \"Hello World\" print(x.split(\" \")) # Output: ['Hello', 'World'] Quitar espacios en blanco Tenemos tres métodos para quitar espacios en blanco de una cadena de texto.\nRstrip quita los espacios en blanco del final de la cadena de texto.\nx = \"Hello World \" print(x.rstrip()) # Output: Hello World Lstrip quita los espacios en blanco del principio de la cadena de texto.\nx = \" Hello World\" print(x.lstrip()) # Output: Hello World Strip quita los espacios en blanco del principio y del final de la cadena de texto.\nx = \" Hello World \" print(x.strip()) # Output: Hello World Formateo de cadenas Podemos utilizar el método format() para formatear cadenas de texto.\nEl método format() toma los argumentos pasados, los formatea y los inserta en la cadena de texto donde se encuentran los corchetes {}.\nx = \"Hello {}\" print(x.format(\"World\")) # Output: Hello World Podemos pasar múltiples argumentos al método format().\nx = \"Hello {}, you are {} years old\" print(x.format(\"John\", 36)) # Output: Hello John, you are 36 years old También podemos utilizar índices para especificar el orden en el que se insertan los argumentos.\nx = \"Hello {1}, you are {0} years old\" print(x.format(36, \"John\")) # Output: Hello John, you are 36 years old O nombres.\nx = \"Hello {name}, you are {age} years old\" print(x.format(age = 36, name = \"John\")) # Output: Hello John, you are 36 years old Por último, también podríamos utilizar el operador % para formatear cadenas de texto.\nx = \"Hello %s, you are %d years old\" print(x % (\"John\", 36)) # Output: Hello John, you are 36 years old Empieza o termina con Podemos utilizar los métodos startswith() y endswith() para comprobar si una cadena de texto empieza o termina con una subcadena de texto.\nx = \"Hello World\" print(x.startswith(\"Hello\")) # Output: True print(x.endswith(\"World\")) # Output: True In - Contiene Podemos utilizar el operador in para comprobar si una cadena de texto contiene una subcadena de texto.\nx = \"Hello World\" print(\"Hello\" in x) # Output: True print(\"Goodbye\" in x) # Output: False Find - Encontrar Podemos utilizar el método find() para encontrar la posición de la primera aparición de una subcadena de texto dentro de una cadena de texto.\nx = \"Hello World\" print(x.find(\"World\")) # Output: 6 ","categories":"","description":"Las cadenas en python nos permiten almacenar texto","excerpt":"Las cadenas en python nos permiten almacenar texto","ref":"/docs/programacion/python/strings/","tags":["python","programación"],"title":"Strings (Cadenas)"},{"body":"Hoy en día cualquier aplicación la podemos ejecutar en nuestro navegador web. Pero, ¿por qué tener aplicaciones sueltas si podemos usarlo para acceder a nuestro sistema operativo completo?. Es verdad que existen soluciones como Microsoft 365, Horizon y demás, las cuales están enfocadas principalmente en entornos corporativos windows y la mayoría requieren de clientes específicos para poder usarlos.\nEl objetivo de esta guía es explicar como ejecutar una distribución linux en tu navegador. Bueno, siendo sinceros, esto tiene un poco de truco. Efectivamente vamos a conseguir tener acceso a una distribución linux en el navegador, pero realmente no lo esta ejecutando el mismo.\nNormalmente este tipo de sistemas funcionan en linux gracias a un proyecto llamado Apache Guacamole. Esta es una herramienta de conexión remota que permite hacer de cliente para conectarse a un sistema a través de RDP o VNC.\nEste es el esquema de lo que vamos a hacer:\nEl objetivo es que nuestro contenedor lance un servicio de VNC o RDP que no esté expuesto y por otra parte un servidor de Apache Guacamole que exponha un servidor web al que podemos conectarnos con el navegador web. Desde esta página podremos gestionar entornos remotos y por debajo otro servicio hace de cliente contra estos entornos remotos.\nVeremos dos formas de conseguirlo, la primera totalmente automática y la segunda haremos de forma manual para desglosar los pasos.\nForma fácil y automática (Recomendada para todos) De la mano de las imágenes de docker de linuxserver.io podemos ejecutar contenedores de linux con todo lo hablado anteriormente, en diferentes distribuciones y con diferentes gestores de ventanas.\nOfrecen las principales distribuciones de linux, como ubuntu, alpine, fedora, arch en combinación con los gestores de ventanas más populares XFCE, KDE, i3, Openbox, IceWM… etc.\nPodéis consultar el listado completo en linuxserver.io. Este es un breve resumen del tag que tendrías que usar en la imagen de tu contenedor en función del sabor que prefieras:\nTag Description latest XFCE Alpine ubuntu-xfce XFCE Ubuntu fedora-xfce XFCE Fedora arch-xfce XFCE Arch alpine-kde KDE Alpine ubuntu-kde KDE Ubuntu fedora-kde KDE Fedora arch-kde KDE Arch Para ejecutar un contenedor de esta forma, simplemente ejecutamos el comando con la configuración de los diferentes parámetros. Importante entender los parámetros opciones, concretamente, el montaje del socket. Este nos permitirá usar docker dentro del contenedor pero pondrá en riesgo la seguridad de nuestro entorno en caso de ser vulnerado.\nSobre la seguridad en contenedores hablo más extendidamente en esta video entrada Seguridad en contenedores.\nComando de ejemplo (en la sección de Parameters de DockerHub se explica cada uno de ellos):\ndocker run -d \\ --name=webtop \\ --security-opt seccomp=unconfined `#optional` \\ -e PUID=1000 \\ -e PGID=1000 \\ -e TZ=Europe/London \\ -e SUBFOLDER=/ `#optional` \\ -e KEYBOARD=en-us-qwerty `#optional` \\ -p 3000:3000 \\ -v /path/to/data:/config \\ -v /var/run/docker.sock:/var/run/docker.sock `#optional` \\ --device /dev/dri:/dev/dri `#optional` \\ --shm-size=\"1gb\" `#optional` \\ --restart unless-stopped \\ lscr.io/linuxserver/webtop Personalmente, si no necesitas usar docker dentro de este contenedor ni montar ningún archivo lo ejecutaría así (para potenciar su seguridad, poner el teclado en español y la hora local):\ndocker run -d \\ --name=pabpereza.dev \\ --security-opt seccomp=unconfined `# Activar solo si no te funciona correctamente` \\ -e PUID=1000 \\ -e PGID=1000 \\ -e TZ=Europe/Madrid `# Hora local` \\ -e KEYBOARD=es-es-qwerty `# Teclado en castellano` \\ -e AUTO_LOGIN=true `# Poner a false para quitar el autologin (recuerda cambiar la pass)` \\ -p 3000:3000 \\ -v /var/run/docker.sock:/var/run/docker.sock `#Borrar si no queremos usar docker dentro del contenedor` \\ --shm-size=\"1gb\" `#Previene a los navegadores modernos fallar por límites de memoria` \\ --restart unless-stopped \\ lscr.io/linuxserver/webtop `# Despues de webtop con : podríamos añadir el tag para usar la distribución que queramos por defecto Alpine con XFCE` Ya lo tendríamos funcionando. También podemos mejorar el rendimiento siguiendo la guía de Hardware acceleration (en la página de DockerHub) aunque solo funciona en el contenedor de ubuntu.\nMás que aconsejable cambiar la contraseña al usuario del contenedor para que nadie pueda acceder a él directamente o poner un proxy previo con autenticación de algún tipo. Además, puedes desactivar el autologin (Variable de entorno AUTO_LOGIN en el comando de docker run).\nEsto lo podemos hacer con el comando (en un terminal dentro del contenedor):\nsudo passwd \u003cusuario\u003e Seguidamente se nos pedirá la nueva contraseña para el usuario (si os pide la anterior por defecto es abc como el usuario). Las próximas veces que entréis al contenedor a través del navegador os pedirá la contraseña para conectarse.\n","categories":"","description":"","excerpt":"Hoy en día cualquier aplicación la podemos ejecutar en nuestro …","ref":"/docs/unix/en_navegador/","tags":["linux"],"title":"En navegador"},{"body":"Para ciertos escenarios es recomendable desactivar el swap o incluso obligatorio. Por ejemplo, en el caso de kubernetes si o si se debe desactivar el swap.\nUbuntu 20.04 En ubuntu 20.04 podemos ver el estado de la memoria swap con el siguiente comando:\nsudo swap --show # También nos serviría el comando free sudo free -h Para desactivarlas, podemos usar el comando:\nsudo swapoff -a #Esto la desactiva, pero solo de forma temporal # Luego tendríamos que borrar el archivo de intercambio sudo rm /swap.img # Por último, borramos la línea de swap del fichero de configuración de linux fstab para que no se recree cuando el sistema se reinicie sudo sed -i '/swap/d' /etc/fstab ","categories":"","description":"","excerpt":"Para ciertos escenarios es recomendable desactivar el swap o incluso …","ref":"/docs/unix/desactivar_swap/","tags":["linux"],"title":"Desactivar swap"},{"body":"Podemos insertar, modificar y borrar datos de las tablas a través de consultas de SQL. Podemos usar los comandos INSERT, UPDATE y DELETE.\nImportante, antes de usar cualquiera de estos comandos, debemos indicar la base de datos sobre la que queremos aplicar la operación con el comando USE.\nEjemplo:\nUSE base_de_datos; Insert - Insertar datos Para insertar datos, podemos usar el comando INSERT.\nINSERT INTO \u003ctabla\u003e (\u003catributos\u003e) VALUES (\u003cvalores\u003e); Por ejemplo:\nINSERT INTO persona (nombre, edad, salario) VALUES ('Juan', 30, 1000); Las inserciones se podrían realizar con subconsultas, como por ejemplo, con un select anidado:\nINSERT INTO persona (nombre, edad, salario) VALUES ( 'Juan', 30, (SELECT salario FROM persona WHERE nombre = 'Juan') ); Insert con select - Insertar datos con select Para insertar datos con un select, podemos usar el comando INSERT con la siguiente sintaxis:\nINSERT INTO \u003ctabla\u003e (\u003catributos\u003e) SELECT \u003cvalores\u003e FROM \u003ctabla\u003e; Esto nos permitiría insertar datos de una tabla en otra, por ejemplo:\nINSERT INTO persona (nombre, edad, salario) SELECT nombre, edad, salario FROM persona; También podríamos combinar datos procedentes del SELECT con datos estáticos introducidos manualmente:\nINSERT INTO persona (nombre, edad, salario) SELECT nombre, edad, 1600, FROM persona WHERE nombre = 'Juan'; O hacer operaciones con datos procedentes del SELECT, como por ejemplo, duplicarle el salario a Juan:\nINSERT INTO persona (nombre, edad, salario) SELECT nombre, edad, salario * 2 FROM persona WHERE nombre = 'Juan'; Update - Modificar datos Para modificar datos, podemos usar el comando UPDATE. Cabe destacar el uso del WHERE para especificar que valores queremos actualizar, si no lo especificamos, se actualizarán todos los datos de la tabla. La sintaxis es la siguiente:\nUPDATE \u003ctabla\u003e SET \u003catributos\u003e = \u003cvalores\u003e WHERE \u003ccondiciones\u003e; Por ejemplo, para modificar un atributo de una tabla:\nUPDATE persona SET nombre = 'Pedro' WHERE id = 1; También podríamos actualizar múltiples valores de una fila separándolos por comas:\nUPDATE persona SET nombre = 'Pedro', edad = 30 WHERE id = 1; Delete - Borrar datos Para borrar datos, podemos usar el comando DELETE.\nDELETE FROM \u003ctabla\u003e WHERE \u003ccondiciones\u003e; Por ejemplo:\nDELETE FROM persona WHERE id = 1; ","categories":"","description":"","excerpt":"Podemos insertar, modificar y borrar datos de las tablas a través de …","ref":"/docs/programacion/sql/modificacion_datos/","tags":["sql","mysql"],"title":"Insert, update y delete"},{"body":"En Python, podemos realizar operaciones numéricas de forma muy sencilla. Para ello, utilizamos los operadores aritméticos:\nOperador Descripción + Suma - Resta * Multiplicación / División % Módulo ** Potencia // División entera Suma La operación más sencilla es la suma. Para ello, utilizamos el operador +:\nx = 5 y = 3 print(x + y) # Output: 8 Resta Para realizar una resta, utilizamos el operador -:\nx = 5 y = 3 print(x - y) # Output: 2 Multiplicación En el caso de la multiplicación, utilizamos el operador *:\nx = 5 y = 3 print(x * y) # Output: 15 División En una división, utilizamos el operador /:\nx = 5 y = 3 print(x / y) # Output: 1.6666666666666667 Módulo El módulo es el resto de una división. Para calcularlo, utilizamos el operador %:\nx = 5 y = 3 print(x % y) # Output: 2 División entera La división entera es la división que devuelve el resultado sin decimales. Para calcularla, utilizamos el operador //:\nx = 5 y = 3 print(x // y) # Output: 1 Potencia Podemos calcular la potencia de un número utilizando el operador **:\nx = 5 y = 3 print(x ** y) # Output: 125 Otra forma de calcular la potencia es utilizando la función pow():\nx = 5 y = 3 print(pow(x, y)) # Output: 125 Raíz cuadrada En el caso opuesto a la potencia, podemos calcular la raíz cuadrada de un número utilizando la función sqrt():\nx = 25 y = 5 print(sqrt(x)) # Output: 5.0 ","categories":"","description":"","excerpt":"En Python, podemos realizar operaciones numéricas de forma muy …","ref":"/docs/programacion/python/operaciones/","tags":"","title":"Operaciones numéricas"},{"body":"Por debajo de todas las acciones de kubernetes, lo que el motor entiende, son archivos manifiesto que definen el tipo de cada elemento.\nCuando se coge cierta experiencia se dejan de usar comandos para usar manifiestos y poder aplicar varios a la vez, haciendo el proceso menos tedioso.\nObtener el manifiesto de un pod kubectl get pods \u003cnombre pod\u003e -o \u003cformato\u003e Existen varios formatos de salida pero los más comunes son yaml (el usado nativamente por kubernetes), json, name, go-template (para customizaciones)… https://kubernetes.io/docs/reference/kubectl/overview/#custom-columns\nDefinir un pod en un manifiesto Creamos la definición de un pod de prueba que escribirá “Hello world” cada hora:\napiVersion: v1 kind: Pod metadata: name: myapp-pod labels: app: myapp spec: containers: - name: myapp-container image: busybox command: ['sh', '-c', 'echo Hello World!; sleep 3600'] Luego podríamos crear el elemento con el comando:\nkubectl apply -f pods.yaml También podríamos eliminarlo usando el manifiesto con el comando:\nkubectl deletec-f pods.yaml Multiples contenedores en un pod Podemos definir varios contenedores en un pod. En este ejemplo podemos ver el balanceo que hace kubernetes a nivel de red entre los distintos contenedores de un pod.\napiVersion: v1 kind: Pod metadata: name: doscont spec: containers: - name: cont1 image: python:3.6-alpine command: ['sh', '-c', 'echo \"cont1 \u003e index.html\" \u0026\u0026 python -m http.server 8082'] - name: cont2 image: python:3.6-alpine command: ['sh', '-c', 'echo \"cont2 \u003e index.html\" \u0026\u0026 python -m http.server 8083'] Labels Podemos usar etiquetas para filtrar recursos en proyectos de cierto tamaño. Por ejemplo, separando frontend de backend:\napiVersion: v1 kind: Pod metadata: name: podtest2 labels: app: front env: dev spec: containers: - name: cont1 image: nginx:alpine --- apiVersion: v1 kind: Pod metadata: name: podtest3 labels: app: back env: dev spec: containers: - name: cont1 image: nginx:alpine Ahora para filtrar desde el cli podríamos usar el parámetro “-l” para ello de la siguiente manera:\nkubectl get pod -l app=front Podríamos filtrar por cualquier variable que hayamos definido, también “env”:\nkubectl get pod -l env=dev Incluso multiples labels a la vez:\nkubectl get pod -l app=front,env=dev ","categories":"","description":"","excerpt":"Por debajo de todas las acciones de kubernetes, lo que el motor …","ref":"/docs/contenedores/kubernetes/replicasets/","tags":["kubernetes","devops"],"title":"Replicasets"},{"body":"","categories":"","description":"Servidor de bases de datos y SQL como lenguaje de consultas aplicado\n","excerpt":"Servidor de bases de datos y SQL como lenguaje de consultas aplicado\n","ref":"/docs/programacion/sql/","tags":"","title":"SQL"},{"body":"En este entrada vamos a ver cómo utilizar tmux. Tmux es un multiplexor de terminales que nos permite crear sesiones de terminal, dividirlas en paneles y ventanas, y acceder a ellas desde cualquier terminal.\nInstalación En la mayoría de distribuciones podemos instalar tmux con el gestor de paquetes de la distribución. Por ejemplo, en Ubuntu:\nsudo apt install tmux En macOS podemos instalarlo con brew:\nbrew install tmux Sesiones Para crear una nueva sesión de tmux, ejecutamos el comando tmux:\ntmux Si queremos crear una sesión con un nombre, podemos usar el parámetro -s:\ntmux -s my_session Para listar las sesiones que tenemos abiertas, podemos usar el comando tmux ls:\ntmux ls Para reanudar una sesión, podemos usar el comando tmux attach:\ntmux attach -t my_session Para reanudar la última sesión, podemos usar el comando tmux attach sin parámetros:\ntmux attach Dentro de una sesión, podemos suspenderla con el comando Ctrl+b d. Esto nos permite volver a la sesión más tarde con el comando tmux attach.\n","categories":"","description":"","excerpt":"En este entrada vamos a ver cómo utilizar tmux. Tmux es un multiplexor …","ref":"/docs/unix/tmux/","tags":["terminal","unix"],"title":"Tmux"},{"body":"Los deployments son elementos de configuración que permiten la creación de una aplicación de una sola instancia.\nEl deployment gestiona uno o varios objetos replicaset y estos a su vez gestionan uno o más pods.\nDefinición de un deployment Este es un ejemplo de su estructura básica:\napiVersion: apps/v1 kind: Deployment metadata: name: nginx-deployment labels: app: nginx spec: replicas: 3 selector: matchLabels: app: nginx template: metadata: labels: app: nginx spec: containers: - name: nginx image: nginx:1.7.9 ports: - containerPort: 80 Aplicaría la configuración anterior con el comando:\nkubectl apply -f deployment.yaml Este deployment gestionaría los servicios de replicaset y los contenedores de nginx definidos.\nPodríamos consultar el estado del deployment con el comando:\nkubectl get deployment nginx-deployment El cual nos devolvería una salida similar a la siguiente:\nNAME READY UP-TO-DATE AVAILABLE AGE nginx-deployment 3 3 3 2m Crear un deployment con comandos También podemos crear un deployment con una sola instancia con el comando:\nkubectl create deployment nginx --image=nginx Actualizar un deployment Supongamos que queremos actualizar el deployment para que gestione una nueva imagen, concretamente, las de nginx basadas en alpine. El yaml de configuración quedaría así:\napiVersion: apps/v1 kind: Deployment metadata: name: nginx-deployment labels: app: nginx spec: replicas: 3 selector: matchLabels: app: nginx template: metadata: labels: app: nginx spec: containers: - name: nginx image: nginx:alpine ports: - containerPort: 80 Aplicamos los cambios de nuevo con el comando ‘kubectl apply -f deployment.yaml’ y esta vez nos devuelve que se ha configurado, en vez de crearse:\nkubectl apply -f deployment.yaml deployment.apps/deployment-test configured #Salida del comando Además, kubernetes gestiona las actualizaciones de los deployment para que sean progresivo entre un cambio de versión y el servicio de que dan los pods no se interrumpa.\nSe puede consultar la actualización del deployment en tiempo real con el comando:\nkubectl rollout status deployment nginx-deployment Este comando nos devolvería paso a paso la actualización del deployment:\nWaiting for deployment \"nginx-deployment\" rollout to finish: 1 out of 3 new replicas have been updated... Waiting for deployment \"nginx-deployment\" rollout to finish: 1 out of 3 new replicas have been updated... Waiting for deployment \"nginx-deployment\" rollout to finish: 1 out of 3 new replicas have been updated... Waiting for deployment \"nginx-deployment\" rollout to finish: 2 out of 3 new replicas have been updated... Waiting for deployment \"nginx-deployment\" rollout to finish: 2 out of 3 new replicas have been updated... Waiting for deployment \"nginx-deployment\" rollout to finish: 2 out of 3 new replicas have been updated... Waiting for deployment \"nginx-deployment\" rollout to finish: 1 old replicas are pending termination... Waiting for deployment \"nginx-deployment\" rollout to finish: 1 old replicas are pending termination... deployment \"nginx-deployment\" successfully rolled out Si el despliegue ya ha terminado no se mostrará este proceso de actualización. Aun así, podremos consultarlo en el registro de eventos usando el comando:\nkubectl describe deployment nginx-deployment Events: Type Reason Age From Message ---- ------ ---- ---- ------- Normal ScalingReplicaSet 4m27s deployment-controller Scaled up replica set nginx-deployment-59c46f7dff to 3 Normal ScalingReplicaSet 4m8s deployment-controller Scaled up replica set nginx-deployment-5c4d5dcbf5 to 1 Normal ScalingReplicaSet 4m4s deployment-controller Scaled down replica set nginx-deployment-59c46f7dff to 2 Normal ScalingReplicaSet 4m4s deployment-controller Scaled up replica set nginx-deployment-5c4d5dcbf5 to 2 Normal ScalingReplicaSet 4m2s deployment-controller Scaled down replica set nginx-deployment-59c46f7dff to 1 Normal ScalingReplicaSet 4m2s deployment-controller Scaled up replica set nginx-deployment-5c4d5dcbf5 to 3 Normal ScalingReplicaSet 4m deployment-controller Scaled down replica set nginx-deployment-59c46f7dff to 0 Escalar un deployment Podemos escalar el deployment con el comando:\nkubectl scale deployment nginx-deployment --replicas=5 Historial de un deployment Podemos consultar el historial de un deployment con el comando:\nkubectl rollout history deployment nginx-deployment Modificar el límite del historial de un deployment Por defecto, el historial de un deployment muestra las últimas 10 actualizaciones a menos que modifiquemos el valor ‘revisionHistoryLimit’ en los spec del deployment. Por ejemplo:\napiVersion: apps/v1 kind: Deployment metadata: name: nginx-deployment labels: app: nginx spec: revisionHistoryLimit: 3 replicas: 3 selector: matchLabels: app: nginx ... Hacer un rollback a una versión anterior Es posible hacer un rollback a una versión anterior de un deployment, ya sea porque el último despliegue no funcione o la aplicación tenga errores inesperados. Se podría hacer con el comando:\nkubectl rollout undo deployment nginx-deployment Este comando hace un rollback a la versión anterior del deployment. También podríamos especificarle una versión específica:\nkubectl rollout undo deployment nginx-deployment --to-revision=1 Pausar y reanudar un deployment Podemos pausar un deployment con el comando:\nkubectl rollout pause deployment nginx-deployment Para reanudar un deployment usaremos el comando:\nkubectl rollout resume deployment nginx-deployment ","categories":"","description":"","excerpt":"Los deployments son elementos de configuración que permiten la …","ref":"/docs/contenedores/kubernetes/deployments/","tags":["kubernetes","devops"],"title":"Deployments"},{"body":"Funciones en consultas de selección Estas se utilizan para manipular y filtrar los datos que se devuelven en una consulta. Se pueden usar en las cláusulas WHERE y HAVING pero lo más común es usarlas en las cláusulas SELECT. Esta consulta de ejemplo nos permitiría obtener el salario redondeado de todos los empleados y modificando la salida (sin alterar el registro de la basa de datos):\nSELECT nombre, ROUND(salario) FROM empleados; Funciones aritméticas Nos permiten realizar operaciones aritméticas sobre los valores de los campos.\nOperador Función ABS() Valor absoluto ROUND(n,d) Redondea el valor “n” con con el número de decimales especificados en “d” FLOOR() Redondea hacia abajo CEIL() Redondea hacia arriba SQRT() Raíz cuadrada POW() Potencia, ejemplo POW(x,y) el valor x elevado a el exponente y Funciones de cadenas de texto Nos permiten manipular textos de las consultas.\nOperador Función CONCAT() Concatena dos o más cadenas de texto SUBSTRING(c,m,n) Devuelve una sub-cadena obtenida de la cadena “c”, a partir de la posición “m” y tomando “n” caracteres. LENGTH() Devuelve la longitud de una cadena de texto UCASE() Convierte una cadena de texto a mayúsculas LCASE() Convierte una cadena de texto a minúsculas REPLACE(c,b,s) Reemplaza en la cadena “c” el valor buscado en “b” por el valor indicado en “s” TRIM() Elimina los espacios en blanco de una cadena de texto REPLICATE(c,n) Repite la cadena “c” tantas veces como indique la variable “n” Funciones de fecha Nos permiten manipular fechas de las consultas.\nOperador Función DATE() Convierte una fecha a una cadena de texto DATE_FORMAT() Convierte una fecha a un formato de cadena de texto NOW() Devuelve la fecha actual YEAR() Devuelve el año de una fecha MONTH() Devuelve el mes de una fecha QUARTER() Devuelve el trimestre del año de una fecha DAY() Devuelve el día de una fecha HOUR() Devuelve la hora de una fecha MINUTE() Devuelve los minutos de una fecha SECOND() Devuelve los segundos de una fecha ","categories":"","description":"","excerpt":"Funciones en consultas de selección Estas se utilizan para manipular y …","ref":"/docs/programacion/sql/funciones_en_consultas/","tags":["database","mysql"],"title":"Funciones en consultas"},{"body":"","categories":"","description":"Kubernetes","excerpt":"Kubernetes","ref":"/docs/contenedores/kubernetes/","tags":"","title":"Kubernetes"},{"body":"Hay momentos en los que una consulta necesita columnas de varias tablas. En este caso podremos definir en el FROM todas las tablas que queremos usar.\nSELECT * FROM tabla1, tabla2, tabla3; Si lo hacemos de esta forma, nos devolverá todos los registros de las tablas pero al no haberlas relacionado nos mostrará los registros de cada unos de ellas combinados entre sí. Estos datos no tendrían coherencia.\nVeamos un ejemplo, vamos a usar las tablas empleados y la tabla departamentos:\nEMPLEADOS\nid nombre apellidos departamento_id 1 Pepe Pérez 1 2 Ana Muñoz 1 3 Juan González 2 4 María Rubio 2 DEPARTAMENTOS\nid nombre 1 Ingeniería 2 Finanzas Si quisiéramos mostrar los empleados junto con los nombres de su departamento, podríamos hacerlo de la siguiente forma:\nSELECT empleados.nombre, empleados.apellidos, departamentos.nombre FROM empleados, departamentos WHERE empleados.departamento_id = departamentos.id; Cuando seleccionamos datos de varias tablas tenemos que difinir en el WHERE la relación entre ellas. En este caso, el id de la tabla empleados y el departamento_id de la tabla departamentos porque es la única forma de mostrar el nombre del departamento al que pertenece cada empleado.\nJOIN El JOIN es una forma de relacionar dos tablas y tiene varios comandos. La consulta anterior es un ejemplo de INNER JOIN realizado con un WHERE. Existen varios tipos de JOIN en función de la información que quieras obtener de dos tablas relacionadas.\nEl más común es el INNER JOIN que nos permite obtener los registros de una tabla que están relacionados con otra.\nAunque son los más comunes, hay más tipos de los que se muestran en la representación visual. De momento nos centraremos en los más comunes:\nINNER JOIN El INNER JOIN nos permite seleccionar los registros que tengan coincidencias en ambas tablas, es decir, que estén relacionados. Para ello, en el FROM seleccionamos la tabla de la que queremos obtener los registros y en el JOIN seleccionamos la tabla con la que queremos relacionar. Por último, tendríamos que definir en el ON del JOIN la relación entre ambas tablas de la misma forma que en el WHERE de la consulta anterior.\nEjemplo:\nSELECT empleados.nombre, empleados.apellidos, departamentos.nombre FROM empleados JOIN departamentos ON empleados.departamento_id = departamentos.id; LEFT JOIN El LEFT JOIN nos permite seleccionar todos los registros de la tabla de la izquierda junto con los registros de la tabla de la derecha que tengan coincidencias.\nEjemplo de uso:\nSELECT empleados.nombre, empleados.apellidos, departamentos.nombre FROM empleados LEFT JOIN departamentos ON empleados.departamento_id = departamentos.id; RIGHT JOIN El RIGHT JOIN nos permite seleccionar todos los registros de la tabla de la derecha junto con los registros de la tabla de la izquierda que tengan coincidencias.\nEjemplo de uso:\nSELECT empleados.nombre, empleados.apellidos, departamentos.nombre FROM empleados RIGHT JOIN departamentos ON empleados.departamento_id = departamentos.id; FULL JOIN El FULL JOIN nos permite seleccionar todos los registros de la tabla de la izquierda junto con los registros de la tabla de la derecha aunque no tengan coincidencias.\nEjemplo de uso:\nSELECT empleados.nombre, empleados.apellidos, departamentos.nombre FROM empleados FULL JOIN departamentos ON empleados.departamento_id = departamentos.id; ","categories":"","description":"","excerpt":"Hay momentos en los que una consulta necesita columnas de varias …","ref":"/docs/programacion/sql/combinacion_joins/","tags":["database","mysql"],"title":"Combinación de tablas. Joins"},{"body":"Los servicios en kubernetes son una forma de agrupar pods mediande sus etiquetas o labels y disponer a los usuarios el acceso a los recursos que están asociados a ellos.\nLos pods en kubernetes son efímeros y cambiaran frecuentemente, con ellos, tambien sus IPs por lo que los servicios entregan una IP única (también tiene DNS), además de balancear las peticiones entre los pods que están asociados a un servicio.\nPartiendo del deployment anterior podemos crear un servicio de la misma forma:\napiVersion: v1 kind: Service metadata: name: nginx-service labels: app: nginx spec: selector: app: nginx ports: - port: 8080 targetPort: 80 Es importante destacar que el selector del servicio tiene que igual al label del deployment para que este funcione.\nHaciendo foco en la declaración del servicio tambien hay que destacar que, la instrucción port indica el puerto al que va a escuchar el servicio, y targetPort indica el puerto del pod al que el servicio va a enviar las peticiones.\nPodemos consultar el estado del servicio con el comando:\nkubectl get service nginx-service kubectl get svc nginx-service # Podemos abreviar el comando anterior Podemos describir el servicio con el comando:\nkubectl describe svc nginx-service Esto nos devolvería una salida similar a la siguiente:\nName: nginx-service Namespace: default Labels: app=front Annotations: \u003cnone\u003e Selector: app=front Type: ClusterIP IP Family Policy: SingleStack IP Families: IPv4 IP: 10.98.234.17 IPs: 10.98.234.17 Port: \u003cunset\u003e 8080/TCP TargetPort: 80/TCP Endpoints: 172.17.0.3:80,172.17.0.4:80,172.17.0.5:80 Session Affinity: None Events: \u003cnone\u003e Endpoints Uno de los datos más interesantes de la salida anterior en el campo Endpoints. Este recoge las IPs de los pods con los que esta conectando el servicio para automatizar que el usuario pueda acceder a ellos.\nAdemás, si algún pod nuevo aparece o desaparece el servicio sabría y actualizaría los endpoints.\nTambién podríamos listar todos los endpoints del namespace con el commando:\nkubectl get endpoints Podríamos abreviar el comando anterior (con ep) y a la vez consultar específicamente el endpoint de un servicio:\nkubectl get ep nginx-service Tipos de servicios La jerarquía de los servicios es la siguiente:\nClusterIP Es el servicio por defecto en kubernetes, en caso de que no especifiquemos ningún otro. Su función es crear una conexión a los pods sin exponerlos a la red externa.\nSi listamos los servicios podemos ver que, el servicio nginx-service que lanzamos antes, tiene la IP del cluster asignada pero la IP externa se queda con el valor none.\nkubectl get service NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE kubernetes ClusterIP 10.96.0.1 \u003cnone\u003e 443/TCP 19d nginx-service ClusterIP 10.98.234.17 \u003cnone\u003e 38080/TCP 10h NodePort Es un servicio que conecta un puerto de nodo (red externa) a un puerto de uno o más pods.\nSi no le especificamos un puerto, el servicio utiliza uno en el rango del 30000 al 32767.\nPara crear un servicio de tipo NodePort solo tenemos que indicarlo en el type dentro del spec del servicio:\napiVersion: 1 kind: Service metadata: name: nginx-service labels: app: front spec: type: NodePort # Definición del tipo de servicio selector: app: front ports: - port: 8080 targetPort: 80 Este tipo también crea una IP del cluster, pero en este caso también abre un puerto a la red externa.\nLoadBalancer Sirve para exponer servicios a través de la red externa. Podría ser utilizado para exponer servicios web, servicios de bases de datos, etc.\nSe podría definir un servicio de tipo LoadBalancer con el siguiente comando para un deployment específico:\nkubectl expose deployment nginx-deployment --type=LoadBalancer Accediendo a una aplicación con un servicio Podríamos crear un servicio vía kubectl:\nkubectl expose deployment/nginx --port=80 --type=NodePort Podemos consultar los servicios con los siguientes comandos:\nkubectl get svc # Listar todos los servicios kubectl get svc nginx -o yaml # Listar un servicio concreto Borrar endpoints Podemos borrar un endpoint con el comando:\nkubectl delete endpoint nginx kubectl delete ep nginx # Podemos abreviar el comando anterior ","categories":"","description":"","excerpt":"Los servicios en kubernetes son una forma de agrupar pods mediande sus …","ref":"/docs/contenedores/kubernetes/services/","tags":["kubernetes","devops"],"title":"Services"},{"body":"El ingress controller es un servicio que se ejecuta en un pod y que permite observar los objetos endpoint. Cuando un nuevo objeto es creado, ingress controller lo detecta y aplica las reglas que tenga definidas para enrutar el tráfico (normalmente HTTP).\nEn resumen, permite enrutar tráfico desde fuera de un cluster a los servicios del mismo.\nCualquier tecnología que sirviera como proxy inverso se puede utilizar como ingress controller. Uno de los más comunes es nginx.\nEjemplos de configuración de nginx para diferentes plataformas ( docker desktop, minikube, AWS, GCP, Azure…)\nInstalación de un ingress controller Podemos instalar el ingress controller basado en nginx con helm. En esta página tengo la documentación sobre Helm.\nPrimero añadimos el repositorio de ingress-nginx y actualizamos:\nhelm repo add ingress-nginx https://kubernetes.github.io/ingress-nginx helm repo update Descargamos el chart:\nhelm fetch ingress-nginx/ingress-nginx --untar Modificamos el fichero values.yaml y en la línea que pone kind: Deployment actualizamos el valor por DaemonSet quedando así:\n## DaemonSet or Deployment kind: DaemonSet Instalamos el chart que acabamos de modificar:\nhelm install myingress . Ahora ya podemos añadir objetos de tipo ingress en kubernetes.\nManifiesto de kubernetes Podemos declarar el objeto del manifiesto de kubernetes como en el siguiente ejemplo:\napiVersion: networking.k8s.io/v1beta1 kind: Ingress metadata: rules: - host: \u003chostname\u003e http: paths: - backend: service: name: \u003cnombre\u003e port: number: \u003cpuerto\u003e path: / pathType: ImplementationSpecific Gestión de objetos ingress Los principales comando de gestión son:\nkubectl get ingress kubectl delete ingress \u003cnombre\u003e kubectl edit ingress \u003cnombre\u003e ","categories":"","description":"","excerpt":"El ingress controller es un servicio que se ejecuta en un pod y que …","ref":"/docs/contenedores/kubernetes/ingress_controller/","tags":["kubernetes"],"title":"Ingress Controller"},{"body":"Los Jobs en kubernetes son una forma de automatizar tareas en kubernetes. A diferencia de los Pods, los Jobs tienen número de ejecuciones definido y un tiempo de ejecución limitado.\nEstos recursos se suelen utilizar para tareas de mantenimiento que se ejecutan de forma puntual y recurrente.\nSintaxis básica Este sería un ejemplo de sintáxis básica de un Job:\napiVersion: batch/v1 kind: Job metadata: name: test-job spec: completions: 5 # Número de ejecuciones template: spec: containers: - name: test image: busybox command: [\"/bin/sleep\"] args: [\"3\"] restartPolicy: Never El parámetro diferenciador del Jobs frente a los Pods es el completions. Este define el número de ejecuciones que se realizarán y una vez que se alcanza el número de ejecuciones, el Job se detendrá.\nSi vemos el estado de un Job en kubernetes, podemos ver que está en estado Pending si no se ha iniciado, Running si se está ejecutando y Succeeded si se ha terminado con éxito.\n","categories":"","description":"","excerpt":"Los Jobs en kubernetes son una forma de automatizar tareas en …","ref":"/docs/contenedores/kubernetes/jobs/","tags":["kubernetes","devops"],"title":"Jobs"},{"body":"Namespaces Los namespaces son una forma de agrupar y aislar los recursos de kubernetes. Esto permite que podamos segregar los diferentes recursos de una aplicación ( pod, deployment, service, etc) para establecer unas cuotas recursos, políticas de seguridad y configuraciones específicas.\nPor omisión, kubernetes crea un namespace llamado default que es el namespace por defecto.\nListar namespaces Podemos listar los namespaces con el comando:\nkubectl get ns Esto nos muestra nuestro namespace por defecto y los namespaces del sistema de kubernetes (no tocar estos namespaces):\nNAME STATUS AGE default Active 26d kube-node-lease Active 26d kube-public Active 26d kube-system Active 26d Puede ser interesante listar los namespaces junto con sus `labels``:\nkubectl get ns --show-labels Este comando nos muestra nuestros namespaces de la siguiente forma:\nNAME STATUS AGE LABELS default Active 26d kubernetes.io/metadata.name=default kube-node-lease Active 26d kubernetes.io/metadata.name=kube-node-lease kube-public Active 26d kubernetes.io/metadata.name=kube-public kube-system Active 26d kubernetes.io/metadata.name=kube-system Crear un namespace Podemos crear un namespace simplemente con el comando:\nkubectl create ns \u003cnombre-namespace\u003e Aún así, también también lo podemos crear con un fichero de configuración (este en formato json) para dejarlo definido como código:\n{ \"apiVersion\": \"v1\", \"kind\": \"Namespace\", \"metadata\": { \"name\": \"development\", \"labels\": { \"name\": \"development\" } } } Para utilizar este json de configuración podemos utilizar el comando:\nkubectl create -f \u003cfichero-json\u003e Borrar un namespace Podemos borrar un namespace con el comando:\nkubectl delete ns \u003cnombre-namespace\u003e Cambiar de namespace y contextos Podríamos ejecutar comandos en cualquier namespace añadiendo el parámentro --namespace o -n a cualquier comando, por ejemplo:\nkubectl get pods --namespace development El proceso anterior sería más farragoso, excepto que queramos lanzar un comando puntual en un namespace concreto, es más recomendable utilizar la configuración de contexto de kubectl:\nkubectl config set-context \u003cnombre-context\u003e --namespace=\u003cnombre-namespace\u003e Así estaríamos asociando un namespace a un contexto.\nContext Los contextos en kubernetes permiten definir a nuestro cliente diferentes entornos a los que conectarse. Estos entornos puedes ser namespaces o clusters diferentes.\nPodemos ver nuestra configuración con el comando:\nkubectl config view Esto nos mostrará nuestra configuración de organizada de la siguiente manera:\napiVersion: v1 kind: Config preferences: {} clusters: - cluster: name: development - cluster: name: scratch users: - name: developer - name: experimenter contexts: - context: name: dev-frontend user: developer cluster: development - context: cluster: scratch namespace: develop user: experimenter name: scratch-frontend Podemos distinguir tres elementros de la configuración:\nClusters: definen los clusters a los que podemos conectarnos. Users: definen los usuarios que podemos utilizar para conectarnos a los clusters. Contexts: definen los contextos a los que podemos conectarnos. Estos contextos guardan la relación de usuario, cluster y namespace. Esta organización nos permite definir clusters y usuarios individualmente y luego ir asociándolos en contexto concretos.\nEste fichero de configuración se suele alojar en el directorio ~/.kube/config. Podemos añadir una nueva configuración editando el fichero o usando el comando:\nkubectl config set-context \u003cnombre del contexto\u003e --namespace=\u003cnombre namespace OPCIONAL\u003e \\ --cluster=\u003cnombre del cluster\u003e \\ --user=\u003cusuario\u003e Definir usuario Se puede definir un usuario con el comando en nuestro fichero de configuración con el siguiente comando:\nkubectl config set-credentials \u003cnombre-usuario\u003e --client-certificate=\u003ccertificado\u003e --client-key=\u003cclave\u003e Definir un cluster También podemos definir por comandos clusters:\nkubectl config set-cluster \u003cnombre-cluster\u003e --server=\u003curl del cluster\u003e --certificate-authority=\u003ccertificado-autoridad\u003e ","categories":"","description":"","excerpt":"Namespaces Los namespaces son una forma de agrupar y aislar los …","ref":"/docs/contenedores/kubernetes/namespaces/","tags":["kubernetes","devops"],"title":"Namespaces y context"},{"body":"Un disparador o trigger es un tipo de procedimiento almacenado que se ejecuta cuando se intentan alterar los datos de una tabla o vista. La diferencia con los procedimientos almacenados es que los disparadores:\nNo pueden ser invocados directamente. El disparador se ejecuta automáticamente. No reciben y devuelven parámetros. Son apropiados para mantener la integridad de los datos, no para obtener resultados de consultas Su función es ejecutarse cuando ocurre algún evento en una tabla. Estos eventos pueden ser insertar, modificar o borrar datos ( INSERT, UPDATE, DELETE ).\nSintaxis básica Antes de empezar, hay que detallar algunos variables que se usarán en el siguiente ejemplo:\nNombre del disparador (name): Nombre del disparador. Tiempo del disparador (time)[ AFTER o BEFORE ]: se puede especificar cuando se ejecuta el disparador. Antes o después de la ejecución de la consulta. Evento (evento)[ INSERT, UPDATE o DELETE ]: se puede especificar el evento en el que se desea que se ejecute el disparador. Nombre de la tabla (nombre_tabla): se puede especificar el nombre de la tabla en la que se desea que se ejecute el disparador. Orden del trigger (orden opcional) [ FOLLOWS o PRECEDES ]: se puede especificar el orden en el que se desea que se ejecute el disparador. Cuerpo del disparador (cuerpo): se puede especificar el cuerpo del disparador. La sintaxis de un disparador es la siguiente:\nCREATE TRIGGER \u003cname\u003e \u003ctime\u003e \u003cevento\u003e ON \u003cnombre_tabla\u003e FOR EACH ROW BEGIN \u003ccuerpo\u003e END; Por ejemplo:\nCREATE TRIGGER tr_insert_persona AFTER INSERT ON persona FOR EACH ROW BEGIN \u003ccuerpo\u003e END; Cuerpo del disparador El cuerpo del disparador es el código que se ejecuta cuando se lanza el disparador. Dentro de un disparador nos podemos referir a los datos que se están insertando, modificando o borrando. Esto nos permite evitar que se borren o modifiquen datos indeseados; aplicar condiciones como por ejemplo, que haya stock suficiente para un producto.. etc.\nEl cuerpo del disparador se puede definir en varias partes. En cada parte se puede definir una sentencia SQL.\nPor ejemplo, controlar la edad de una persona para evitar que se inserten menores de edad:\nCREATE TRIGGER tr_insert_persona BEFORE UPDATE ON persona FOR EACH ROW BEGIN IF NEW.edad \u003c 18 THEN UPDATE persona SET edad = 18 WHERE id = NEW.id; END IF; END; En el cuerpo podemos definir variables, condiciones, sentencias SQL, etc.\nPor ejemplo, un disparador en el que consultamos y almacenamos en variables datos de otras tablas:\nCREATE TRIGGER tr_insert_persona AFTER INSERT ON persona FOR EACH ROW BEGIN DECLARE nombre_mascota VARCHAR(50); SET nombre_mascota = (SELECT nombre FROM mascotas WHERE id = NEW.id); INSERT INTO persona_mascota (id, nombre, edad, fecha_nacimiento, ) VALUES (NEW.id, nombre_mascota, NEW.edad, NEW.fecha_nacimiento); END; #TODO: Diferencias entre NEW y OLD…\n","categories":"","description":"","excerpt":"Un disparador o trigger es un tipo de procedimiento almacenado que se …","ref":"/docs/programacion/sql/triggers/","tags":["mysql","database"],"title":"Trigger o disparador"},{"body":"Introducción Con el fin de mejorar la eficiencia y reutilizar las consultas SQL, se ha desarrollado una serie de procedimientos y funciones que permiten realizar operaciones de forma más eficiente.\nEstos objetos se almacena en la base de datos y se pueden utilizar en las consultas SQL.\nProcedimientos y funciones Sus principales diferencias son:\nValores de retorno: Los procedimientos no tienen porque retornar ningún valor, mientras que las funciones siempre retornan un valor. Tipos de valores de retorno: Los procedimientos pueden mostrar resultados de cualquier tipo (listas, tablas), mientras que las funciones siempre retornan un valor concreto (int, varchar, etc.). Parámetros: Los procedimientos pueden tener parámetros múltiples valores de entrada y salida (in, out, inout), mientras que las funciones siempre tienen un solo parámetro de entrada y un valor de salida. Procedimientos Los procedimientos son rutinas o subprogramas compuestos por un conjunto nombrado de sentencias SQL agrupados lógicamente para realizar una tarea específica, que se guardan en la base de datos y que se ejecutan como una unidad cuando son invocados por su nombre. Es decir, nos permiten agrupar un conjuntos de sentencias para lanzarlas en bloque.\nEl procedimiento consta de las siguientes partes:\nDefinición del nombre del procedimiento. Parámetros de entrada o salida Sentencias SQL Sintaxis básicas de procedimientos almacenados:\nCREATE PROCEDURE \u003cnombre_procedimiento\u003e ( \u003cparametro_entrada\u003e \u003ctipo\u003e \u003cparametro_entrada\u003e \u003ctipo\u003e ... ) ... Los parámetros de entrada pueden ser de los siguientes tipos:\nIN: De entrada OUT: De salida INOUT: De entrada y salida Un ejemplo completo sería el siguiente:\nCREATE PROCEDURE procedimiento_ejemplo (IN nombre VARCHAR(50), OUT edad INT) BEGIN SELECT edad INTO edad FROM usuarios WHERE nombre = nombre ; END Podemos ejecutar el procedimiento usando la siguiente sintaxis:\nCALL \u003cnombre_procedimiento\u003e(\u003cparametro_entrada\u003e, \u003cparametro_salida\u003e) Por ejemplo, para ejecutar el procedimiento anterior:\nCALL procedimiento_ejemplo('Pablo', @edad); Funciones Las funciones son rutinas o subprogramas compuestos por un conjunto. Estas siempre tiene un valor de retorno, el cuál, cuyo tipo depende de la declaración de la función con la sintaxis RETURNS \u003ctipo\u003e y luego en el cuerpo de la función se devuelve con la instrucción RETURN \u003cvalor\u003e.\nPor ejemplo, la siguiente función devuelve el nombre de un usuario. Primero hacemos un select que asigna el resultado a una variable y luego hacemos que la función devuelva el valor de la variable.\nCREATE FUNCTION nombre_usuario (id_usuario INT) RETURNS VARCHAR(50) BEGIN DECLARE nombre_obtenido VARCHAR(50); SELECT nombre INTO nombre_obtenido FROM usuarios WHERE id_usuario = id_usuario; RETURN nombre_obtenido; END Podemos ejecutar la función usando un select:\nSELECT nombre_usuario(1); Borrado de procedimientos y funciones Para borrar un procedimiento o función, se utiliza la siguiente sintaxis:\nDROP PROCEDURE \u003cnombre_procedimiento\u003e DROP FUNCTION \u003cnombre_funcion\u003e También se puede borrar un procedimiento o función solo si existe:\nDROP PROCEDURE IF EXISTS \u003cnombre_procedimiento\u003e DROP FUNCTION IF EXISTS \u003cnombre_funcion\u003e ","categories":"","description":"","excerpt":"Introducción Con el fin de mejorar la eficiencia y reutilizar las …","ref":"/docs/programacion/sql/procedimientos_funciones/","tags":["sql","mysql"],"title":"Procedimientos y funciones"},{"body":"Cifrar y descifrar datos es una tarea muy común en la programación. En este artículo vamos a ver como hacerlo en MySQL.\nCifrado sin reversibilidad Estos métodos de cifrado no permiten descifrar el texto cifrado. Es decir, no se puede obtener el texto original a partir del texto cifrado. Se utilizan para almacenar contraseñas en la base de datos. El valor cifrado se llama hash. Este hash se puede comparar con otro hash para comprobar si la contraseña es correcta o no. Así se evita que un atacante pueda obtener las contraseñas de los usuarios.\nSHA1 El algoritmo SHA1 es un algoritmo de cifrado sin reversibilidad. Se utiliza para generar hashes de 40 caracteres. El hash se genera a partir de un texto plano. El texto plano no se puede obtener a partir del hash.\nSELECT SHA1('texto_plano'); Cifrados con reversibilidad Estos métodos de cifrado permiten descifrar el texto cifrado. Es decir, se puede obtener el texto original a partir del texto cifrado. Se utilizan para almacenar datos sensibles en la base de datos.\nPara cifrar y descifrar datos en MySQL se utiliza la función AES_ENCRYPT y AES_DECRYPT. Estas funciones requieren de una clave de cifrado. Esta clave debe ser la misma para cifrar y descifrar los datos.\nEjemplo:\nSELECT AES_ENCRYPT('texto_plano', 'clave_cifrado'); SELECT AES_DECRYPT('texto_cifrado', 'clave_cifrado'); ","categories":"","description":"","excerpt":"Cifrar y descifrar datos es una tarea muy común en la programación. En …","ref":"/docs/programacion/sql/cifrar_descifrar/","tags":["mysql"],"title":"Cifrar y descifrar"},{"body":"Un cursor es una consulta declarada que provoca que el servidor, cuando se realiza la operación de abrir cursor, cargue en memoria los resultados de la consulta en una tabla interna. Teniendo abierto el cursor, es posible, mediante una sentencia FETCH, leer una a una las filas correspondientes al cursor y, por tanto, correspondientes a la consulta definida. Los cursores deben declararse después de las variables locales.Los cursores nos permiten tras una consulta SQL, recuperar los resultados de la misma y poder trabajar con ellos de uno en uno.\nPara hacer uso de un cursor, tendremos que:\nDeclarar el cursor (después de las variables locales). Abrir el cursor. Asignar las filas al cursor según tarea a realizar. Cerrar el cursor una vez finalizada la tarea (CLOSE) Los cursores se usan dentro de procedimientos y funciones\nSintaxis básica Este cursor nos permite leer uno a uno los resultados de una consulta para trabajar con los datos. Cabe destacar la necesidad de abrir y cerrar el cursor (OPEN y CLOSE).\nPodemos leer los valores de un cursor con el comando FETCH:\nDECLARE \u003cvariable\u003e \u003ctipo\u003e DECLARE \u003cnombre_cursor\u003e CURSOR FOR \u003cconsulta\u003e; OPEN \u003cnombre_cursor\u003e; FETCH \u003cnombre_cursor\u003e INTO \u003cvariable\u003e; CLOSE \u003cnombre_cursor\u003e; Uso con repetición/bucles Al leer los valores de un cursor, podemos repetir el proceso de leer los valores de un cursor. Para ello, podemos usar el comando FETCH repetidamente:\nDECLARE \u003cnombre_cursor\u003e CURSOR FOR \u003cconsulta\u003e; OPEN \u003cnombre_cursor\u003e; FETCH \u003cnombre_cursor\u003e INTO \u003cvariable\u003e; FETCH \u003cnombre_cursor\u003e INTO \u003cvariable\u003e; FETCH \u003cnombre_cursor\u003e INTO \u003cvariable\u003e; FETCH \u003cnombre_cursor\u003e INTO \u003cvariable\u003e; CLOSE \u003cnombre_cursor\u003e; Pero si quisieramos leer todos los valores de un cursor, lo normal es hacer un bucle para no estar repitiendo la misma operación tantas veces como filas tenga el cursor.\nCon repeat until - hasta que Para leer valores hasta un momento específico, podemos usar el comando REPEAT UNTIL. Vamos a suponer en este caso que queremos sumar el precio de los 5 primeros resultados de un SELECT.\nDECLARE total INT DEFAULT 0; DECLARE precio INT DEFAULT 0; DECLARE contador INT DEFAULT 1; DECLARE cursor1 CURSOR FOR SELECT precio FROM productos; OPEN cursor1; REPEAT FETCH cursor1 INTO precio; SET total = total + precio; SET contador = contador + 1; UNTIL contador \u003e 5; END REPEAT; CLOSE cursor1; Con loop - todos los valores Para leer todos los valores de un cursor, podemos usar el comando LOOP. Vamos a suponer en este caso que queremos sumar el precio de todos los resultados de un SELECT. Para ello, podemos usar el comando LOOP. Aún así, tenemos que ayudar a nuestro programa para que sepa cuando termina de leer los valores. Para ello, utilizamos un HANDLER para saber cuando no hay valores y utilizar una variable auxiliar para decirle al programa que salga del LOOP.\nCuando el handler detecta que no hay valores, el HANDLER añade a la variable auxiliar el valor 1. Como el bucle LOOP al principio de la sentencia comprueba si la variable auxiliar es igual a uno, saldría del programa gracias a la intrucción LEAVE \u003cnombre del bucle\u003e.\nDECLARE total INT DEFAULT 0; DECLARE precio INT DEFAULT 0; DECLARE auxiliar INT DEFAULT 0; DECLARE cursor1 CURSOR FOR SELECT precio FROM productos; DECLARE CONTINUE HANDLER FOR NOT FOUND SET auxiliar = 1; OPEN cursor1; bucle:LOOP FETCH cursor1 INTO precio; IF auxiliar = 1 THEN LEAVE bucle; END IF; SET total = total + precio; END LOOP:bucle; CLOSE cursor1; ","categories":"","description":"","excerpt":"Un cursor es una consulta declarada que provoca que el servidor, …","ref":"/docs/programacion/sql/cursores/","tags":["mysql"],"title":"Cursores"},{"body":"Kubernetes nos permite compartir información y configuraciones entre el cluster y los distintos recursos de kubernetes.\nSecrets Los secretos en kubernetes son una forma de almacenar información sensible. Estos se almacenan en una base de datos de forma privada y pueden consumir por otros recursos de kubernetes.\nPodemos obtener, crear o eliminar secretos en kubernetes con los siguientes comandos.\nListar secretos:\nkubectl get secrets Crear secretos:\n# Create a new secret named my-secret with keys for each file in folder bar kubectl create secret generic my-secret --from-file=path/to/bar # Create a new secret named my-secret with specified keys instead of names on disk kubectl create secret generic my-secret --from-file=ssh-privatekey=path/to/id_rsa --from-file=ssh-publickey=path/to/id_rsa.pub # Create a new secret named my-secret with key1=supersecret and key2=topsecret kubectl create secret generic my-secret --from-literal=key1=supersecret --from-literal=key2=topsecret # Create a new secret named my-secret using a combination of a file and a literal kubectl create secret generic my-secret --from-file=ssh-privatekey=path/to/id_rsa --from-literal=passphrase=topsecret # Create a new secret named my-secret from an env file kubectl create secret generic my-secret --from-env-file=path/to/bar.env Borrar un secreto:\nkubectl delete secret \u003cnombre\u003e Usando secretos en un pod Un secreto se puede usar en un pod. Podríamos pasarlo como una variable de entorno como en el siguiente ejemplo:\n... spec: containers: - image: mysql:5.5 name: dbpod env: - name: MYSQL_ROOT_PASSWORD valueFrom: secretKeyRef: name: mysql key: password También podríamos montarlo como un volumen en su manifest. Este Requeriría el path donde estamos montando un fichero con el contenido del secreto. Mounting Secrets as Volumes You can also mount secrets as files using a volume definition in a pod manifest. The mount path will contain a file whose name will be the key of the secret created with the kubectl create secret step earlier.\n... spec: containers: - image: busybox command: - sleep - \"3600\" volumeMounts: - mountPath: /mysqlsecret name: mysqlsecret name: busy volumes: - name: mysqlsecret secret: secretName: mmysql Crea un configmap Dado el caracter efímero de un pod en kubernetes necesitamos algún método para compartir ficheros o información entre los contenedores dentro de un pod.\nCrear un configmap con comandos Para crear un config map usamos el siguiente comando:\nkubectl create configmap \u003cnombre\u003e \\ --from-literal=text=\u003ctexto\u003e \\ --from-file=\u003cfichero\u003e \\ --from-file=\u003cdirectorio\u003e Este nos permite importar información ya sea text en plano que introduzcamos en el comando (--from-literal=text=), el contenido de un fichero (--from-file=) o el contenido de un directorio completo (--from-file=).\nPodemos consultar el contenido de un configmap con el siguiente comando:\nkubectl get configmap \u003cnombre\u003e Aunque este solo nos mostrará el total de datos y su edad. Podemos obtener el contenido completo especificando la salida en formato yaml:\nkubectl get configmap \u003cnombre\u003e -o yaml Crear un configmap con yaml Podríamos declararlo como un yaml para facilitar el almacenamiento de la configuración como código.\napiVersion: v1 kind: ConfigMap metadata: name: cars namespace: default data: car.make: Opel car.model: Astra car.trim: OPC Para guardar el configmap en el cluster podemos usar el comando:\nkubectl create -f \u003cconfigmap\u003e.yaml Usar configmap en un pod Utilizar en el entorno de un pod Podemos configurar el contenido de un configmap en un pod como variable de entorno así:\napiVersion: v1 kind: Pod metadata: name: demo spec: containers: - name: nginx image: nginx env: - name: \u003cnombre de la variable de entorno\u003e valueFrom: configMapKeyRef: name: \u003cnombre_configmap\u003e key: \u003cclave a usar\u003e Esto nos permitiría importar una única clave del configmap.\nTambién podríamos importar todo el contenido del configmap así:\napiVersion: v1 kind: Pod metadata: name: demo spec: containers: - name: nginx image: nginx envFrom: - configMapRef: name: \u003cnombre_configmap\u003e Cambiaríamos el configMapKeyRef por configMapRef y env por envFrom. Por último, borraríamos key y valueFrom datos que ya no tendríamos que especificar.\nMontar como volumen en un pod Podemos montar un configmap como un volumen en un pod. Esta sería una configuración de ejemplO:\napiVersion: v1 kind: Pod metadata: name: shell-demo spec: containers: - name: nginx image: nginx volumeMounts: - name: car-vol mountPath: /etc/cars volumes: - name: car-vol configMap: name: cars Borrar un configmap Podemos elimitar este objeto de kubernetes con el comando:\nkubectl delete ","categories":"","description":"","excerpt":"Kubernetes nos permite compartir información y configuraciones entre …","ref":"/docs/contenedores/kubernetes/secrets_configmaps/","tags":["kubernetes","secrets"],"title":"Secrets y configmaps"},{"body":"En kubernetes existe la posibilidad de crear volumenes para persistir los datos de los pods. Estos se agrupan en dos objetos:\nPV: “Persistent Volume”, es la declaración de un espacio del host que el cluster va a reservar para su uso. PVC: “Persistent Volume Claim” es la petición de reserva de espacio de un PV para un uso más especifico, por ejemplo, para un único proyecto. Esta asiganación de espacio se realiza a dos niveles para reservar espacio para el cluster por un lado (PV) y luego se utilizan los objetos (PVC) para repartir ese espacio entre diferentes proyectos (namespaces) u objetos.\nPersistent Volume (PV) Estos permiten múltiples configuraciones en función del tipo de cluster. En entornos de nube lo normal suele ser usar almacenamiento nativo del proveedor. En este ejemplo lo haremos utilizando un volumen NFS totalmente válido para infraestructura no gestionada por un proveedor cloud.\nEn esta entrada explico como trabajar con NFS (solo es necesaria la parte de servidor). NFS en Linux\nUna vez que tenemos configurado el volumen NFS podemos configurarlo como volumen persistente en kubernetes con una configuración como la siguiente:\napiVersion: v1 kind: PersistentVolume metadata: name: pvvol spec: capacity: storage: 40Gi accessModes: - ReadWriteMany persistentVolumeReclaimPolicy: Retain nfs: path: /ruta/carpeta/nfs server: \u003chost\u003e #Puede ser un disco local o remoto readOnly: false Persistent Volume Claim Los claim sirve para hacer peticiones de espacio al cluster para que pueda ser consumido por un pod.\nPodemos consular los PVC existentes con el comando:\nkubectl get pvc Para crear un objeto PVC podemos usar un fichero de configuración como el siguiente:\napiVersion: v1 kind: PersistentVolumeClaim metadata: name: pvc-test spec: accessModes: - ReadWriteMany resources: requests: storage: 200Mi Aplicaríamos la configuración anterior con el comando create:\nkubectl create -f config_anterior.yaml Ya tendríamos nuestro PVC. Este ahora podría ser consumido por un pod. Lo veremos en el siguiente punto.\nUsar un PVC Persistent Volume Claim en un pod Podríamos hacer que cualquier pod tuviera acceso a este PVC o volumen con una configuración como la siguiente:\n... spec: containers: - image: nginx imagePullPolicy: Always name: nginx volumeMounts: - name: nfs-vol mountPath: /opt ports: - containerPort: 80 protocol: TCP resources: {} volumes: # Concretamente todo lo del grupo volumes - name: nfs-vol persistentVolumeClaim: claimName: pvc-test # Importante usar el mismo nombre que la declaración del PVC ... Una vez terminada la configuración del pod, aplicamos el yaml con el comando create:\nkubectl create -f nfs-pod.yaml Si hacemos un describe del pod podemos ver el montaje de este volumen:\n... Volumes: nfs-vol: Type: PersistentVolumeClaim (a reference to a PersistentVolumeClaim in the same namespace) ClaimName: pvc-test ReadOnly: false ... ResourceQuota para limitar el uso de un PVC El objeto encargado de crear cuotas de recursos es ResourceQuota. Este nos permite limitar el tamaño y número de PVC\nTODO\n","categories":"","description":"","excerpt":"En kubernetes existe la posibilidad de crear volumenes para persistir …","ref":"/docs/contenedores/kubernetes/pv_pvc/","tags":["kubernetes"],"title":"Volúmenes y cuotas"},{"body":"La función de scheduling es la que decide qué podemos ejecutar en un nodo. Por ejemplo, podemos decidir en que nodo se ejecuta un pod en base a varios criterios.\nSe pueden utilizar diferentes opciones y etiquetas para esto:\nLabels Taints Affinity Scheduling policies Permiten definir los criterios de scheduling para un clúster, este establece un conjunto de reglas que se aplican a los nodos.\nLabels Los labels son una forma de identificar un nodo. Nos permiten agrupar nodos por un criterio, por ejemplo, podemos agrupar los nodos por país o por tipo de hardware.\nPara ver la información de un nodo, podemos usar los siguientes comando:\nkubectl describe node # Para ver el nodo actual kubectl describe node \u003cnombre_nodo\u003e # Para ver el nodo especificado kubectl describe nodes # Para ver todos los nodos Podríamos ver concretamente los labels de un nodo:\nkubectl describe nodes | grep -A5 -i label Esto mejora la organización de los nodos y nos permite filtrar por un criterio determinado. Además, y donde más potencial obtiene esta característica, podemos configurar los pods con estos labels para que se ejecuten en un nodo determinado.\nPodemos especificar el nodo en el que queremos que se ejecute un pod con el parámetro nodeSelector. Por ejemplo::\napiVersion: v1 kind: Pod metadata: name: my-pod spec: containers: - name: my-container image: busybox command: - sleep - \"3600\" nodeSelector: kubernetes.io/hostname: my-node #Para especificar un nodo concreto Añadir un label a un nodo Para añadir un label a un nodo, podemos usar el siguiente comando:\nkubectl label nodes \u003cnombre_nodo\u003e \u003cnombre_label\u003e=\u003cvalor_label\u003e Eliminar un label de un nodo Para eliminar un label de un nodo, podemos usar el siguiente comando:\nkubectl label nodes \u003cnombre_nodo\u003e \u003cnombre_label\u003e- Desplegar pods con nodos específicos con labels personalizados Siguiendo el ejemplo anterior, podemos añadir un label a un nodo y desplegar un pod en ese nodo.\napiVersion: v1 kind: Pod metadata: name: my-pod spec: containers: - name: my-container image: busybox command: - sleep - \"3600\" nodeSelector: \u003clabel-personalizado\u003e: \u003cvalor_label\u003e # Para especificar un nodo concreto Taints Los taints nos permiten especificar una restricción a un nodo para controlar donde los pods se están ejecutando y donde tienen permisos de hacerlo.\nExisten tres tipos de taints:\nNoSchedule: No permite que se ejecuten pods en el nodo. PreferNoSchedule: Intenta no ejecutar pods en el nodo. NoExecute: No permite que se ejecuten pods en el nodo y evita que los pods que ya se estén ejecutando en el nodo se muevan a otro nodo. ","categories":"","description":"","excerpt":"La función de scheduling es la que decide qué podemos ejecutar en un …","ref":"/docs/contenedores/kubernetes/scheduling/","tags":["kubernetes"],"title":"Scheduling"},{"body":"Exportar e importar bases de datos es un proceso crítico y totalmente necesario para proteger nuestros datos.\nEstas exportaciones se puede hacer con clientes como mysql workbench, phpmyadmin, etc. En la práctica, suele haber incompatibilidades entre algunas vesiones de los clientes con el servidor de bases de datos. Personalmente, siempre recomiendo utilizar la utilidad de terminal que lleva el propio servidor para minimizar la posibilidad de errores.\nA continuación, una lista de como exportar e importar bases de datos sql clasificados por tecnología:\nMySQL Exportar Podemos exportar con el siguiente comando:\nmysqldump -u USER -p DATABASE \u003e salida.sql #La contraseña nos la pedirá interactivamente Ejemplo real:\nmysqldump -u root -p database1 \u003e database1.sql Exportar múltiples bases de datos:\nmysqldump -u root -p --databases database1 database2 database3 \u003e databases.sql Exportar tablas específicas:\nmysqldump -u root -p --databases database1 --tables table1 table2 table3 \u003e tables.sql Importar Podemos importar con el siguiente comando:\nmysql -u USER -p DATABASE \u003c salida.sql ","categories":"","description":"","excerpt":"Exportar e importar bases de datos es un proceso crítico y totalmente …","ref":"/docs/programacion/sql/export_import/","tags":["mysql","database"],"title":"Exportar e importar"},{"body":"Los logs son una de las herramientas más importantes para entender el comportamiento de una aplicación. Esta información nos permite entender qué está pasando en el sistema y nos ayuda a depurar errores. En este apartado vamos a ver cómo consumir los logs de los contenedores que se ejecutan en Kubernetes y como integrarlos con otras herramientas de monitorización.\nLocalización de los ficheros logs Para los cluster de kubernetes basados en systemd podemos ver los logs de cada nodo usando el comando journalctl:\njournalctl -u kubelet |less La mayoría de procesos de docker, actualmente, se ejecutan en contenedores. Para encontrar los ficheros de logs del kube-apiserver podemos usar el siguiente comando:\nsudo find / -name \"*apiserver*log\" Luego podemos usar el comando less para ver el contenido del fichero:\nsudo less /var/log/containers/kube-apiserver-k8s-master-1_kube-system_kube-apiserver-1.log # Usa las rutas obtenidas en el comando anterior Otras rutas donde podemos encontrar logs en función del tipo de nodo son:\n/var/log/kube-apiserver.log # Api server /var/log/kube-scheduler.log # Scheduler /var/log/kube-controller-manager.log # Controller manager /var/log/containers # Logs de los contenedores /var/log/pods/ # Logs de los pods /var/log/kubelet.log # Logs del kubelet /var/log/kube-proxy.log # Logs del kube-proxy Documentación oficial de kubernetes:\nDepurar servicios Entender errores de un pod Logs de kubernetes - kubectl logs Podemos acceder a los logs de un pod usando el comando kubectl logs:\nkubectl -n \u003cnamespace\u003e logs \u003cpod\u003e #El comando namespace es opcional, si no se especifica se usa el namespace por defecto Añadiendo herramientas de monitorización y métricas Metric Server - Métricas (kubectl top) En este apartado vamos a ver cómo añadir herramientas de monitorización y métricas a nuestro cluster de kubernetes. Lo primero será instalar “metrics-server” en nuestro cluster. Para ello vamos a usar el siguiente comando:\nkubectl apply -f https://github.com/kubernetes-sigs/metrics-server/releases/latest/download/components.yaml Para entornos de prueba o desarrollo, podemos permitir TLS inseguro. Su certificado es x509 auto firmado y no será válido. Podemos utilizar la flag --kubelet-insecure-tls para permitir TLS inseguro. NO RECOMENDADO PARA ENTORNOS DE PRODUCCIÓN.\nkubectl -n kube-system edit deployment metrics-server Añadimos la siguiente línea en la sección containers:\n..... spec: containers: - args: - --cert-dir=/tmp - --secure-port=4443 - --kubelet-insecure-tls # Añadimos esta línea - --kubelet-preferred-address-types=InternalIP,ExternalIP,Hostname - --kubelet-use-node-status-port image: k8s.gcr.io/metrics-server/metrics-server:v0.3.6 A partir de aquí, ya podrímos consultar las métricas de nuestros pods usando el comando kubectl top:\nkubectl top pod --all-namespaces # Muestra las métricas de todos los pods kubectl top pod -n \u003cnamespace\u003e # Muestra las métricas de los pods de un namespace kubectl top node # Muestra las métricas de los nodos Dashboard Para instalar el dashboard de kubernetes, podemos usar el siguiente comando (Si no tienes instalado helm te recomiendo que visites su web para instalarlo):\nhelm repo add k8s-dashboard https://kubernetes.github.io/dashboard # Añadimos el repositorio a helm helm install \u003cnombre que le quieras dar al despliegue\u003e k8s-dashboard/kubernetes-dashboard La salida de helm nos dará las instrucción para acceder al dashboard. Ejecuta los comandos indicados, deberían ser similares a los siguientes:\nNAME: kube-dashboard LAST DEPLOYED: Sat Oct 22 16:04:19 2022 NAMESPACE: default STATUS: deployed REVISION: 1 TEST SUITE: None NOTES: ********************************************************************************* *** PLEASE BE PATIENT: kubernetes-dashboard may take a few minutes to install *** ********************************************************************************* Get the Kubernetes Dashboard URL by running: export POD_NAME=$(kubectl get pods -n default -l \"app.kubernetes.io/name=kubernetes-dashboard,app.kubernetes.io/instance=kube-dashboard\" -o jsonpath=\"{.items[0].metadata.name}\") echo https://127.0.0.1:8443/ kubectl -n default port-forward $POD_NAME 8443:8443 Si quisiéramos acceder al dashboard desde fuera del cluster podríamos usar el parámetro --address, añadido al comando anterior, para indicar la dirección IP desde la que queremos acceder:\nkubectl -n default port-forward --address 0.0.0.0 $POD_NAME 8443:8443 # Así cualuier usuario de la red podrá acceder al dashboard, ojo si no es lo que queremos Durante la instalación, se crea un usuario de servicio para acceder al dashboard. Este no tiene privilegios por lo que no podremos realizar ciertas acciones desde el dashboard. Podemos asignarle privilegios de administrador usando el siguiente comando:\nkubectl create clusterrolebinding dashaccess --clusterrole=cluster-admin --serviceaccount=default:\u003cnombre del usuario\u003e ¡OJO! El nombre de usuario depende del nombre que le hayamos dado al despliegue al dashboard. Ante la duda podemos consultar el nombre de nuestro usuario de servicio usando el siguiente comando:\nkubectl get serviceaccounts Nuestro usuario debería ser algo similar a \u003cnombre del despliegue\u003e-kubernetes-dashboard.\nSi accedemos al dashboard, podemos autenticarnos mediante el token de este usuario de servicio ( también podríamos usar el kubeconfig del administrador del cluster). Para obtener el token, ejecutamos el siguiente comando:\nkubectl describe secrets dashboard-kubernetes-dashboard-token-\u003cTAB\u003e # TAB para autocompletar el nombre completo del secret ","categories":"","description":"","excerpt":"Los logs son una de las herramientas más importantes para entender el …","ref":"/docs/contenedores/kubernetes/logging/","tags":["kubernetes"],"title":"Logging"},{"body":"La definición de recursos personalizados o (CRD, Custom Resource Definition) es una de las características más potentes de Kubernetes. Nos permite extender la funcionalidad de Kubernetes añadiendo nuevos tipos de recursos. Estos recursos pueden ser usados por los desarrolladores para definir sus propias abstracciones de alto nivel.\nConsultar recursos personalizados Podemos consultar los recursos personalizados usando el comando kubectl get:\nkubectl get crd --all-namespaces Es muy normal que aparecen recursos personalizados que no hemos definido nosotros. Estos recursos son definidos por otros componentes de Kubernetes. Por ejemplo, el componente metrics-server define el recurso pods.metrics.k8s.io. O por ejemplo, los componentes de calico definen el recurso networkpolicies.crd.projectcalico.org.\nPodemos obtener detalles de un recurso personalizado usando el comando kubectl describe:\nkubectl describe crd \u003cnombre del recurso\u003e Definir un recurso personalizado Para definir un recurso personalizado, debemos crear un fichero YAML con la definición del recurso. Por ejemplo, para definir un recurso personalizado de ejemplo:\napiVersion: apiextensions.k8s.io/v1beta1 kind: CustomResourceDefinition metadata: name: crontab.example.com spec: group: example.com versions: - name: v1 served: true storage: true schema: openAPIV3Schema: type: object properties: spec: type: object properties: cronSpec: type: string image: type: string replicas: type: integer scope: Namespaced names: plural: crontabs singular: crontab kind: CronTab shortNames: - ct Podemos crear el recurso personalizado usando el comando kubectl create:\nkubectl create -f crontab.yaml Crear un objeto de un recurso personalizado Para crear un objeto de un recurso personalizado, debemos crear un fichero YAML con la definición del objeto. Por ejemplo, para crear un objeto de ejemplo:\napiVersion: \"example.com/v1\" kind: CronTab metadata: name: my-new-cron-object spec: cronSpec: \"* * * * */5\" image: my-awesome-cron-image A partir de aquí, podemos usar el recurso personalizado como si fuera un recurso nativo de Kubernetes. Por ejemplo, podemos consultar los objetos de un recurso personalizado usando el comando kubectl get:\nkubectl get crontab --all-namespaces # Listar todos los objetos crontab de todos los namespaces kubectl get crontab -n \u003cnamespace\u003e # Listar todos los objetos crontab de un namespace kubectl get crontab \u003cnombre del objeto\u003e -n \u003cnamespace\u003e # Obtener detalles de un objeto crontab kubectl describe crontab \u003cnombre del objeto\u003e -n \u003cnamespace\u003e # Obtener detalles de un objeto crontab ","categories":"","description":"","excerpt":"La definición de recursos personalizados o (CRD, Custom Resource …","ref":"/docs/contenedores/kubernetes/recursos_personalizados/","tags":["kubernetes"],"title":"Recursos personalizados"},{"body":"Creación de usuarios Podemos crear usuarios para que accedan a la base de datos. Para ello, utilizamos el comando CREATE USER:\nCREATE USER 'usuario'@'localhost' IDENTIFIED BY 'password'; El comando anterior crea un usuario llamado usuario con contraseña password que solo puede acceder desde el servidor localhost.\nModificación de usuarios Podemos modificar la contraseña de un usuario con el comando SET PASSWORD:\nSET PASSWORD FOR 'usuario'@'localhost' = PASSWORD('nueva_password'); También podríamos haber utilizado el comando ALTER USER:\nALTER USER 'usuario'@'localhost' IDENTIFIED BY 'nueva_password'; Podemos modificar el nombre de un usuario con el comando RENAME USER:\nRENAME USER 'usuario'@'localhost' TO 'nuevo_usuario'@'localhost'; Eliminación de usuarios Podemos eliminar un usuario con el comando DROP USER:\nDROP USER 'usuario'@'localhost'; Podemos eliminar todos los usuarios con el comando DROP ALL USERS:\nDROP ALL USERS; Bloqueo y desbloqueo de usuarios Si en algún momento queremos bloquear a un usuario, podemos hacerlo modificando sus permisos y aplicando el atributo ACCOUNT LOCK:\nALTER USER 'usuario'@'localhost' ACCOUNT LOCK; Podemos desbloquear a un usuario con el comando UNLOCK ACCOUNT:\nALTER USER 'usuario'@'localhost' UNLOCK ACCOUNT; ","categories":"","description":"","excerpt":"Creación de usuarios Podemos crear usuarios para que accedan a la base …","ref":"/docs/programacion/sql/usuarios/","tags":["mysql"],"title":"Usuarios"},{"body":"La seguridad en Kubernetes es un tema muy amplio. Podemos agruparlo en varias categorías:\nSeguridad de accesos e identidades (Autenticación y Autorización) Contexto de seguridad (Security Context) Políticas de seguridad para Pods (Pod Security Policy) Políticas de red (Network Security Policies) Autenticación, autorización y control de admisión Cada llamada que hacemos al API de kubernetes es autenticada y autorizada. Además, podemos configurar un control de admisión para rechazar llamadas que no cumplan ciertas condiciones.\nEste diagrama ilustra este proceso: Autenticación La autenticación es el proceso de identificación de un usuario. Kubernetes soporta varios métodos de autenticación. Por ejemplo, podemos usar certificados, tokens, contraseñas, etc.\nAutorización La autorización es el proceso de determinar si un usuario tiene permisos para realizar una acción. Kubernetes soporta varios métodos de autorización. Por ejemplo, podemos usar roles y permisos, políticas de RBAC, etc.\nPara esta sección, consulta la documentación sobre usuarios, cuentas y permisos\nRBAC (Role Based Access Control) RBAC es un método de autorización basado en roles. En este método, definimos roles y permisos. Luego, asignamos los roles a los usuarios. Por ejemplo, podemos definir un rol admin con permisos de lectura y escritura. Luego, podemos asignar este rol a un usuario admin.\nPara conseguir esta granularidad, se definen operaciones CRUD (Create, Read, Update, Delete) sobre recursos. Por ejemplo, podemos definir permisos para crear, leer, actualizar y borrar pods. Luego, podemos asignar estos permisos a un rol. Por ejemplo, podemos definir un rol admin con permisos para crear, leer, actualizar y borrar pods. Luego, podemos asignar este rol a un usuario admin.\nEsto nos permite definir roles con permisos muy específicos. Por ejemplo, podemos definir un rol pod-reader con permisos para leer pods. Luego, podemos asignar este rol a un usuario reader.\nControlador de admisión (Admission Controller) El controlador de admisión es un componente que se ejecuta antes de que se realice una acción en el API de kubernetes. Podemos configurar varios controladores de admisión.\nPodemos ver las configuraciones de los controladores de admisión en el fichero /etc/kubernetes/manifests/kube-apiserver.yaml en el nodo maestro. Por ejemplo:\nsudo grep admission /etc/kubernetes/manifests/kube-apiserver.yaml Security Context Los pods y contenedores en kubernetes pueden ejecutarse con un contexto de seguridad. Este contexto de seguridad define los permisos que tiene el contenedor, sus capacidades y limitaciones, etc.\nPor ejemplo, podemos configurar un contexto de seguridad para que un contenedor no pueda ejecutar comandos como sudo o su. También podemos configurar un contexto de seguridad para que un contenedor no pueda ejecutar comandos como mount o umount.\nEstos contextos se definen dentro de los spec de los pods. Por ejemplo, podemos definir un contexto de seguridad para un pod de la siguiente forma:\napiVersion: v1 kind: Pod metadata: name: nginx spec: securityContext: runAsUser: 1000 runAsGroup: 3000 fsGroup: 2000 containers: - name: nginx image: nginx ports: - containerPort: 80 Si una de las propiedades del contexto de seguridad se incumple, el contenedor no se ejecutará. Se quedará en un estado de error y en su mensaje de estado se mostrará el motivo del error.\nPod Security Policy DEPRECADO: Pod Security Policy está deprecado en Kubernetes 1.21 y se eliminará en Kubernetes 1.25. En su lugar, se recomienda usar Admission Controller de Pod Security.\nLas Pod Security Policies (PSP) sos permiten definir políticas de seguridad para todos los pods, a diferencia de la aproximación anterior, la cuál requeria definir el contexto de seguridad en cada pod.\nPodemos definir una PSP para que los pods no puedan ejecutar comandos como sudo o su, no puedan ejecutar ciertos comandos, sean incapaz de montar volúmenes, etc.\nNetwork Security Policies Por defecto, los pods en kubernetes pueden comunicarse con cualquier otro pod y todo tipo de tráfico es permitido. Podemos configurar políticas de red para restringir este tráfico.\nCuando aplicamos una política, por defecto, se restringe todo el tráfico de entrada y salida. Luego debemos configurar manualmente las excepciones.\nPor ejemplo, podemos configurar una política de red para que un pod solo pueda comunicarse con otros pods que tengan un label app=nginx. También podemos configurar una política de red para que un pod solo pueda comunicarse con otros pods que tengan un label app=nginx y que estén en el mismo namespace.\napiVersion: networking.k8s.io/v1 kind: NetworkPolicy metadata: name: ingress-egress-policy namespace: default spec: podSelector: matchLabels: role: db policyTypes: - Ingress - Egress ingress: - from: - ipBlock: cidr: 172.17.0.0/16 except: - 172.17.1.0/24 - namespaceSelector: matchLabels: project: myproject - podSelector: matchLabels: role: frontend ports: - protocol: TCP port: 6379 egress: - to: - ipBlock: cidr: 10.0.0.0/24 ports: - protocol: TCP port: 5978 En este ejemplo, restringimos el tráfico entrante a un rango de IPs (con una excepción), en un namespace concreto y en los pods con el label ‘frontend’. También limitamos este tráfico a un puerto concreto.\nTambién restringimos el tráfico saliente a un rango de IPs y a un puerto concreto.\nPodemos usar {} para seleccionar todos los pods y no permitir ningún tráfico. Por ejemplo, para todo el tráfico de entrada:\napiVersion: networking.k8s.io/v1 kind: NetworkPolicy metadata: name: ingress-egress-policy namespace: default spec: podSelector: {} policyTypes: - Ingress Si no especificamos el tráfico de salida egress, no se verá afectado por esta política.\n","categories":"","description":"","excerpt":"La seguridad en Kubernetes es un tema muy amplio. Podemos agruparlo en …","ref":"/docs/contenedores/kubernetes/seguridad/","tags":["kubernetes"],"title":"Seguridad"},{"body":"Helm es una herramienta que nos permite gestionar, versionar y desplegar múltiples recursos de kubernetes.\nLos componentes en helm se estructuran de la siguiente manera:\n├── Chart.yaml ├── README.md ├── templates │ ├── NOTES.txt │ ├── _helpers.tpl │ ├── configmap.yaml │ ├── deployment.yaml │ ├── pvc.yaml │ ├── secrets.yaml │ └── svc.yaml └── values.yaml El fichero chart.yaml contiene los metadatos del chart, el values contiene las claves y atributos a modificar y el templates contienen los manifiestos de kubernetes.\nLas templates se generan como un recurso nombre de kubernetes solo que plantillando las variables para que el chart sirva a diferentes propósitos y organizaciones. Por ejemplo:\napiVersion: v1 kind: Secret metadata: name: {{ template \"fullname\" . }} labels: app: {{ template \"fullname\" . }} chart: \"{{ .Chart.Name }}-{{ .Chart.Version }}\" release: \"{{ .Release.Name }}\" heritage: \"{{ .Release.Service }}\" type: Opaque data: mariadb-root-password: {{ default \"\" .Values.mariadbRootPassword | b64enc | quote }} mariadb-password: {{ default \"\" .Values.mariadbPassword | b64enc | quote }} Este elemento de tipo secreto esta plantillado para que todos sus campos se recojan del fichero values. Esto nos permite, centralizar todos los valores en un único fichero (values.yaml) y por otra parte, permitir que nuestros elementos se kubernetes sean reutilizables.\nEste conjunto de elementos se llama chart y se pueden interactuar con ellos como repositorios de git.\nRepositorios Por defecto, helm busca charts dentro de la web de Artifactory Hub.\nPodríamos buscar charts con el comando:\nhelm search hub \u003cnombre del chart\u003e #Buscar repositorios helm search repo \u003cnomrbre del repositorio\u003e #Buscar dentro del repositorio También podríamos añadir nuevos repositorios, por ejemplo, el de bitnami:\nhelm repo add bitnami ht‌tps://charts.bitnami.com/bitnami Los repositorios que trae por defecto y los que añadimos nosotros manualmente, pueden actualizarse con el comando:\nhelm repo update Si ahora quisieramos buscar charts solo dentro de este repositorio podríamos hacerlo así:\nhelm search repo bitnami Desplegando un chart Podríamos desplegar un chart con el comando helm install pero la mayoría de ellos necesitan una personalización para que funcionen correctamente por lo que primero debemos descargarlos en local para leer su README y modificar los valores pertinentes.\nEsto lo podríamos hacer con el comando:\nhelm fetch \u003cnombre repositorio\u003e --untar Tras modificar todo lo que nos resultara necesario, podemos lanzar el siguiente comando en la ruta del repositorio:\nhelm install \u003cnombre del despliegue\u003e Podríamos desinstalarlo con el comando:\nhelm uninstall \u003cnombre del despliegue\u003e También podríamos listar todos los charts desplegados y sus respectivas versiones con el comando:\nhelm list ","categories":"","description":"","excerpt":"Helm es una herramienta que nos permite gestionar, versionar y …","ref":"/docs/contenedores/kubernetes/helm/","tags":["helm","kubernetes"],"title":"Helm"},{"body":"Creación de permisos Podemos crear permisos para que los usuarios puedan acceder a la base de datos. Para ello, utilizamos el comando GRANT:\nGRANT ALL PRIVILEGES ON *.* TO 'usuario'@'localhost'; Pero ojo, porque este comando da todos los permisos al usuario. Si queremos darle permisos específicos, podemos hacerlo de la siguiente manera:\nGRANT SELECT, INSERT, UPDATE, DELETE ON \u003cbase de datos\u003e.* TO 'usuario'@'localhost'; También podríamos dar permisos específicos a una tabla en concreto:\nGRANT SELECT, INSERT, UPDATE, DELETE ON base_de_datos.tabla TO 'usuario'@'localhost'; Por último, podemos dar permisos para que el usuario afectado pueda gestionar permisos a otros usuarios:\nGRANT SELECT, INSERT ON mysql.* TO 'usuario'@'localhost' WITH GRANT OPTION; Permisos sobre vistas Podríamos dar permisos a un usuario para que pueda acceder a una vista, sería similar a dar permisos a una tabla:\nGRANT SELECT ON base_de_datos.vista TO 'usuario'@'localhost'; Consultar permisos Podemos consultar los permisos de un usuario con el comando SHOW GRANTS:\nSHOW GRANTS FOR 'usuario'@'localhost'; Podríamos consultar los permisos de las tablas desde la “table_priv” de la base de datos “mysql”:\nSELECT * FROM mysql.table_priv WHERE User = 'usuario' AND Host = 'localhost'; Eliminación de permisos Para eliminar permisos, utilizamos el comando REVOKE. En mysql, podemos eliminar todos los permisos de un usuario con el siguiente comando:\nREVOKE ALL PRIVILEGES, GRANT OPTION FROM 'usuario'@'localhost'; También podemos eliminar permisos específicos:\nREVOKE SELECT, INSERT, UPDATE, DELETE ON \u003cbase de datos\u003e.* FROM 'usuario'@'localhost'; ","categories":"","description":"","excerpt":"Creación de permisos Podemos crear permisos para que los usuarios …","ref":"/docs/programacion/sql/permisos/","tags":["sql","mysql"],"title":"Permisos"},{"body":"Por defecto, Kubernetes no tiene usuarios ni roles. Sin embargo, podemos definir usuarios y roles para controlar el acceso a los recursos de Kubernetes.\nUsuarios Normalmente los usuarios se definen en un sistema de autenticación externo, como LDAP, Active Directory, etc. Kubernetes no tiene un sistema de autenticación propio, pero puede integrarse con sistemas de autenticación externos mediante plugins de autenticación.\nSe pueden definir usuarios de forma manual mediante certificados x509.\nCrear usuario mediante Certificado x509 Estos pasos se tienen que realizar en un control plane de Kubernetes, el cuál, ejecuta el API y es el encargado de validar los certificados x509.\nPrimero tendremos que crear un par de claves privada y pública. Para ello, ejecutamos el siguiente comando:\nopenssl genrsa -out user.key 2048 A continuación, generamos el certificado x509:\nopenssl req -new -key user.key -out user.csr -subj \"/CN=user/O=group\" Finalmente, firmamos el certificado x509 con la clave privada del control plane:\nopenssl x509 -req -in user.csr -CA /etc/kubernetes/pki/ca.crt -CAkey /etc/kubernetes/pki/ca.key -CAcreateserial -out user.crt -days 500 Una vez generado el certificado x509, podemos añadirlo al API de Kubernetes. Para ello, ejecutamos el siguiente comando:\nkubectl config set-credentials user --client-certificate=user.crt --client-key=user.key --embed-certs=true Por defecto, este usuario carecerá de permisos para realizar ninguna acción en el cluster. Para asignarle permisos, tendremos que crear asignarle un rol ( a nivel de namespace) o un clusterrole (a nivel de cluster).\nEsta asignación de un rol, se realiza mediante rolesbindings ( a nivel de namespace) o clusterrolebindings (a nivel de rol).\nService Accounts - Cuentas de servicio Kubernetes crea una cuenta de servicio por defecto para cada namespace. Esta cuenta de servicio se utiliza para acceder a la API de Kubernetes. Podemos crear cuentas de servicio adicionales para acceder a la API de Kubernetes.\nkubectl create serviceaccount \u003cnombre\u003e Estas cuentas podríamos asocialas a un role mediante objetos RoleBinding o ClusterRoleBinding como se explica en los siguientes pasos.\nRoles Podemos definir roles en kubebernetes creando objetos de tile Role. Por ejemplo:\napiVersion: rbac.authorization.k8s.io/v1 kind: Role metadata: namespace: default name: pod-admin rules: - apiGroups: [\"\",\"extensions\",\"apps\"] # \"\" indica el core API group resources: [\"pods\"] verbs: [\"get\", \"watch\", \"list\", \"delete\", \"create\", \"update\", \"patch\"] # Podríamos usar * para indicar todos los verbos Estos nos permiten granularizar el acceso a cada uno de los recursos y los permisos específicos que les queremos otorgar.\nCrear un rol solo es el primer paso. Para usarlo, tenemos que asignarlo a un usuario o grupo de usuarios. Para ello, podemos usar un objeto de tipo RoleBinding. Por ejemplo:\napiVersion: rbac.authorization.k8s.io/v1 kind: RoleBinding metadata: name: read-pods namespace: default subjects: - kind: User name: jdoe # Nombre del usuario apiGroup: rbac.authorization.k8s.io roleRef: kind: Role # Este debe ser Role o ClusterRole name: pod-reader # Este debe ser el nombre del rol que queremos asignar apiGroup: rbac.authorization.k8s.io Con esto, creamos la relación entre el rol pod-reader y el usuario jdoe.\nPodemos consultar los roles y los bindings usando los comandos kubectl get roles y kubectl get rolebindings. Estos comandos nos devolverán los roles y los bindings de todos los namespaces. Si queremos consultar los roles y los bindings de un namespace en concreto, podemos usar el flag -n o --namespace.\nPor ejemplo:\nkubectl get roles -n default kubectl get rolebindings -n default Estos nos mostrarían una salida similar a la siguiente:\nName: pod-admin Labels: \u003cnone\u003e Annotations: \u003cnone\u003e PolicyRule: Resources Non-Resource URLs Resource Names Verbs --------- ----------------- -------------- ----- deployments [] [] [list get watch create update patch delete] pods [] [] [list get watch create update patch delete] replicasets [] [] [list get watch create update patch delete] deployments.apps [] [] [list get watch create update patch delete] pods.apps [] [] [list get watch create update patch delete] replicasets.apps [] [] [list get watch create update patch delete] deployments.extensions [] [] [list get watch create update patch delete] pods.extensions [] [] [list get watch create update patch delete] replicasets.extensions [] [] [list get watch create update patch delete] En el caso de los bindings, la salida sería similar a la siguiente:\nName: read-pods Labels: \u003cnone\u003e Annotations: \u003cnone\u003e Role: Kind: Role Name: dev-prod Subjects: Kind Name Namespace ---- ---- --------- User jdoe ","categories":"","description":"","excerpt":"Por defecto, Kubernetes no tiene usuarios ni roles. Sin embargo, …","ref":"/docs/contenedores/kubernetes/usuarios_roles/","tags":["kubernetes"],"title":"Usuarios y roles"},{"body":"Los roles son una forma de agrupar usuarios y darles un conjunto de permisos. Sería una especie de plantilla de permisos que se puede aplicar a un usuario.\nCreación de roles Podemos crear roles para que accedan a la base de datos. Para ello, utilizamos el comando CREATE ROLE:\nCREATE ROLE 'rol'; Asignamos permisos a un rol con el comando GRANT:\nGRANT SELECT, INSERT, UPDATE, DELETE ON 'tabla' TO 'rol'; Asignación de roles a usuarios Podemos asignar un rol a un usuario con el comando GRANT:\nGRANT 'rol' TO 'usuario'@'localhost'; También podríamos usar el comando set:\nSET ROLE 'rol' TO 'usuario'@'localhost'; Por último, lo podríamos asignar por defecto al usuario:\nSET DEFAULT ROLE 'rol' TO 'usuario'@'localhost'; Consultar roles de un usuario Podemos consultar los roles de un usuario con el comando SHOW GRANTS:\nSHOW GRANTS FOR 'usuario'@'localhost'; Modificación de roles Podemos modificar el nombre de un rol con el comando RENAME ROLE:\nRENAME ROLE 'rol' TO 'nuevo_rol'; Eliminación de roles Podemos eliminar un rol con el comando DROP ROLE:\nDROP ROLE 'rol'; ","categories":"","description":"","excerpt":"Los roles son una forma de agrupar usuarios y darles un conjunto de …","ref":"/docs/programacion/sql/roles/","tags":["mysql"],"title":"Roles"},{"body":"Las variables son valores que se pueden modificar en tiempo de ejecución. Podemos consultar el valor de una variable con el comando SHOW VARIABLES:\nSHOW VARIABLES; Podemos modificar el valor de una variable con el comando SET:\nSET @variable = valor; También podemos modificar el valor de una variable global con el comando SET GLOBAL:\nSET GLOBAL @variable = valor; ","categories":"","description":"","excerpt":"Las variables son valores que se pueden modificar en tiempo de …","ref":"/docs/programacion/sql/variables/","tags":["mysql","sql"],"title":"Variables"},{"body":"El mantenimiento de kubernetes es una tarea que se realiza con frecuencia.\nBackup base de datos etcd Durante los procesos de actualización, por muy estables que sean, siempre es buena idea crear una copia de seguridad de la base de datos del cluster.\nLo primero que tenemos que hacer es buscar el directorio de los datos de etcd: sudo grep data-dir /etc/kubernetes/manifests/etcd.yaml Toda esta parte se realiza ejecutando comandos dentro del contenedor de etcd. Se llama etcd-\u003cnombre nodo\u003e , aunque podrías listar los pods del sistema para encontrarlo con kubectl -n kube-system get pods.\nComprobamos el estado de la base de datos de etcd: kubectl -n kube-system exec -it etcd-\u003cnombre_pod\u003e -- sh -c \"ETCDCTL_API=3 \\ ETCDCTL_CACERT=/etc/kubernetes/pki/etcd/ca.crt \\ ETCDCTL_CERT=/etc/kubernetes/pki/etcd/server.crt \\ ETCDCTL_KEY=/etc/kubernetes/pki/etcd/server.key \\ etcdctl endpoint health\" Comprobamos el estado del cluster: kubectl -n kube-system exec -it etcd-kube-master -- sh -c \"ETCDCTL_API=3 \\ ETCDCTL_CACERT=/etc/kubernetes/pki/etcd/ca.crt \\ ETCDCTL_CERT=/etc/kubernetes/pki/etcd/server.crt \\ ETCDCTL_KEY=/etc/kubernetes/pki/etcd/server.key \\ etcdctl --endpoints=https://127.0.0.1:2379 member list -w table\" Por último, hacemos la copia de seguridad con el comando snapshot: kubectl -n kube-system exec -it etcd-kube-master -- sh -c \"ETCDCTL_API=3 \\ ETCDCTL_CACERT=/etc/kubernetes/pki/etcd/ca.crt \\ ETCDCTL_CERT=/etc/kubernetes/pki/etcd/server.crt \\ ETCDCTL_KEY=/etc/kubernetes/pki/etcd/server.key \\ etcdctl --endpoints=https://127.0.0.1:2379 snapshot save /var/lib/etcd/snapshot.db\" Si hacemos un ls en directorio del paso 1 (normalmente /var/lib/etcd) podremos ver el la base de datos que acabamos de extraer:\nsudo ls -l /var/lib/etcd Actualizar el cluster Lo primero es actualizar la herramienta kubeadm, la cuál, nos ayudará a actualizar el cluster.\nActualizamos los metadatos de los paquetes del sistema con: sudo apt update Podemos consultar las versiones disponibles con la herramienta madison las versiones disponibles con la herramienta madison: sudo apt-cache madison kubeadm Si teníamos bloqueado el paquete kubeadm para que no se actualizara automáticamente, lo desbloqueamos: sudo apt-mark unhold kubeadm Instalamos la versión deseada: sudo apt install -y kubeadm=1.23.1-00 Volvemos a bloquear la actualización del paquete: sudo apt-mark hold kubeadm Podemos comprobar la versión que accabamos de instalar: sudo kubeadm version Para preparar el nodo para la actualización, tenemos que desalojar a todos los pods como sea posible (si estuvieramos actualizando un nodo trabajador el drain tendríamos que hacerlo desde el maestro). Se puede realizar así: kubectl drain \u003cnombre_nodo\u003e --ignore-daemonsets El comando kubeadm nos permite previsualizar los cambios que va a generar la actualización con el comando plan: sudo kubeadm upgrade plan Podemos realizar la actualización del nodo con el comando apply: sudo kubeadm upgrade plan Actualizamos el resto de paquetes a la misma version: sudo apt-mark unhold kubelet kubectl sudo apt-get install -y kubelet=1.23.1-00 kubectl=1.23.1-00 sudo apt-mark hold kubelet kubectl Aunque hemos actualizado correctamente, si ejecutamos kubectl get nodes nos seguirá mostrando la versión anterior. La actualización se hará efectiva hasta que reiniciemos los servicios: sudo systemctl daemon-reload sudo systemctl restart kubelet Por último, en el proceso de actualización de un nodo, este desactiva el planificador de tareas. Podemos desbloquearlo así: kubectl uncordon \u003cnombre_nodo\u003e Se puede verificar el estado con el comando:\nkubectl get nodes ","categories":"","description":"","excerpt":"El mantenimiento de kubernetes es una tarea que se realiza con …","ref":"/docs/contenedores/kubernetes/mantenimiento/","tags":["kubernetes"],"title":"Mantenimiento Y actualización"},{"body":"En el mundo de la infraestructura como código, Docker se ha convertido en una herramienta esencial para desarrolladores y administradores de sistemas. Una de las ventajas de Docker es la capacidad de crear imágenes ligeras, lo que permite un despliegue rápido y eficiente de aplicaciones.\nExisten casos, ya sea por la complejidad de la aplicación, la cantidad de paquetes instalados o la cantidad de archivos, en los que las imágenes Docker pueden llegar a ser muy pesadas. Esto puede afectar muy negativamente el rendimiento y la eficiencia de los automatismos de construcción, pruebas y despliegue.\nEn este artículo, vamos a explorar cómo crear imágenes de Docker ligeras para optimizar el rendimiento y la eficiencia en el despliegue de aplicaciones.\nPaso 1: Utilizar una imagen base pequeña La primera etapa en la creación de una imagen de Docker ligera es elegir una imagen base pequeña. Esto significa elegir una imagen que tenga el menor tamaño posible y solo contenga los componentes esenciales para ejecutar la aplicación. Por ejemplo, dentro de las imágenes de debian, podemos optar por las versiones con tag “-slim” (debian:11-slim) las cuales traen muchos menos paquetes por defecto.\nOtras imágenes que se han vuelto muy populares los últimos años son las de Alpine Linux. Estas tienen un tamaño minúsculo y tienen un sistema de paquetes muy poblado y bien mantenido.\nPaso 2: Eliminar archivos no necesarios Una vez que tenemos nuestra imagen base, es importante eliminar cualquier archivo o paquete que no sea necesario para la ejecución de la aplicación. Esto puede incluir documentación, archivos de configuración y aplicaciones adicionales.\nUn caso práctico, construyo una aplicación Java con Maven y luego utilizo una imagen base de OpenJDK para ejecutar la aplicación. En este caso, Maven no es necesario para la ejecución de la aplicación, por lo que puedo eliminarlo de la imagen. Esto sería extrapolable a npm para aplicaciones Node.js, pip para aplicaciones Python, etc.\nTenemos que pensar que solo tenemos que dejar lo esencial para que la aplicación funcione. Esto no es solo una cuestión de optimización, sino también de seguridad. Si dejamos archivos o paquetes innecesarios en la imagen, podemos estar expuestos a vulnerabilidades debido a aumentar la superficie de ataque.\nPaso 3: Utilizar multi-etapas de construcción La característica de multi-etapas de construcción de Docker nos permite utilizar varias imágenes en una sola definición de construcción. Esto significa que podemos utilizar una imagen base para compilar nuestra aplicación y luego utilizar otra imagen base más pequeña para desplegar la aplicación. Esto nos permite eliminar cualquier paquete o archivo no necesario utilizado solo en la etapa de compilación.\nPost-paso 1: Monitorizar el rendimiento de la imagen. Algunos errores de optimización no serán visibles hasta que la imagen se ejecute en un entorno de producción. Por lo tanto, es importante monitorizar el rendimiento de la imagen una vez que se haya desplegado en producción. Esto nos permitirá identificar cualquier problema de rendimiento y optimizar la imagen de forma proactiva.\nAquí podríamos vigilar que no se escriban demasiados archivos en el disco, que no se consuma demasiada memoria, que no se consuma demasiado ancho de banda, etc.\nEl comando docker stats nos permite realizar esta tarea. Aunque tendremos que ejecutarlo manualmente, también podríamos automatizarlo o utilizar herramientas como Prometheus para monitorizar el rendimiento de la imagen y guardar los datos en un servidor de métricas.\nPost-paso 2: Utilizar herramientas de análisis de imágenes Algunas herramientas de análisis de imágenes nos permiten analizar las imágenes Docker y obtener información sobre el tamaño de la imagen, los archivos y los paquetes que contiene.\nPor ejemplo, la herramienta Dive, la cual, dispone recientemente de extensión de docker.\nEsta extensión nos permite visualizar el tamaño de cada capa de la imagen, así como los archivos y los paquetes que contiene. Esto nos permite identificar archivos y paquetes innecesarios que podemos eliminar de la imagen.\nBonus: Distroless Esto me lo guardo para un artículo/vídeo aparte, pero os dejo un enlace a enlace a la documentación de google por si no podéis esperar. Distroless\nDejaré un enlace aquí cuando lo publique.\nConclusión Para generar imágenes Docker ligeras, debemos seguir los siguientes pasos:\nUtilizar una imagen base pequeña, como las versiones slim de debian, las UBI de Red Hat o las imágenes de Alpine. Eliminar archivos no necesarios, como componentes de desarrollo, compiladores, documentación.. etc. Para esto, podemos utilizar herramientas como Dive, tanto desde la línea de comandos como desde docker desktop. Construir una imagen con multi-etapas de construcción. ","categories":"","description":"Optimizar imágenes Docker es la clave para que el despliegue de aplicaciones sea más rápido y eficiente.","excerpt":"Optimizar imágenes Docker es la clave para que el despliegue de …","ref":"/blog/2023/03/08/aligerar-im%C3%A1genes-docker/","tags":["docker"],"title":"Aligerar imágenes Docker"},{"body":"","categories":"","description":"","excerpt":"","ref":"/tags/docker/","tags":"","title":"docker"},{"body":"","categories":"","description":"","excerpt":"","ref":"/tags/","tags":"","title":"Tags"},{"body":"PowerToys es un conjunto de herramientas de productividad de Microsoft para Windows 10 y 11. Incluye una variedad de utilidades diseñadas para mejorar la experiencia del usuario al trabajar con el sistema operativo.\nLogo de PowerToys Una de las herramientas más populares de PowerToys es FancyZones, que permite a los usuarios crear zonas personalizadas en su escritorio para organizar sus ventanas. Esto es especialmente útil para aquellos que trabajan con varias aplicaciones al mismo tiempo y necesitan una manera de organizarlas de manera eficiente.\nOtra herramienta popular es PowerRename, que permite a los usuarios renombrar múltiples archivos de manera masiva con una variedad de opciones de búsqueda y reemplazo. Esto es especialmente útil para aquellos que trabajan con grandes cantidades de archivos y necesitan una manera de organizarlos de manera eficiente.\nPowerToys también incluye una herramienta llamada Shortcut Guide, que muestra una lista de atajos de teclado disponibles en la aplicación en la que se encuentra el usuario en ese momento. Esto es especialmente útil para aquellos que desean aprender nuevos atajos de teclado y aumentar su productividad.\nEn resumen, PowerToys es un conjunto de herramientas de productividad de Microsoft para Windows 10 que incluye una variedad de utilidades diseñadas para mejorar la experiencia del usuario al trabajar con el sistema operativo. Incluye herramientas como FancyZones, PowerRename y Shortcut Guide, que son especialmente útiles para aquellos que trabajan con varias aplicaciones al mismo tiempo y necesitan una manera de organizarlas de manera eficiente, renombrar múltiples archivos de manera masiva y aprender nuevos atajos de teclado.\n","categories":"","description":"PowerToys es una colección de utilidades para Windows 10 y 11 que te ayudan a ser más productivo.","excerpt":"PowerToys es una colección de utilidades para Windows 10 y 11 que te …","ref":"/blog/2023/01/10/powertoys/","tags":["windows","productividad"],"title":"PowerToys"},{"body":"","categories":"","description":"","excerpt":"","ref":"/tags/productividad/","tags":"","title":"productividad"},{"body":"","categories":"","description":"","excerpt":"","ref":"/tags/windows/","tags":"","title":"windows"},{"body":"¡Hola! En esta entrada me gustaría contar mi experiencia con la certificación CKA (Certified Kubernetes Administrator) gestionada por la Linux Foundation.\nTodo este último año he dedicado mis esfuerzos, tanto en lo personal como en lo profesional, a profundizar mis conocimientos en contenedores y orquestación de los mismos. Aunque había trabajado previamente con la tecnología, no había tenido la posibilidad de pelearme con sus tripas ni desplegar mi propia infraestructura.\nLo primero es contestar a las preguntas esenciales que personalmente me hice:\n¿Por qué elegí esta certificación? Personalmente me interesaba más la certificación CKS, la cuál profundiza en kubernetes desde el punto de vista de seguridad, pero sacarse el CKA primero y asentar los conocimientos base me pareció más razonable. ¿Cuánto tiempo requiere? Sin conocimientos previos, si estas familiarizado con contenedores, entre tres y seis meses te la puedes sacar sin problemas. Todo depende de tu carga te trabajo, rutina personal.. etc. En mi caso, dedicando unas tres horas semanales terminé el temario del libro en 6 meses y el séptimo mes me embarqué en una maratón para repasar todo el temario y presentarme al examen. ¿Cuánto tiempo dispongo para hacerla? La plataforma te deja acceder al curso y examinarte durante un año. Además, también tienes derecho a un examen extra en caso de que suspendas. ¿Necesito un super ordenador? No, no es necesario. El examen se puede hacer desde cualquier navegador y no requiere de una gran potencia de procesamiento. Para realizar los ejercicios si que es recomendable un ordenador con al menos 16GB de RAM (32GB recomendable) para las múltiples instancias de kubernetes que se van a crear. También podrías hacerlo en máquinas virtuales en la nube con el coste que ello conlleva. Mi experiencia Ahora sí, vamos al lío. Mi experiencia con la certificación CKA. Personalmente no se me hizo especialmente dura, aunque es cierto que tenía conocimientos previos de contenedores y el tema no me era completamente desconocido.\nEl temario es bastante completo y es recomendable ir poco más allá de los ejercicios que te plantea el libro para adquirir unos conocimientos más sólidos. No te recomiendo dilatar mucho en el tiempo la certificación, si tienes tiempo, hazlo cuanto antes. Cuando al sexto mes había terminado los ejercicios del libro, había olvidado gran parte de lo aprendido y tuve que repasar todo de nuevo para llegar al examen con soltura.\nIMPORTANTE. Junto con el libro y el examen, también se te da acceso a dos exámenes de prueba en la plataforma killer.sh que te ayudarán a familiarizarte con el examen y a saber si estás preparado para presentarte al examen final. No te frustres si suspendes, es muy normal. Estos tienen una duración y dificultad bastante mayor respecto al examen final. Lo importante es que, aunque no te de tiempo o falles, tienes acceso durante 24 horas al examen para que lo termines de completar. Además, puedes ver si las respuestas que has dado son correctas o no (algo que en el examen final no puedes hacer) y así entender mejor como se evalúa el examen.\nDe forma complementaria, también puedes hacer ejercicios en la plataforma katacoda, la cual te permite crear instancias de kubernetes y te plantea retos concretos que debes resolver. Es una buena forma de practicar y familiarizarte aún más con los comandos y la sintaxis de kubernetes.\nEl examen El examen son 17 preguntas (si no recuerdo mal), están bien descritas y son bastante claras aun teniendo unos conocimientos básicos de inglés. Hay que obtener al menos 65 puntos para aprobar. Si has hecho los dos exámenes de prueba (aunque hayas tardado 3,4 o 7 horas en completarlos la primera vez) y has practicado con katacoda, no deberías tener problemas en aprobar.\nAquí te recomiendo nada más terminar el temario, hacer un examen de prueba de killer.sh, completarlo durante las 24-36 horas que tienes abierta la plataforma sin prisa y asimilando bien todo lo que haces. A partir de ahí, no dejaría pasar más de una semana para hacer el segundo examen de prueba y el final. El segundo examen de prueba va a ser exactamente igual que el primero ( al menos en mi caso) pero te servirá para practicar la velocidad con la que solucionas los ejercicios.\nAlgunos trucos concretos para mejorar tu velocidad No creo que el examen sea muy complejo, pero si que hay que ir ligero para que luego tengas tiempo de repasar todas las preguntas. Personalmente, ya traía bastante experiencia en vim y tmux por lo que era bastante ágil con el terminal. Por eso es importante que estés familiarizado con los comandos para que no pierdas tiempo en buscarlos. Si prefieres nano o el gestor de pestañas del terminal del linux perfecto, la idea es que estés cómodo y que seas lo más rápido posible en el terminal.\nAunque es recomendable llevar la sintaxis fresca es imposible recordar todos los yaml de un objeto de memoria, en estos casos no te preocupes, tienes a tu disposición en el navegador de la máquina del examen acceso a la documentación de kubernetes. La navegación está muy limitada a la web de kubernetes pero es suficiente para encontrar toda la información que necesitas. En mi caso me molesté en documentarme los objetos que más utilizaba en mi web (puedes consultarla en la pestaña de -\u003e Documentación/contenedores/kubernetes) y de cara al examen tuve que practicar utilizando la oficial para ser rápido y tener ubicado todo lo que necesitaba en el examen.\nCuando empieces el examen la máquina virtual a la que te dan acceso trae la configuración de un linux por defecto. Aquí es interesante que inviertas un par de minutos en configurar tu entorno de trabajo.\nSin duda ganarás mucho tiempo configurando alias de kubernetes. Al menos el k para abreviar kubectl y el dro para --dry-run=client -o yaml te permitirá crear plantillas de objetos de kubernetes mucho más rápido (y el dry-run te permite ver el resultado sin crear el objeto). Estas configuraciones las puedes hacer en el fichero .bashrc:\nalias k=kubectl alias dro=--dry-run=client -o yaml También puede ser interesante configurar tmux y vim si tienes alguna personalización que aumente tu productividad. Personalmente, con los alias tenía suficiente para ganar tiempo.\nConclusión En resumen, la certificación CKA te permite sentirte cómodo administrando un cluster de kubernetes. Si tienes conocimientos previos de contenedores y orquestadores, no debería ser un problema. Si no los tienes, te recomiendo que te familiarices con ellos antes de empezar con la certificación. En cualquier caso, aún con la certificación, te encuentras con muchas situaciones en el día a día que no están cubiertas en el temario y que tendrás que investigar por tu cuenta.\nEspero que os haya servido de ayuda. Si tenéis cualquier duda, podéis preguntarme por cualquiera de mis redes sociales. ¡Un saludo!\n","categories":"","description":"","excerpt":"¡Hola! En esta entrada me gustaría contar mi experiencia con la …","ref":"/blog/2022/12/21/cka-mi-experiencia/","tags":["kubernetes"],"title":"CKA: Mi experiencia"},{"body":"","categories":"","description":"","excerpt":"","ref":"/tags/kubernetes/","tags":"","title":"kubernetes"},{"body":"En docker, podemos utilizar volúmenes para persistir datos incluso cuando los contenedores se destruyen. Estos volúmenes eran complejos de administrar en muchas circunstancias, por lo que docker ha creado una nueva funcionalidad para docker desktop, que nos permite crear backups de los volúmenes y compartirlos con otros usuarios de una forma sencilla.\n¿Cómo funciona? Docker desktop empezó a ofrecer extensiones hace unos meses. Estas extensiones nos permiten añadir funcionalidades a docker desktop, como por ejemplo, gestión visual de logs, uso de disco, herramientas de desarrollo, seguridad, etc.\nTengo un vídeo en youtube hablando de las extensiones de docker desktop, si quieres saber más sobre ellas.\nEn este caso, la extensión que nos interesa es la de Docker Backup. Esta extensión nos permite crear backups de los volúmenes de docker y compartirlos con otros usuarios de diferentes formas. Dentro vídeo:\nComandos utilizados Crear el contenedor de postgresql para las pruebas:\ndocker run --hostname=cb8f628fbe6d --mac-address=02:42:ac:11:00:02 --env=POSTGRES_PASSWORD=postgrespw --env=PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/lib/postgresql/15/bin --env=GOSU_VERSION=1.14 --env=LANG=en_US.utf8 --env=PG_MAJOR=15 --env=PG_VERSION=15.1-1.pgdg110+1 --env=PGDATA=/var/lib/postgresql/data --volume=/var/lib/postgresql/data -p 5432 --label='com.docker/featured-image=postgres:latest' --runtime=runc -d postgres:latest ","categories":"","description":"","excerpt":"En docker, podemos utilizar volúmenes para persistir datos incluso …","ref":"/blog/2022/12/01/crea-y-comparte-backups-en-docker/","tags":["docker","noticia"],"title":"Crea y comparte backups en docker"},{"body":"","categories":"","description":"","excerpt":"","ref":"/tags/noticia/","tags":"","title":"noticia"},{"body":"","categories":"","description":"","excerpt":"","ref":"/tags/pentesting/","tags":"","title":"pentesting"},{"body":"He hablado mucho de como hacer diversas acciones en docker y contenedores. Tampoco quiero que mi contenido sea monotemático pero me han lanzando una sugerencia de vídeo y no me puedo resistir a abordar el tema.\nConcretamente, el usuario pwnhun73r me sugirió utilizar contenedores para pentesting en laboratorios como HackTheBox o TryHackMe. Gracias por el apoyo y la sugerencia. Tu también puedes sugerir nuevo contenido desde la sección de issues de esta página en GitHub.\nHace tiempo que no me dedico al pentesting profesionalmente pero tampoco me gusta que se me oxide el tema. Youtube es muy restrictivo con el contenido del hacking por lo que, para este vídeo, me limitaré a plantear el entorno sin entrar en la explotación.\n¿Por qué? Esta es la pregunta del millón… ¿Por qué?¿Cuál es la necesidad?. Realmente las máquinas virtuales para esta labor igual son más prácticas que un contenedor, tienes tus copias de seguridad, tu interfaz, puedes conectarles hardware cómodamente (antenas, cables, etc) y puedes configurar los servicios que necesites.\nPara los fanáticos de los contenedores como yo, es por amor de llevar la tecnología al límite. Hay que reconocer que los contenedores tienen sus ventajas. Fáciles de ejecutar, versionar y almacenar. Suficiente para justificar este vídeo.\nRetos Tenemos dos retos a tener en cuenta basados en dos escenarios:\nContenedor para pentesting de un sitio web público Warning Antes de nada recordad que el sitio deberá ser de vuestra propiedad o deberéis tener permiso para auditarlo. En este supuesto, accedemos a algún sitio público y queremos hacer pentesting. Para la parte de la enumeración no tendremos limitación alguna. El problema surge cuando queremos explotar un sitio. La mayoría de conexiones que intentaremos generar serán inversas y, por tanto, necesitaremos abrir puertos en el router.\nConexiones desde un contenedor a un servidor público Supongamos que hacemos las pruebas desde un servidor público también, como un VPS. En este caso, no tendremos problema para abrir puertos. Aunque no todo queda ahí, tendremos que natear al contenedor un rango de puertos para que el servidor pueda acceder a los servicios que estemos ejecutando en el contenedor.\nImaginaros que estamos escuchando una conexión con netcat en el puerto 4444. Deberíamos ejecutar el contenedor con ese puerto mapeado del host para que podamos capturar las conexiones desde del contenedor.\nEsto podemos hacerlo así:\ndocker run -it -p 4444:4444 kalilinux/kali-rolling /bin/bash Contenedor para pentesting en un laboratorio privado En este caso, la parte de acceso y enrutamiento es más sencillo dado que normalmente a los laboratorios de pentesting nos conectamos a través de una VPN, la cuál, nos crea un tunel directamente desde el contenedor al laboratorio. Conexiones desde un contenedor a un laboratorio privado La problemática viene por la parte del cliente VPN en los contenedores.\nLimitaciones La principal limitación es la acceso a las interfaces de red. En una máquina virtual virtualizas tanto software como hardware. En el caso de los contenedores, al ser procesos aislados, tenemos que lidiar con la problemática de crear interfaces de red para las VPN de algunos laboratorio.\nPodemos levantar un contenedor con Kali Linux solventando estas limitaciones, usando el parámetro --privileged para que el contenedor tenga acceso a las interfaces de red del host y --sysctl net.ipv6.conf.all.disable_ipv6=0 para que el contenedor tenga acceso a la red IPv6.\nEl comando completo sería:\ndocker run -it --privileged --sysctl net.ipv6.conf.all.disable_ipv6=0 kalilinux/kali-rolling /bin/bash Así ya podríamos conectarnos a HackTheBox, por ejemplo.\nVídeo Sin más preámbulos, dentro vídeo: ","categories":"","description":"","excerpt":"He hablado mucho de como hacer diversas acciones en docker y …","ref":"/blog/2022/08/29/pentesting-desde-un-contenedor/","tags":["docker","pentesting","seguridad"],"title":"Pentesting desde un contenedor"},{"body":"","categories":"","description":"","excerpt":"","ref":"/tags/seguridad/","tags":"","title":"seguridad"},{"body":"He de reconocer que no soy muy fan de powershell, es más, en ciertos momentos de mi vida he llegado a detestarlo. Tanto si te encanta powershell como si te ves forzado a usarlo, hay que reconocer quees muy mejorable.\nEn el anterior vídeo vimos el proceso de potenciar el terminal en entornos unix y linux mediante zsh y oh-my-zsh. Aquí la entrada al blog y enlace al vídeo\nPara esta ocasión, abordaremos el tema en sistemas windows utilizando oh my posh. OMP nos ofrece características, que a día de hoy considero indispensables, como:\nAuto completado Navegación simplificada Información avanzada Personalizacion con múltiples temas Dentro vídeo: Todos los comandos del vídeo y enlaces están en la siguiente página: Documentación: /docs/windows/oh_my_posh/\n","categories":"","description":"Potencia la terminal de tu sistema operativo y enamórate de ella.","excerpt":"Potencia la terminal de tu sistema operativo y enamórate de ella.","ref":"/blog/2022/08/08/potencia-powershell/","tags":["powershell","terminal"],"title":"Potencia powershell"},{"body":"","categories":"","description":"","excerpt":"","ref":"/tags/powershell/","tags":"","title":"powershell"},{"body":"","categories":"","description":"","excerpt":"","ref":"/tags/terminal/","tags":"","title":"terminal"},{"body":"Los contenedores son procesos aislados que, por defecto, ¿se podrían considerar como seguros?. Su enfoque nos dice que sí pero existen muchos casos en los que, principalmente por malas configuraciones, podrían ser vulnerables.\nAislados pero no herméticos Tecnologías de contenedores como Docker, LXC, LXD, etc.. permiten a los usuarios lanzar un proceso aislado pero, existen multiples funcionalidades, que podrían comprometer la aplicación en mayor o menor medida.\nDocumentación: /docs/pentesting/privilegios/contenedores\nEn este vídeo trato las principales malas configuraciones que permiten a un atacante escapar de un contenedor:\nPrincipales malas configuraciones:\nMontaje de volúmenes Ejecución en modo privilegiado Escalado a través del grupo de docker Host vulnerable Secretos o variables de entorno Montaje del socket Segregación de redes ","categories":"","description":"","excerpt":"Los contenedores son procesos aislados que, por defecto, ¿se podrían …","ref":"/blog/2022/03/29/escalar-privilegios-en-docker/","tags":["docker","privilegios"],"title":"Escalar privilegios en docker"},{"body":"","categories":"","description":"","excerpt":"","ref":"/tags/privilegios/","tags":"","title":"privilegios"},{"body":"","categories":"","description":"","excerpt":"","ref":"/tags/raspberry/","tags":"","title":"raspberry"},{"body":"Las raspberry pi son de las computadoras más versátiles y asequibles que puedes encontrar en el mercado. Además, dada su popularidad, tienen una gran cantidad de software específico (pihole, piretro… etc) que ayudará a darle un sinfín de usos y, por otra parte, tiene muchos accesorios que la potenciarán aún más si cabe.\nConcretamente me refiero a la pantalla táctil de 7 pulgadas que se puede montar en cualquier raspberry pi. Esta se puede utilizar para crear un consola portátil, control industrial, etc.\nRaspberry touchscreen 7 pulgadas Instalación y configuración En este vídeo he detallado el proceso de instalación y configuración de la pantalla táctil.\nPero, ¿y la carcasa? En la pantalla oficial no viene incluida una carcasa que proteja la parte trasera de la pantalla y la raspberry. Podemos comprarlas por precios entre 10-20€, aunque, si eres maker o tienes una impresora 3D, en la web de thingiverse podrás encontrar una gran variedad de modelos para hacértela tu mismo.\n","categories":"","description":"Montaje e instalación de una pantalla táctil de 7 pulgadas en un Raspberry Pi 4","excerpt":"Montaje e instalación de una pantalla táctil de 7 pulgadas en un …","ref":"/blog/2022/02/27/raspberry-pi-touchscreen-7/","tags":["raspberry"],"title":"Raspberry Pi Touchscreen 7"},{"body":"","categories":"","description":"","excerpt":"","ref":"/tags/bash/","tags":"","title":"bash"},{"body":"Hola y bienvenidos a un nuevo vídeo en el que hablaremos de zsh y un framework llamado oh-my-zsh. Estos te permitirán personalizar el terminal para adaptarlo a tus gustos y necesidades. Espero que después de este vídeo termines amándolo y usándolo más a menudo.\nDentro vídeo: Todos los comandos del vídeo y enlaces estan en la siguiente página: Documentación: /docs/linux/zsh/\n","categories":"","description":"Potencia la terminal de tu sistema operativo y enamórate de ella.","excerpt":"Potencia la terminal de tu sistema operativo y enamórate de ella.","ref":"/blog/2021/12/30/potencia-tu-terminal/","tags":["bash","zsh","terminal"],"title":"Potencia tu terminal"},{"body":"","categories":"","description":"","excerpt":"","ref":"/tags/zsh/","tags":"","title":"zsh"},{"body":"","categories":"","description":"","excerpt":"","ref":"/tags/desarrollo/","tags":"","title":"desarrollo"},{"body":"","categories":"","description":"","excerpt":"","ref":"/tags/errores/","tags":"","title":"errores"},{"body":"Hola y bienvenidos a una nueva entrada del blog. En este artículo se explicarán los errores más comunes en git y como solucionarlos.\nLogo de git Git es un sistma metódico de control de versiones, que permite almacenar una serie de cambios en un repositorio de código fuente. Durante los procesos de desarrollo es muy habitual que se cometan ciertos errores al trabajar con git. No pasa nada, es normal y más cuando se esta aprendiendo.\nEn este vídeo comento los que considero más comunes pero no dudes en contribuir si se te ocurre algún error que no se haya explicado. Todos los comandos los puedes encontrar en la documentación por escrito. Para todo lo demás, dentro vídeo:\n","categories":"","description":"Errores más comunes en git y como solucionarlos","excerpt":"Errores más comunes en git y como solucionarlos","ref":"/blog/2021/12/12/errores-comunes-en-git/","tags":["git","errores","video","desarrollo"],"title":"Errores comunes en Git"},{"body":"","categories":"","description":"","excerpt":"","ref":"/tags/git/","tags":"","title":"git"},{"body":"","categories":"","description":"","excerpt":"","ref":"/tags/video/","tags":"","title":"video"},{"body":"El subsistema de linux en windows se introdujo hace unos años en windows 10 pero sus primeras versiones tenían ciertas limitaciones y no acababa de funcionar como se esperaba. Personalmente, con WSL2 y Windows 11 creo que ha llegado a ofrecer el funcionamiento que realmente se esperaba de el. Dentro vídeo: Ventajas y desventajas En el vídeo analizo las principales ventajas que ofrece y alguna que otra desventaja por el camino. Los principales puntos a destacar son:\nEl consumo de memoria es inferior al de una máquina virtual. Aunque mayor que una solución nativa, windows virtualiza un kernel linux que aprovechan y comparten las distintas distribuciones del subsistema. También sirve backend para aplicaciones como Docker Desktop o Rancher Desktop haciendolos más livianos que usándolos sober hyper-V. La integración con windows terminal es sencilla. Además, este nuevo terminal nos ofrece una interfaz limpia, personalizable y con una multitarea que ya le hacía falta. Nose vosotros pero a mi me encanta. Simplicidad en el uso de varios entornos, instalación, reseteo o borrado. La integración con VS Code de forma bidireccional es algo que me encanta. Ya no me molesto en instalar los lenguajes de programación o las herramientas de sistemas en windows, prácticamente todo lo uso sobre una distribución u otra en función de lo que necesite. Montaje del sistema de archivos. Aunque el acceso es más lento al ser dos sistemas de archivos diferentes, windows nos monta nuestro home (c:/users/pablo) en cada uno de los subsistemas. Integración de los sistemas de archivos de las distribuciones en el explorador de windows. Integración de los sistemas de archivos de las distribuciones en el explorador de windows. Espero que os guste y os anime a sacarle más partido a las herramientas que nos ofrece windows. ¡Hasta el próximo!\n","categories":"","description":"El subsistema de linux en windows nos permite ejecutar nuestras herramientas de desarrollo o sistemas favoritas sin complicaciones","excerpt":"El subsistema de linux en windows nos permite ejecutar nuestras …","ref":"/blog/2021/11/10/linux-en-windows-windows-subsystem-linux/","tags":"","title":"Linux en Windows - Windows Subsystem Linux"},{"body":"","categories":"","description":"","excerpt":"","ref":"/tags/kalilinux/","tags":"","title":"kalilinux"},{"body":"Unas semanas antes de la creación de esta web había hecho una trilogía de vídeos hablando de como utilizar el sistema operativo Kalilinux en Docker. Por dejarlos aquí archivados de alguna manera y dejar la documentación por escrito he optado por escribir esta entrada.\nVentajas y desventajas de utilizar Kalilinux en Docker Bueno, yo creo que si conoces la tecnología docker la respuesta es simple. Puedes tener imágenes ligeras, con las herramientas que necesitas, preparadas para ejecutar muy rápidamente. Tambien puedes gestionarlas con un repositorio remoto y transportarlas fácilmente entre distintos entornos.\nPero como todo, tiene sus grandes inconvenientes. Las imágenes de docker no tienen acceso directo al hardware y eso puede lastrar un poco el rendimiento, concretamente si necesitamos la tarjeta gráfica en operaciones de computación como el cracking de contraseñas.\nEn la propia página de Kali se puede ver la comparativa completa con todas sus opciones:\nComparativa de las distintas opciones de Kalilinux. Vídeos explicativos ","categories":"","description":"Como crear tus propias imágenes, dockerfiles y usarlo con interfaz gráfica","excerpt":"Como crear tus propias imágenes, dockerfiles y usarlo con interfaz …","ref":"/blog/2021/11/01/kali-en-docker-recopilaci%C3%B3n/","tags":["docker","kalilinux","seguridad"],"title":"Kali en Docker recopilación"},{"body":"","categories":"","description":"","excerpt":"","ref":"/tags/devops/","tags":"","title":"devops"},{"body":"Ya estuve explicando en este artículo los nuevos planes de Docker Desktop y como afectaría a los usuarios. Aunque existen otras alternativas como Buildah o Podman, estas, solo funcionan sobre linux y si sois usuarios de Windows o Mac y pensais en montar una máquina Linux quizá prefiráis usar docker engine por la familiaridad que no usar otras herramientas.\nRancher Desktop se posiciona como una alternativa a tener en cuenta. Dentro vídeo ¿Qué es rancher desktop? Si vienes del mundo de kubernetes seguro que Rancher te es familiar. Este es una plataforma de kubernetes con una capa de gestión pensado en la facilidad de despliegue y gestión de clústers.\nEn esta ocasión, rancher desktop es una forma de acercarse a los desarrolladores y competir directamente con docker en el escritorio.\n¿Qué aporta? El planteamiento es similar al de Docker Desktop, gestiona automáticamente la instalación de una interfaz de usario, el engine de contenedores (containerd), k3s (la misma tecnología que utiliza rancher para kubernetes), kubectl… etc y todo este paquete en una instalación sencilla.\nPanel de control de rancher desktop en Mac Si has visto el vídeo Rancher Desktop, al menos en Windows, tiene algunos pequeños errores. Cabe recordar que su estado de desarrollo es pre-release y es normal que durante sus betas encontremos errores que nos impidan utilizarlo a día de hoy.\nLa alternativa definitiva Como ya comentaba, una solución 100% efectiva es instalar docker en una máquina virtual de linux. Esto lo podríamos hacer manualmente pero, puestos a hacerlo, mejor hacerlo bien.\nUn viejo compañero con alias Yohnah en Github ha creado un repositorio con automatismos y una máquina virtual preparada para desplegar automáticamente con Vagrant. La máquina virtual viene con docker instalado y listo para funcionar, además, el automatismo deja el host configurado para que utilice el docker engine de la máquina virtual de una forma similar a la que lo hace docker desktop. Toda la guía aquí: https://github.com/Yohnah/Docker\n¡Hasta el siguiente!\n","categories":"","description":"","excerpt":"Ya estuve explicando en este artículo los nuevos planes de Docker …","ref":"/blog/2021/10/24/la-alternativa-a-docker-que-estabas-buscando-rancher-desktop/","tags":["docker","devops"],"title":"La alternativa a Docker que estabas buscando - Rancher Desktop"},{"body":"En anteriores vídeos he hablado acerca de la seguridad a la hora de crear imágenes pero hay un aspecto más crítico y fundamental que se suele obviar al construir imágenes. Estas, contienen software en forma de librerías del sistema que también pueden ser vulnerables. Pero, ¿como podemos revisar esa seguridad?\n¿Qué riesgos de seguridad hay en las imágenes de Docker? Cuando construimos imágenes de Docker siempre partimos de una imagen base, que es la que se usa para construir las imágenes que queremos. Esta imagen base puede ser una imagen de una distribución Linux, o de una imagen de una aplicación. Estas imágenes pueden contener código de una aplicación, librerías, paquetes, etc. Todo el código que se encuentre en estas imágenes puede ser vulnerable a ataques de seguridad.\n¿Que herramientas podemos usar para analizar la seguridad de las imágenes de Docker? Existen multitud de herramientas que pueden ser útiles para analizar la seguridad de las imágenes de Docker. Las más destacadas son:\nTrivy Anchore Clair Para este vídeo y evitar instalar nada, hemos utilizado el escáner que viene incorporado con Docker en las últimas versiones. Se puede ejecutar con el siguiente comando:\ndocker scan \u003cnombre de la imagen\u003e Iré documentando el uso de diferentes herramientas de análisis de seguridad en la siguiente pagína de la documentación: Escaneo de seguridad en contenedores\n","categories":"","description":"","excerpt":"En anteriores vídeos he hablado acerca de la seguridad a la hora de …","ref":"/blog/2021/09/19/analizar-la-seguridad-de-las-im%C3%A1genes-de-docker/","tags":["docker","seguridad"],"title":"Analizar la seguridad de las imágenes de Docker"},{"body":"La empresa Docker anunció la semana pasada los cambios en su modelo de negocio empresarial y sus nuevos planes de subscripción para empresas.\nHasta el momento, la empresa ha sabido posicionarse como una de las más importantes en el mundo de la tecnología pero sin generar ningún tipo de ingreso.\nLas nuevas versiones tendrán ciertas restricciones que forzarán a algunas empresas a utilizar las modalidades de pago.\nPlanes de precios de Docker Con el precio, todo hay que decirlo, ganamos muchas funcionalidades como SSO, escaneos de seguridad, builds en la nube, colaboración entre equipos… etc. Podéis ver una lista completa de las funcionalidades en la página de Docker.\n¿Quién tiene que pagar? Las empresas que tengan más de 250 empleados o unos ingresos anuales de 10 millones de dólares deberán utilizar los planes profesionales, de equipos o de empresa. Para dar margen a medianas y grandes empresas, las principales afectadas, se dará un periodo de gracia hasta el 31 de Enero de 2022.\nSeguirá siendo totalmente gratuito en los siguientes casos:\nPequeñas empresas con menos de 250 empleados y menos de 10 millones de dólares de ingresos anuales. Uso personal. Instituciones educativas. Proyectos no comerciales open-source. ¿Qué alternativas tengo? Estas nuevas políticas solo afecta a la versión de Docker Desktop, es decir, a la versión de Windows y Mac. En linux se utiliza Docker Engine al cuál no se le aplican estas restricciones.\nAdemás, docker no es la única forma de construir contenedores. Existen otras tecnologías como podman o buildah que también nos permiten construir imágenes sin requerir un docker engine aunque estas también solo estan disponibles en Linux.\n","categories":"","description":"Analizamos los últimos cambios de Docker Desktop, como afectarán al usuario y las posibles alternativas.","excerpt":"Analizamos los últimos cambios de Docker Desktop, como afectarán al …","ref":"/blog/2021/09/12/docker-desktop-de-pago/","tags":["docker","noticia"],"title":"¿Docker desktop de pago?"},{"body":"Esta es la sección de blog. Tiene dos categorías principales: Entradas y noticias. También puedes utilizar las etiquetas o el buscador para navegar sobretodo el contenido.\n","categories":"","description":"","excerpt":"Esta es la sección de blog. Tiene dos categorías principales: Entradas …","ref":"/blog/","tags":"","title":"Blog"},{"body":"","categories":"","description":"","excerpt":"","ref":"/categories/","tags":"","title":"Categories"},{"body":"","categories":"","description":"","excerpt":"","ref":"/tags/configuracion/","tags":"","title":"configuracion"},{"body":"","categories":"","description":"","excerpt":"","ref":"/tags/contenedores/","tags":"","title":"contenedores"},{"body":"","categories":"","description":"","excerpt":"","ref":"/tags/database/","tags":"","title":"database"},{"body":"","categories":"","description":"","excerpt":"","ref":"/tags/fingerprinting/","tags":"","title":"fingerprinting"},{"body":" Bienvenido a mi sitio personal Sobre mí Documentación Blog Vídeos ¡Pasa y descubre en que invierto mi tiempo!\nEste sitio personal busca ser el nexo de todo el contenido que genero en mi tiempo libre. Me encanta compartir conocimiento y aprender en el proceso.\nYoutube No te pierdas ningún video suscribiendote a mi canal.\nContiuar leyendo …\nGitHub Puedes hacer un Pull Request de todo el contenido de la web y visitar otros proyectos. ¡Toda ayuda en bienvenida!\nContiuar leyendo …\nTwitter Para estar al día de los últimos anuncios y publicaciones.\nContiuar leyendo …\n¿Quieres saber más de mí o del contenido de la web?\nEn este sitio web almaceno toda la documentación que vaya generando, las entradas de blog y mi perfil personal.\nPerfil personal Para saber un poco más de mi, aunque no te pierdes nada.\nContiuar leyendo …\nDocumentación Recopilación de todos los recursos que vaya generando.\nContiuar leyendo …\nBlog Para estar al tanto de las últimas novedades.\nContiuar leyendo …\n","categories":"","description":"","excerpt":" Bienvenido a mi sitio personal Sobre mí Documentación Blog Vídeos …","ref":"/","tags":"","title":"Goldydocs"},{"body":"","categories":"","description":"","excerpt":"","ref":"/tags/grub/","tags":"","title":"grub"},{"body":"","categories":"","description":"","excerpt":"","ref":"/tags/helm/","tags":"","title":"helm"},{"body":"","categories":"","description":"","excerpt":"","ref":"/tags/linux/","tags":"","title":"linux"},{"body":"","categories":"","description":"","excerpt":"","ref":"/tags/mysql/","tags":"","title":"mysql"},{"body":"","categories":"","description":"","excerpt":"","ref":"/tags/programaci%C3%B3n/","tags":"","title":"programación"},{"body":"","categories":"","description":"","excerpt":"","ref":"/tags/python/","tags":"","title":"python"},{"body":"","categories":"","description":"","excerpt":"","ref":"/tags/reconocimiento/","tags":"","title":"reconocimiento"},{"body":"","categories":"","description":"","excerpt":"","ref":"/tags/redes/","tags":"","title":"redes"},{"body":"","categories":"","description":"","excerpt":"","ref":"/tags/restaurar/","tags":"","title":"restaurar"},{"body":"","categories":"","description":"","excerpt":"","ref":"/search/","tags":"","title":"Search Results"},{"body":"","categories":"","description":"","excerpt":"","ref":"/tags/secrets/","tags":"","title":"secrets"},{"body":"","categories":"","description":"","excerpt":"","ref":"/tags/shell/","tags":"","title":"shell"},{"body":" Sobre mí Pablo Pérez-Aradros. ¿Quién soy? Soy un entusiasta de la tecnología en general, la seguridad informática y el desarrollo de software en particular. Disfruto creando contenido y compartiendo mis conocimientos. Tras impartir formación en los últimos años descubrí que la mejor manera de aprender es enseñando a los demás.\n\"Si quieres dominar algo, enséñalo. Cuanto más enseñas mejor aprendes. La enseñanza es una herramienta poderosa para el aprendizaje\" - Richard Feynman Empecé hace unos años en el mundo del desarrollo del software. Pronto me especializé en pentesting, especialmente en tecnologías web, uniendo en parte dos pasiones. Pasé un poco de puntillas por la parte de sistemas hasta descubrir las tecnologías de contenedores y la filosofía DevOps. En los dos últimos años he hecho un cocktel con todos estos intereses y me dedico profesionalmente a la securización de procesos de desarrollo como DevSecOps. Mi perfil profesional Mi perfil personal ","categories":"","description":"","excerpt":" Sobre mí Pablo Pérez-Aradros. ¿Quién soy? Soy un entusiasta de la …","ref":"/about/","tags":"","title":"Sobre mí"},{"body":"","categories":"","description":"","excerpt":"","ref":"/tags/sql/","tags":"","title":"sql"},{"body":"","categories":"","description":"","excerpt":"","ref":"/tags/unix/","tags":"","title":"unix"},{"body":"","categories":"","description":"","excerpt":"","ref":"/tags/vulnerabilidades/","tags":"","title":"vulnerabilidades"}]